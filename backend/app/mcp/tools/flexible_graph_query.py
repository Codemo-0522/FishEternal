"""
çµæ´»çš„çŸ¥è¯†å›¾è°±æŸ¥è¯¢å·¥å…·ï¼ˆLLMé©±åŠ¨ï¼‰

æ ¸å¿ƒç†å¿µï¼š
- ä¸å†ç¡¬ç¼–ç å‡ åä¸ªå›ºå®šæŸ¥è¯¢å‡½æ•°
- LLMæ ¹æ®ç”¨æˆ·æ„å›¾åŠ¨æ€ç”ŸæˆCypheræŸ¥è¯¢
- åç«¯è´Ÿè´£å®‰å…¨éªŒè¯å’Œæ‰§è¡Œ

ä¼˜åŠ¿ï¼š
- æ— é™çµæ´»ï¼šæ”¯æŒä»»æ„å¤æ‚çš„æŸ¥è¯¢ç»„åˆ
- è‡ªé€‚åº”ï¼šLLMè‡ªåŠ¨ç†è§£ç”¨æˆ·æ„å›¾
- å¯æ‰©å±•ï¼šæ–°å¢èŠ‚ç‚¹ç±»å‹æ— éœ€ä¿®æ”¹ä»£ç 
"""
import json
import logging
import re
from typing import Dict, Any, List, Optional
from ..base import BaseTool, ToolMetadata, ToolContext, ToolExecutionError
from ...knowledge_graph.neo4j_client import get_client as get_neo4j_client, is_neo4j_available

logger = logging.getLogger(__name__)


class FlexibleGraphQueryTool(BaseTool):
    """
    çµæ´»çš„çŸ¥è¯†å›¾è°±æŸ¥è¯¢å·¥å…·
    
    å…è®¸LLMæ ¹æ®ç”¨æˆ·éœ€æ±‚åŠ¨æ€ç”ŸæˆCypheræŸ¥è¯¢ï¼Œå®ç°çœŸæ­£çš„çµæ´»æ£€ç´¢
    """
    
    # å®‰å…¨ç™½åå•ï¼šå…è®¸çš„Cypherå…³é”®å­—
    ALLOWED_KEYWORDS = {
        # æŸ¥è¯¢å…³é”®å­—
        "MATCH", "OPTIONAL MATCH", "WHERE", "RETURN", "WITH", "UNWIND",
        "ORDER BY", "LIMIT", "SKIP", "DISTINCT", "AS",
        
        # èšåˆå‡½æ•°
        "count", "collect", "sum", "avg", "min", "max",
        
        # å­—ç¬¦ä¸²å‡½æ•°
        "toLower", "toUpper", "trim", "substring", "replace", "split",
        "CONTAINS", "STARTS WITH", "ENDS WITH",
        
        # æ•°å­¦å‡½æ•°
        "abs", "ceil", "floor", "round", "sqrt",
        
        # é€»è¾‘è¿ç®—
        "AND", "OR", "NOT", "IN", "IS NULL", "IS NOT NULL",
        
        # å…³ç³»å’ŒèŠ‚ç‚¹
        "Paper", "Author", "FieldOfStudy", "Venue", "Reference",
        "AUTHORED", "CITED", "BELONGS_TO_FIELD", "PUBLISHED_IN", "COLLABORATED"
    }
    
    # å±é™©æ“ä½œé»‘åå•
    FORBIDDEN_KEYWORDS = {
        "CREATE", "MERGE", "DELETE", "REMOVE", "SET", "DETACH",
        "DROP", "ALTER", "CALL", "LOAD CSV", "FOREACH"
    }
    
    def __init__(self):
        """åˆå§‹åŒ–çµæ´»æŸ¥è¯¢å·¥å…·"""
        self.neo4j_client = get_neo4j_client()
    
    def _check_availability(self) -> tuple[bool, str]:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨"""
        if not is_neo4j_available():
            return False, "neo4jåº“æœªå®‰è£…"
        
        if not self.neo4j_client.is_connected():
            return False, "çŸ¥è¯†å›¾è°±æœªè¿æ¥"
        
        return True, "å¯ç”¨"
    
    def get_metadata(self, context: Optional[ToolContext] = None) -> Optional[ToolMetadata]:
        """è·å–å·¥å…·å…ƒæ•°æ®"""
        available, reason = self._check_availability()
        if not available:
            logger.debug(f"ğŸš« çµæ´»å›¾è°±æŸ¥è¯¢å·¥å…·ä¸å¯ç”¨: {reason}")
            return None
        
        description = """
ğŸ”¥ **çµæ´»çš„çŸ¥è¯†å›¾è°±æŸ¥è¯¢å·¥å…·ï¼ˆLLMå®Œå…¨æ§åˆ¶ï¼‰**

è¿™æ˜¯ä¸€ä¸ªé©å‘½æ€§çš„æŸ¥è¯¢å·¥å…·ï¼Œå…è®¸ä½ æ ¹æ®ç”¨æˆ·æ„å›¾**åŠ¨æ€ç”ŸæˆCypheræŸ¥è¯¢**ï¼Œè€Œä¸æ˜¯è¢«é™åˆ¶åœ¨å‡ ä¸ªå›ºå®šçš„æŸ¥è¯¢å‡½æ•°ä¸­ã€‚

---

## âš ï¸ å¼ºåˆ¶è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰

**ğŸš¨ æ¯ä¸ªæŸ¥è¯¢å¿…é¡»åŒ…å« LIMIT å­å¥ï¼ˆæœ€å¤§100ï¼‰**
- âœ… æ­£ç¡®ï¼š`RETURN ... LIMIT 20`
- âŒ é”™è¯¯ï¼š`RETURN ...`ï¼ˆç¼ºå°‘LIMITä¼šè¢«æ‹’ç»ï¼‰

---

## ğŸ“Š å®Œæ•´å›¾è°±ç»“æ„ï¼ˆèŠ‚ç‚¹ + å…³ç³»ï¼‰

### ğŸ”· èŠ‚ç‚¹ç±»å‹ï¼ˆ5ç§ï¼‰

| èŠ‚ç‚¹ç±»å‹ | å”¯ä¸€ID | æ ¸å¿ƒå±æ€§ | è¯´æ˜ |
|---------|--------|---------|------|
| **Paper** | `paper_id` | `title`, `abstract`, `year`, `n_citation`, `venue`, `doi`, `volume`, `issue`, `page_start`, `page_end`, `publisher`, `doc_type` | è®ºæ–‡ï¼ˆæ ¸å¿ƒèŠ‚ç‚¹ï¼‰ |
| **Author** | `author_id` | `name`, `org`, `total_papers` | ä½œè€… |
| **FieldOfStudy** | `field_id` | `name`, `paper_count` | ç ”ç©¶é¢†åŸŸ |
| **Venue** | `venue_id` | `name`, `type`, `paper_count` | ä¼šè®®/æœŸåˆŠ |
| **Reference** | `ref_id` | `title`, `authors`, `year`, `venue` | å¼•ç”¨æ–‡çŒ®ï¼ˆä¸åœ¨åº“ä¸­çš„è®ºæ–‡ï¼‰ |

### ğŸ”— å…³ç³»ç±»å‹ï¼ˆ7ç§ï¼‰

| å…³ç³» | æ–¹å‘ | å±æ€§ | è¯´æ˜ | æŸ¥è¯¢ç¤ºä¾‹ |
|-----|------|------|------|---------|
| **AUTHORED** | Author â†’ Paper | `position` (first/middle/last) | ä½œè€…æ’°å†™è®ºæ–‡ | `(a:Author)-[:AUTHORED]->(p:Paper)` |
| **AUTHORED** | Author â†’ Reference | æ—  | ä½œè€…æ’°å†™å¼•ç”¨æ–‡çŒ® | `(a:Author)-[:AUTHORED]->(ref:Reference)` |
| **BELONGS_TO_FIELD** | Paper â†’ FieldOfStudy | æ—  | è®ºæ–‡æ‰€å±é¢†åŸŸï¼ˆæ ¸å¿ƒæ£€ç´¢ï¼‰ | `(p:Paper)-[:BELONGS_TO_FIELD]->(f:FieldOfStudy)` |
| **PUBLISHED_IN** | Paper â†’ Venue | `year` | è®ºæ–‡å‘è¡¨åœ¨ä¼šè®®/æœŸåˆŠ | `(p:Paper)-[:PUBLISHED_IN]->(v:Venue)` |
| **PUBLISHED_IN** | Reference â†’ Venue | `year` | å¼•ç”¨æ–‡çŒ®å‘è¡¨åœ¨ä¼šè®®/æœŸåˆŠ | `(ref:Reference)-[:PUBLISHED_IN]->(v:Venue)` |
| **CITED** | Paper â†’ Paper | æ—  | è®ºæ–‡å¼•ç”¨è®ºæ–‡ï¼ˆéƒ½åœ¨åº“ä¸­ï¼‰ | `(p1:Paper)-[:CITED]->(p2:Paper)` |
| **CITED** | Paper â†’ Reference | æ—  | è®ºæ–‡å¼•ç”¨æ–‡çŒ®ï¼ˆè¢«å¼•ç”¨çš„ä¸åœ¨åº“ä¸­ï¼‰ | `(p:Paper)-[:CITED]->(ref:Reference)` |
| **COLLABORATED** | Author â†” Author | `paper_count` | ä½œè€…åˆä½œå…³ç³»ï¼ˆåŒå‘ï¼‰ | `(a1:Author)-[:COLLABORATED]-(a2:Author)` |

### ğŸ¯ æ”¯æŒçš„æŸ¥è¯¢ç±»å‹

âœ… **å•ç»´åº¦æŸ¥è¯¢**ï¼šæŒ‰ä½œè€…/é¢†åŸŸ/ä¼šè®®/å¹´ä»½/å¼•ç”¨æ•°æŸ¥æ‰¾è®ºæ–‡
âœ… **äº¤å‰æŸ¥è¯¢**ï¼šç»„åˆå¤šä¸ªæ¡ä»¶ï¼ˆå¦‚ï¼šæŸé¢†åŸŸ + æŸä½œè€… + æŸå¹´ä»½ + æœ€å°å¼•ç”¨æ•°ï¼‰
âœ… **å›¾éå†**ï¼šå¤šè·³å¼•ç”¨é“¾ã€åˆä½œç½‘ç»œï¼ˆå¦‚ï¼š`-[:CITED*1..3]->`ï¼‰
âœ… **åå‘æŸ¥è¯¢**ï¼šé€šè¿‡å¼•ç”¨æ–‡çŒ®æ ‡é¢˜æ‰¾å¼•ç”¨å®ƒçš„è®ºæ–‡
âœ… **èšåˆç»Ÿè®¡**ï¼šcountã€collectã€avg ç­‰

---

## ğŸ¯ ä½¿ç”¨æ–¹å¼

### å‚æ•°è¯´æ˜

| å‚æ•° | å¿…å¡« | è¯´æ˜ |
|-----|------|------|
| `cypher_query` | âœ… | CypheræŸ¥è¯¢è¯­å¥ï¼ˆ**å¿…é¡»åŒ…å«LIMIT**ï¼‰ |
| `query_parameters` | âŒ | å‚æ•°åŒ–å€¼ï¼ˆå¦‚ `{"author_name": "Yann LeCun"}`ï¼‰ |
| `intent_description` | âœ… | æŸ¥è¯¢æ„å›¾æè¿°ï¼ˆä¸€å¥è¯ï¼‰ |
| `max_results` | âŒ | æœ€å¤§è¿”å›æ•°ï¼ˆé»˜è®¤50ï¼Œæœ€å¤§100ï¼‰ |

### ğŸ“Š å›¾è°±å¯è§†åŒ–è‡ªåŠ¨æ”¯æŒ

**ğŸ‰ å¥½æ¶ˆæ¯**ï¼šåç«¯ä¼š**è‡ªåŠ¨æå–å›¾è°±æ•°æ®**ç”¨äºå¯è§†åŒ–ï¼Œä½ åªéœ€å…³æ³¨ä¸šåŠ¡æ•°æ®ï¼

**å·¥ä½œåŸç†**ï¼š
1. ä½ å†™æŸ¥è¯¢æ—¶ï¼Œåªéœ€ RETURN ä½ æƒ³è¦çš„æ•°æ®ï¼ˆå¦‚ `RETURN p.title, p.year`ï¼‰
2. åç«¯è‡ªåŠ¨ä»æŸ¥è¯¢è·¯å¾„ä¸­æå–æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»
3. æ•°æ®åˆ†ç¦»ï¼š
   - **ç»™ LLM**ï¼šåªæœ‰ä¸šåŠ¡å­—æ®µï¼ˆ`p.title`, `p.year`ï¼‰
   - **ç»™å‰ç«¯**ï¼šå®Œæ•´çš„å›¾è°±ç»“æ„ï¼ˆèŠ‚ç‚¹+è¾¹ï¼Œç”¨äºå¯è§†åŒ–ï¼‰

**ç¤ºä¾‹**ï¼š
```cypher
MATCH (a:Author)-[r:AUTHORED]->(p:Paper)
WHERE toLower(a.name) CONTAINS 'tom stafford'
RETURN p.title, p.year  â† ä½ åªå†™ä¸šåŠ¡æ•°æ®
ORDER BY p.year DESC
LIMIT 20  â† å¿…é¡»æœ‰LIMIT
```

**åç«¯è‡ªåŠ¨å¤„ç†**ï¼š
- ğŸ“¤ ç»™ LLMï¼š`{"p.title": "...", "p.year": 2021}`ï¼ˆç®€æ´ï¼‰
- ğŸ“¤ ç»™å‰ç«¯ï¼š`{"nodes": [Author, Paper], "edges": [AUTHORED]}`ï¼ˆå¯è§†åŒ–ï¼‰

---

## ğŸ’¡ æŸ¥è¯¢ç¤ºä¾‹ï¼ˆå¿…é¡»åŒ…å«LIMITï¼‰

### ç¤ºä¾‹1ï¼šæŸ¥æ‰¾æŸä½œè€…çš„æ‰€æœ‰è®ºæ–‡
```cypher
MATCH (a:Author)-[r:AUTHORED]->(p:Paper)
WHERE toLower(a.name) CONTAINS toLower($author_name)
RETURN 
  p.paper_id, 
  p.title, 
  COALESCE(p.abstract, '') as abstract,
  COALESCE(p.year, 0) as year, 
  COALESCE(p.n_citation, 0) as citations,
  COALESCE(p.venue, '') as venue,
  COALESCE(p.doi, '') as doi
ORDER BY COALESCE(p.n_citation, 0) DESC
LIMIT 20
```
å‚æ•°ï¼š`{"author_name": "Yann LeCun"}`

### ç¤ºä¾‹2ï¼šæŸ¥æ‰¾æŸè®ºæ–‡çš„å¼•ç”¨é“¾
```cypher
MATCH path = (p:Paper {paper_id: $paper_id})-[:CITED*1..2]->(cited:Paper)
RETURN 
  cited.paper_id, 
  cited.title, 
  COALESCE(cited.year, 0) as year, 
  COALESCE(cited.n_citation, 0) as citations,
  length(path) as depth
ORDER BY COALESCE(cited.n_citation, 0) DESC
LIMIT 30
```
å‚æ•°ï¼š`{"paper_id": "abc123"}`

### ç¤ºä¾‹3ï¼šæŸ¥æ‰¾ä¸¤ä¸ªä½œè€…çš„åˆä½œè®ºæ–‡
```cypher
MATCH (a1:Author)-[r1:AUTHORED]->(p:Paper)<-[r2:AUTHORED]-(a2:Author)
WHERE toLower(a1.name) CONTAINS toLower($author1)
  AND toLower(a2.name) CONTAINS toLower($author2)
RETURN 
  p.paper_id, 
  p.title, 
  COALESCE(p.year, 0) as year,
  a1.name as author1_name,
  a2.name as author2_name
ORDER BY COALESCE(p.year, 0) DESC
LIMIT 10
```
å‚æ•°ï¼š`{"author1": "Geoffrey Hinton", "author2": "Yann LeCun"}`

### ç¤ºä¾‹4ï¼šâœ¨ é€šè¿‡é¢†åŸŸæ£€ç´¢æ‰€æœ‰ç›¸å…³è®ºæ–‡ï¼ˆğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ï¼‰
```cypher
MATCH (f:FieldOfStudy)<-[rf:BELONGS_TO_FIELD]-(p:Paper)
WHERE toLower(f.name) CONTAINS toLower($field_name)
OPTIONAL MATCH (a:Author)-[ra:AUTHORED]->(p)
RETURN 
  p.paper_id,
  p.title,
  COALESCE(p.abstract, '') as abstract,
  COALESCE(p.year, 0) as year,
  COALESCE(p.n_citation, 0) as citations,
  COALESCE(p.venue, '') as venue,
  COALESCE(p.doi, '') as doi,
  f.name as field,
  collect(DISTINCT a.name)[0..5] as top_authors
ORDER BY COALESCE(p.n_citation, 0) DESC
LIMIT 50
```
å‚æ•°ï¼š`{"field_name": "deep learning"}`

### ç¤ºä¾‹4.1ï¼šé¢†åŸŸæ£€ç´¢ + æ—¶é—´ä¸å¼•ç”¨è¿‡æ»¤
```cypher
MATCH (f:FieldOfStudy)<-[r:BELONGS_TO_FIELD]-(p:Paper)
WHERE toLower(f.name) CONTAINS toLower($field_name)
  AND COALESCE(p.year, 0) >= $start_year
  AND COALESCE(p.n_citation, 0) >= $min_citations
RETURN 
  p.paper_id, 
  p.title, 
  COALESCE(p.year, 0) as year, 
  COALESCE(p.n_citation, 0) as citations, 
  f.name as field
ORDER BY COALESCE(p.n_citation, 0) DESC
LIMIT 30
```
å‚æ•°ï¼š`{"field_name": "deep learning", "start_year": 2020, "min_citations": 50}`

### ç¤ºä¾‹5ï¼šæŸ¥æ‰¾æŸä½œè€…çš„åˆä½œè€…ç½‘ç»œ
```cypher
MATCH (a1:Author)-[r:COLLABORATED]-(a2:Author)
WHERE toLower(a1.name) CONTAINS toLower($author_name)
RETURN 
  a2.name, 
  a2.org, 
  a2.total_papers
ORDER BY a2.total_papers DESC
LIMIT 20
```
å‚æ•°ï¼š`{"author_name": "Andrew Ng"}`

### ç¤ºä¾‹6ï¼šğŸ”¥ é€šè¿‡å¼•ç”¨æ–‡çŒ®æ ‡é¢˜åå‘æŸ¥æ‰¾å¼•ç”¨å®ƒçš„è®ºæ–‡
```cypher
MATCH (p:Paper)-[r:CITED]->(ref:Reference)
WHERE toLower(ref.title) CONTAINS toLower($ref_title)
RETURN 
  p.paper_id,
  p.title,
  COALESCE(p.year, 0) as year,
  COALESCE(p.n_citation, 0) as citations,
  ref.title as cited_title,
  ref.authors as cited_authors,
  ref.year as cited_year
ORDER BY COALESCE(p.year, 0) DESC
LIMIT 20
```
å‚æ•°ï¼š`{"ref_title": "deep learning"}`
ğŸ’¡ **è¯´æ˜**ï¼šæŸ¥æ‰¾å¼•ç”¨äº†æ ‡é¢˜ä¸­åŒ…å«"deep learning"çš„æ–‡çŒ®çš„æ‰€æœ‰è®ºæ–‡

### ç¤ºä¾‹7ï¼šæŸ¥æ‰¾æŸè®ºæ–‡çš„ä½œè€…åŠå…¶æœºæ„
```cypher
MATCH (a:Author)-[r:AUTHORED]->(p:Paper)
WHERE p.paper_id = $paper_id AND r.position = $position
RETURN 
  a.name, 
  a.org, 
  a.total_papers,
  p.title
ORDER BY a.total_papers DESC
```
å‚æ•°ï¼š`{"paper_id": "xyz789", "position": "first"}`

### ç¤ºä¾‹8ï¼šæŸ¥æ‰¾æŸä¼šè®®çš„æ‰€æœ‰è®ºæ–‡
```cypher
MATCH (p:Paper)-[r:PUBLISHED_IN]->(v:Venue)
WHERE toLower(v.name) CONTAINS toLower($venue_name)
  AND COALESCE(p.year, 0) >= $start_year 
  AND COALESCE(p.year, 0) <= $end_year
RETURN 
  p.paper_id, 
  p.title, 
  COALESCE(p.year, 0) as year, 
  COALESCE(p.n_citation, 0) as citations,
  v.name as venue_name
ORDER BY COALESCE(p.year, 0) DESC, COALESCE(p.n_citation, 0) DESC
LIMIT 50
```
å‚æ•°ï¼š`{"venue_name": "NeurIPS", "start_year": 2020, "end_year": 2024}`

### ç¤ºä¾‹9ï¼šğŸ”¥ å¤æ‚äº¤å‰æŸ¥è¯¢ - æŸé¢†åŸŸä¸­æŸä½œè€…çš„é«˜è¢«å¼•è®ºæ–‡ï¼ˆå±•ç¤ºäº¤å‰èƒ½åŠ›ï¼‰
```cypher
MATCH path = (a:Author)-[:AUTHORED]->(p:Paper)-[:BELONGS_TO_FIELD]->(f:FieldOfStudy)
WHERE toLower(a.name) CONTAINS toLower($author_name)
  AND toLower(f.name) CONTAINS toLower($field_name)
  AND COALESCE(p.n_citation, 0) >= $min_citations
RETURN 
  p.paper_id, 
  p.title, 
  COALESCE(p.year, 0) as year, 
  COALESCE(p.n_citation, 0) as citations, 
  a.name as author,
  f.name as field
ORDER BY COALESCE(p.n_citation, 0) DESC
LIMIT 10
```
å‚æ•°ï¼š`{"author_name": "Yoshua Bengio", "field_name": "neural networks", "min_citations": 100}`
ğŸ’¡ **è¯´æ˜**ï¼šè¿™æ˜¯å…¸å‹çš„**äº¤å‰æŸ¥è¯¢**ï¼ŒåŒæ—¶è¿‡æ»¤ä½œè€…ã€é¢†åŸŸã€å¼•ç”¨æ•°ä¸‰ä¸ªç»´åº¦

### ç¤ºä¾‹10ï¼šè·å–è®ºæ–‡çš„å®Œæ•´å‡ºç‰ˆå…ƒæ•°æ®
```cypher
MATCH (p:Paper)
WHERE p.paper_id = $paper_id
OPTIONAL MATCH (p)-[rv:PUBLISHED_IN]->(v:Venue)
OPTIONAL MATCH (a:Author)-[ra:AUTHORED]->(p)
RETURN 
  p.paper_id,
  p.title,
  COALESCE(p.abstract, '') as abstract,
  COALESCE(p.year, 0) as year,
  COALESCE(p.venue, v.name, '') as venue,
  COALESCE(p.volume, '') as volume,
  COALESCE(p.issue, '') as issue,
  COALESCE(p.page_start, '') as page_start,
  COALESCE(p.page_end, '') as page_end,
  COALESCE(p.doi, '') as doi,
  COALESCE(p.publisher, '') as publisher,
  COALESCE(p.doc_type, '') as doc_type,
  COALESCE(p.n_citation, 0) as citations,
  collect(DISTINCT a.name) as authors
LIMIT 1
```
å‚æ•°ï¼š`{"paper_id": "abc123"}`

---

## âš ï¸ å¼ºåˆ¶è§„åˆ™ä¸æœ€ä½³å®è·µ

### ğŸš¨ å¼ºåˆ¶è§„åˆ™ï¼ˆè¿åä¼šè¢«æ‹’ç»ï¼‰

1. **ğŸ”´ å¿…é¡»åŒ…å« LIMIT**ï¼šæ¯ä¸ªæŸ¥è¯¢å¿…é¡»æœ‰ LIMIT å­å¥ï¼ˆæœ€å¤§100ï¼‰
   - âœ… `RETURN ... LIMIT 20`
   - âŒ `RETURN ...`ï¼ˆä¼šè¢«æ‹’ç»ï¼‰

2. **åªå…è®¸åªè¯»æŸ¥è¯¢**ï¼šç¦æ­¢ CREATE, DELETE, SET ç­‰ä¿®æ”¹æ“ä½œ

3. **å‚æ•°åŒ–æŸ¥è¯¢**ï¼šç”¨æˆ·è¾“å…¥å¿…é¡»é€šè¿‡ `$param` ä¼ é€’ï¼ˆé˜²æ­¢æ³¨å…¥ï¼‰

### ğŸ’¡ æœ€ä½³å®è·µ

4. **ğŸ”¥ NULLå€¼å¤„ç†ï¼ˆé‡è¦ï¼‰**ï¼š
   - âš ï¸ æ•°æ®ä¸­å­˜åœ¨NULLå€¼ï¼ˆå¦‚ `year`, `n_citation`, `abstract`ï¼‰
   - âœ… æ’åºæ—¶ï¼š`ORDER BY COALESCE(p.n_citation, 0) DESC`
   - âœ… è¿‡æ»¤æ—¶ï¼š`WHERE COALESCE(p.year, 0) >= 2020`
   - âœ… è¿”å›æ—¶ï¼š`RETURN COALESCE(p.abstract, '') as abstract`
   - âŒ é”™è¯¯ï¼š`ORDER BY p.n_citation DESC`ï¼ˆNULLæ’åºå¼‚å¸¸ï¼‰

5. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨ç´¢å¼•å­—æ®µï¼ˆ`paper_id`, `author_id`ï¼‰
   - é¿å…è¿‡å¤§çš„ LIMITï¼ˆå»ºè®® â‰¤ 50ï¼‰
   - å¤šè·³æŸ¥è¯¢é™åˆ¶æ·±åº¦ï¼ˆå¦‚ `-[:CITED*1..3]->`ï¼‰

---

## ğŸš€ å·¥å…·èƒ½åŠ›ä¸Šé™

### âœ… æ”¯æŒçš„èƒ½åŠ›

| èƒ½åŠ› | è¯´æ˜ | ç¤ºä¾‹ |
|-----|------|------|
| **å•ç»´åº¦æŸ¥è¯¢** | æŒ‰å•ä¸ªæ¡ä»¶æŸ¥æ‰¾ | æŸ¥æ‰¾æŸä½œè€…çš„æ‰€æœ‰è®ºæ–‡ |
| **ğŸ”¥ äº¤å‰æŸ¥è¯¢** | ç»„åˆå¤šä¸ªæ¡ä»¶ï¼ˆæ— é™åˆ¶ï¼‰ | æŸé¢†åŸŸ + æŸä½œè€… + æŸå¹´ä»½ + æœ€å°å¼•ç”¨æ•° |
| **å›¾éå†** | å¤šè·³å…³ç³»æŸ¥è¯¢ | å¼•ç”¨é“¾ï¼ˆ`-[:CITED*1..3]->`ï¼‰ã€åˆä½œç½‘ç»œ |
| **åå‘æŸ¥è¯¢** | é€šè¿‡è¢«å¼•æ–‡çŒ®æ‰¾è®ºæ–‡ | æŸ¥æ‰¾å¼•ç”¨äº†æŸæ–‡çŒ®çš„æ‰€æœ‰è®ºæ–‡ |
| **èšåˆç»Ÿè®¡** | countã€collectã€avg ç­‰ | æŸä½œè€…çš„è®ºæ–‡æ€»æ•°ã€æŸé¢†åŸŸçš„å¹³å‡å¼•ç”¨æ•° |
| **å¤æ‚è¿‡æ»¤** | ä»»æ„ WHERE æ¡ä»¶ç»„åˆ | å¹´ä»½èŒƒå›´ + å¼•ç”¨æ•°é˜ˆå€¼ + é¢†åŸŸåŒ¹é… |

### âš ï¸ é™åˆ¶

- **æ•°æ®é‡é™åˆ¶**ï¼šå•æ¬¡æŸ¥è¯¢æœ€å¤šè¿”å› 100 æ¡è®°å½•ï¼ˆLIMIT 100ï¼‰
- **è¶…æ—¶é™åˆ¶**ï¼šæŸ¥è¯¢è¶…è¿‡ 30 ç§’ä¼šè¢«ä¸­æ–­
- **åªè¯»é™åˆ¶**ï¼šä¸èƒ½ä¿®æ”¹å›¾è°±æ•°æ®

### ğŸ¯ äº¤å‰æŸ¥è¯¢ç¤ºä¾‹

**æ”¯æŒä»»æ„ç»´åº¦ç»„åˆ**ï¼š
```cypher
-- 5ç»´äº¤å‰ï¼šä½œè€… + é¢†åŸŸ + ä¼šè®® + å¹´ä»½ + å¼•ç”¨æ•°
MATCH (a:Author)-[:AUTHORED]->(p:Paper)-[:BELONGS_TO_FIELD]->(f:FieldOfStudy),
      (p)-[:PUBLISHED_IN]->(v:Venue)
WHERE toLower(a.name) CONTAINS 'hinton'
  AND toLower(f.name) CONTAINS 'deep learning'
  AND toLower(v.name) CONTAINS 'neurips'
  AND COALESCE(p.year, 0) >= 2020
  AND COALESCE(p.n_citation, 0) >= 100
RETURN p.title, p.year, p.n_citation
ORDER BY COALESCE(p.n_citation, 0) DESC
LIMIT 20
```

---

## ğŸ’­ ä½•æ—¶ä½¿ç”¨æ­¤å·¥å…·ï¼Ÿ

- âœ… ç”¨æˆ·è¯¢é—®**ç‰¹å®šä½œè€…/é¢†åŸŸ/ä¼šè®®**çš„è®ºæ–‡
- âœ… éœ€è¦**ç»„åˆå¤šä¸ªæ¡ä»¶**è¿‡æ»¤ï¼ˆäº¤å‰æŸ¥è¯¢ï¼‰
- âœ… éœ€è¦**å›¾è°±éå†**ï¼ˆå¼•ç”¨é“¾ã€åˆä½œç½‘ç»œï¼‰
- âœ… éœ€è¦**èšåˆç»Ÿè®¡**ï¼ˆè®ºæ–‡æ•°ã€å¹³å‡å¼•ç”¨æ•°ï¼‰
- âœ… ä»»ä½•**å‘é‡æ£€ç´¢æ— æ³•æ»¡è¶³**çš„ç»“æ„åŒ–æŸ¥è¯¢éœ€æ±‚
        """.strip()
        
        input_schema = {
            "type": "object",
            "properties": {
                "cypher_query": {
                    "type": "string",
                    "description": "CypheræŸ¥è¯¢è¯­å¥ï¼ˆåªè¯»æŸ¥è¯¢ï¼Œå¿…é¡»åŒ…å«LIMITï¼‰"
                },
                "query_parameters": {
                    "type": "object",
                    "description": "æŸ¥è¯¢å‚æ•°ï¼ˆå¦‚ {\"author_name\": \"Yann LeCun\"}ï¼‰",
                    "additionalProperties": True
                },
                "intent_description": {
                    "type": "string",
                    "description": "æŸ¥è¯¢æ„å›¾æè¿°ï¼ˆä¸€å¥è¯è¯´æ˜æŸ¥è¯¢ç›®çš„ï¼Œç”¨äºæ—¥å¿—ï¼‰"
                },
                "max_results": {
                    "type": "integer",
                    "description": "æœ€å¤§è¿”å›ç»“æœæ•°ï¼ˆé»˜è®¤50ï¼Œæœ€å¤§100ï¼‰",
                    "minimum": 1,
                    "maximum": 100,
                    "default": 50
                }
            },
            "required": ["cypher_query", "intent_description"]
        }
        
        return ToolMetadata(
            name="flexible_graph_query",
            description=description,
            input_schema=input_schema
        )
    
    async def execute(self, arguments: Dict[str, Any], context: ToolContext) -> str:
        """
        æ‰§è¡Œçµæ´»çš„å›¾è°±æŸ¥è¯¢
        
        Args:
            arguments: åŒ…å« cypher_query, query_parameters, intent_description
            context: å·¥å…·ä¸Šä¸‹æ–‡
        
        Returns:
            JSONæ ¼å¼çš„æŸ¥è¯¢ç»“æœ
        """
        # æ£€æŸ¥å¯ç”¨æ€§
        available, reason = self._check_availability()
        if not available:
            return json.dumps({
                "success": False,
                "error": f"çŸ¥è¯†å›¾è°±æŸ¥è¯¢ä¸å¯ç”¨: {reason}",
                "results": []
            }, ensure_ascii=False)
        
        # è§£æå‚æ•°
        cypher_query = arguments.get("cypher_query", "").strip()
        query_parameters = arguments.get("query_parameters", {})
        intent_description = arguments.get("intent_description", "æœªçŸ¥æ„å›¾")
        max_results = arguments.get("max_results", 50)
        
        logger.info(f"ğŸ” çµæ´»å›¾è°±æŸ¥è¯¢: {intent_description}")
        logger.debug(f"ğŸ“ Cypher: {cypher_query[:200]}...")
        logger.debug(f"ğŸ“Š å‚æ•°: {query_parameters}")
        
        # å®‰å…¨éªŒè¯
        is_safe, error_msg = self._validate_query_safety(cypher_query)
        if not is_safe:
            logger.warning(f"âš ï¸ æŸ¥è¯¢è¢«æ‹’ç»: {error_msg}")
            return json.dumps({
                "success": False,
                "error": f"æŸ¥è¯¢å®‰å…¨éªŒè¯å¤±è´¥: {error_msg}",
                "results": []
            }, ensure_ascii=False)
        
        try:
            # ğŸ”¥ æ–°æ¶æ„ï¼šä½¿ç”¨è§£è€¦çš„æŸ¥è¯¢æ–¹æ³•
            # 1. æ¨¡å‹æŸ¥è¯¢åŸæ ·æ‰§è¡Œï¼ˆä¸è¢«ç¯¡æ”¹ï¼‰
            # 2. å›¾è°±æ•°æ®ç‹¬ç«‹æå–ï¼ˆä¸å½±å“æ¨¡å‹ï¼‰
            query_results, graph_data = self.neo4j_client.execute_query_with_graph(
                cypher_query,
                query_parameters,
                extract_graph_from_ids=True
            )
            
            # é™åˆ¶è¿”å›æ•°é‡
            if len(query_results) > max_results:
                query_results = query_results[:max_results]
                logger.info(f"âš ï¸ ç»“æœè¢«æˆªæ–­: {len(query_results)} -> {max_results}")
            
            # æ ¼å¼åŒ–å“åº”ï¼ˆç»™ LLM çš„æ•°æ®ï¼‰
            return self._format_response(
                results=query_results,
                intent=intent_description,
                context=context,
                graph_data=graph_data  # å•ç‹¬ä¼ é€’å›¾è°±æ•°æ®
            )
        
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return json.dumps({
                "success": False,
                "error": f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}",
                "results": [],
                "suggestion": "è¯·æ£€æŸ¥Cypherè¯­æ³•æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•ç®€åŒ–æŸ¥è¯¢"
            }, ensure_ascii=False)
    
    def _validate_query_safety(self, cypher_query: str) -> tuple[bool, str]:
        """
        éªŒè¯æŸ¥è¯¢å®‰å…¨æ€§
        
        Returns:
            (æ˜¯å¦å®‰å…¨, é”™è¯¯ä¿¡æ¯)
        """
        # 1. è½¬æ¢ä¸ºå¤§å†™ä¾¿äºæ£€æŸ¥
        query_upper = cypher_query.upper()
        
        # 2. æ£€æŸ¥æ˜¯å¦åŒ…å«å±é™©æ“ä½œ
        for forbidden in self.FORBIDDEN_KEYWORDS:
            if re.search(r'\b' + forbidden + r'\b', query_upper):
                return False, f"ç¦æ­¢ä½¿ç”¨ {forbidden} æ“ä½œï¼ˆåªå…è®¸åªè¯»æŸ¥è¯¢ï¼‰"
        
        # 3. æ£€æŸ¥æ˜¯å¦åŒ…å« LIMITï¼ˆé˜²æ­¢è¿”å›è¿‡å¤šæ•°æ®ï¼‰
        if "LIMIT" not in query_upper:
            return False, "æŸ¥è¯¢å¿…é¡»åŒ…å« LIMIT å­å¥ï¼ˆé˜²æ­¢è¿”å›è¿‡å¤šæ•°æ®ï¼‰"
        
        # 4. æ£€æŸ¥ LIMIT å€¼æ˜¯å¦åˆç†
        limit_match = re.search(r'LIMIT\s+(\d+)', query_upper)
        if limit_match:
            limit_value = int(limit_match.group(1))
            if limit_value > 100:
                return False, f"LIMIT å€¼è¿‡å¤§ï¼ˆ{limit_value}ï¼‰ï¼Œæœ€å¤§å…è®¸100"
        
        # 5. æ£€æŸ¥æ˜¯å¦åªåŒ…å« MATCH/OPTIONAL MATCH/WHERE/RETURN ç­‰åªè¯»æ“ä½œ
        if not any(keyword in query_upper for keyword in ["MATCH", "RETURN"]):
            return False, "æŸ¥è¯¢å¿…é¡»åŒ…å« MATCH å’Œ RETURN å­å¥"
        
        return True, ""
    
    def _build_graph_visualization(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ğŸ”¥ å®Œå…¨åŸºäº _graph å­—æ®µæ„å»ºå¯è§†åŒ–ï¼ˆä¸å†ç¡¬ç¼–ç å­—æ®µï¼‰
        
        å·¥ä½œåŸç†ï¼š
        1. neo4j_client è‡ªåŠ¨ä»æŸ¥è¯¢è·¯å¾„ä¸­æå–æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»ï¼ˆ_graphå­—æ®µï¼‰
        2. æœ¬æ–¹æ³•åªè´Ÿè´£å°† Neo4j èŠ‚ç‚¹/å…³ç³»è½¬æ¢ä¸ºå‰ç«¯å¯è§†åŒ–æ ¼å¼
        3. æ— è®º LLM æ„å»ºä»€ä¹ˆæŸ¥è¯¢ï¼Œéƒ½èƒ½æ­£ç¡®æå–å›¾è°±ç»“æ„
        
        Args:
            results: æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼ˆå¿…é¡»åŒ…å« _graph å­—æ®µï¼‰
            
        Returns:
            å›¾è°±å¯è§†åŒ–æ•°æ® {nodes: [...], edges: [...]}
        """
        nodes = []
        edges = []
        node_ids = set()  # ç”¨äºå»é‡ï¼ˆNeo4j å†…éƒ¨ IDï¼‰
        edge_ids = set()  # è¾¹å»é‡
        node_id_map = {}  # Neo4j ID -> å¯è§†åŒ– ID çš„æ˜ å°„
        
        for result in results:
            # ğŸ”¥ ä» _graph ä¸­æå–èŠ‚ç‚¹å’Œå…³ç³»ï¼ˆç”± neo4j_client è‡ªåŠ¨ç”Ÿæˆï¼‰
            graph_data = result.get("_graph", {})
            graph_nodes = graph_data.get("nodes", [])
            graph_rels = graph_data.get("relationships", [])
            
            # å¤„ç†èŠ‚ç‚¹
            for node_data in graph_nodes:
                neo4j_id = node_data.get("_neo4j_id")
                if not neo4j_id or neo4j_id in node_ids:
                    continue
                
                labels = node_data.get("_labels", [])
                
                # æ ¹æ®èŠ‚ç‚¹ç±»å‹åˆ›å»ºå¯è§†åŒ–èŠ‚ç‚¹
                if "Author" in labels:
                    name = node_data.get("name", "æœªçŸ¥ä½œè€…")
                    viz_id = f"author_{neo4j_id}"
                    nodes.append({
                        "id": viz_id,
                        "type": "author",
                        "label": name,
                        "data": {
                            "name": name,
                            "h_index": node_data.get("h_index"),
                            "n_citation": node_data.get("n_citation"),
                            "n_pubs": node_data.get("n_pubs")
                        }
                    })
                    node_id_map[neo4j_id] = viz_id
                    node_ids.add(neo4j_id)
                
                elif "Paper" in labels:
                    title = node_data.get("title", "æœªçŸ¥è®ºæ–‡")
                    paper_id = node_data.get("paper_id", f"paper_{neo4j_id}")
                    viz_id = f"paper_{paper_id}"
                    nodes.append({
                        "id": viz_id,
                        "type": "paper",
                        "label": title[:50] + "..." if len(title) > 50 else title,
                        "data": {
                            "paper_id": paper_id,
                            "title": title,
                            "year": node_data.get("year"),
                            "citations": node_data.get("n_citation", 0),
                            "abstract": (node_data.get("abstract", ""))[:200] + "..." if node_data.get("abstract") else ""
                        }
                    })
                    node_id_map[neo4j_id] = viz_id
                    node_ids.add(neo4j_id)
                
                elif "FieldOfStudy" in labels or "Field" in labels:
                    name = node_data.get("name", "æœªçŸ¥é¢†åŸŸ")
                    viz_id = f"field_{neo4j_id}"
                    nodes.append({
                        "id": viz_id,
                        "type": "field",
                        "label": name,
                        "data": {"name": name}
                    })
                    node_id_map[neo4j_id] = viz_id
                    node_ids.add(neo4j_id)
                
                elif "Venue" in labels:
                    name = node_data.get("name", "æœªçŸ¥ä¼šè®®/æœŸåˆŠ")
                    viz_id = f"venue_{neo4j_id}"
                    nodes.append({
                        "id": viz_id,
                        "type": "venue",
                        "label": name,
                        "data": {"name": name}
                    })
                    node_id_map[neo4j_id] = viz_id
                    node_ids.add(neo4j_id)
                
                elif "Reference" in labels:
                    title = node_data.get("title", "æœªçŸ¥å¼•ç”¨æ–‡çŒ®")
                    ref_id = node_data.get("ref_id", f"ref_{neo4j_id}")
                    viz_id = f"reference_{ref_id}"
                    nodes.append({
                        "id": viz_id,
                        "type": "reference",
                        "label": title[:50] + "..." if len(title) > 50 else title,
                        "data": {
                            "ref_id": ref_id,
                            "title": title,
                            "authors": node_data.get("authors", ""),
                            "year": node_data.get("year"),
                            "venue": node_data.get("venue", "")
                        }
                    })
                    node_id_map[neo4j_id] = viz_id
                    node_ids.add(neo4j_id)
            
            # å¤„ç†å…³ç³»
            for rel_data in graph_rels:
                rel_id = rel_data.get("_neo4j_id")
                if not rel_id or rel_id in edge_ids:
                    continue
                
                rel_type = rel_data.get("_type", "RELATED")
                start_neo4j_id = rel_data.get("_start_node_id")
                end_neo4j_id = rel_data.get("_end_node_id")
                
                # æŸ¥æ‰¾å¯¹åº”çš„å¯è§†åŒ–èŠ‚ç‚¹ ID
                source_id = node_id_map.get(start_neo4j_id)
                target_id = node_id_map.get(end_neo4j_id)
                
                if not source_id or not target_id:
                    continue  # è·³è¿‡æ— æ•ˆå…³ç³»
                
                # å…³ç³»ç±»å‹ä¸­æ–‡æ ‡ç­¾
                label_map = {
                    "AUTHORED": "ä½œè€…",
                    "PUBLISHED_IN": "å‘è¡¨äº",
                    "CITED": "å¼•ç”¨",
                    "BELONGS_TO_FIELD": "é¢†åŸŸ",
                    "HAS_FIELD": "ç ”ç©¶é¢†åŸŸ",
                    "COLLABORATED": "åˆä½œ"
                }
                
                edges.append({
                    "id": f"rel_{rel_id}",
                    "source": source_id,
                    "target": target_id,
                    "type": rel_type,
                    "label": label_map.get(rel_type, rel_type)
                })
                edge_ids.add(rel_id)
        
        return {
            "nodes": nodes,
            "edges": edges,
            "metadata": {
                "total_nodes": len(nodes),
                "total_edges": len(edges),
                "node_types": {
                    "paper": sum(1 for n in nodes if n["type"] == "paper"),
                    "author": sum(1 for n in nodes if n["type"] == "author"),
                    "field": sum(1 for n in nodes if n["type"] == "field"),
                    "venue": sum(1 for n in nodes if n["type"] == "venue"),
                    "reference": sum(1 for n in nodes if n["type"] == "reference")
                }
            }
        }
    
    def _build_graph_visualization_from_graph_data(
        self,
        graph_data: Dict[str, List]
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ æ–°æ–¹æ³•ï¼šä»ç‹¬ç«‹æå–çš„å›¾è°±æ•°æ®æ„å»ºå¯è§†åŒ–
        
        Args:
            graph_data: {'nodes': [...], 'relationships': [...]}
            
        Returns:
            {'nodes': [...], 'edges': [...], 'metadata': {...}}
        """
        nodes = []
        edges = []
        node_ids = set()
        edge_ids = set()
        node_id_map = {}  # Neo4j ID -> å¯è§†åŒ– ID çš„æ˜ å°„
        
        # å¤„ç†èŠ‚ç‚¹
        for node_data in graph_data.get('nodes', []):
            neo4j_id = node_data.get("_neo4j_id")
            if not neo4j_id or neo4j_id in node_ids:
                continue
            
            labels = node_data.get("_labels", [])
            
            # æ ¹æ®èŠ‚ç‚¹ç±»å‹åˆ›å»ºå¯è§†åŒ–èŠ‚ç‚¹
            if "Author" in labels:
                name = node_data.get("name", "æœªçŸ¥ä½œè€…")
                viz_id = f"author_{neo4j_id}"
                nodes.append({
                    "id": viz_id,
                    "type": "author",
                    "label": name,
                    "data": {
                        "name": name,
                        "h_index": node_data.get("h_index"),
                        "n_citation": node_data.get("n_citation"),
                        "n_pubs": node_data.get("n_pubs")
                    }
                })
                node_id_map[neo4j_id] = viz_id
                node_ids.add(neo4j_id)
            
            elif "Paper" in labels:
                title = node_data.get("title", "æœªçŸ¥è®ºæ–‡")
                paper_id = node_data.get("paper_id", f"paper_{neo4j_id}")
                viz_id = f"paper_{paper_id}"
                nodes.append({
                    "id": viz_id,
                    "type": "paper",
                    "label": title[:50] + "..." if len(title) > 50 else title,
                    "data": {
                        "paper_id": paper_id,
                        "title": title,
                        "year": node_data.get("year"),
                        "citations": node_data.get("n_citation", 0),
                        "abstract": (node_data.get("abstract", ""))[:200] + "..." if node_data.get("abstract") else ""
                    }
                })
                node_id_map[neo4j_id] = viz_id
                node_ids.add(neo4j_id)
            
            elif "FieldOfStudy" in labels or "Field" in labels:
                name = node_data.get("name", "æœªçŸ¥é¢†åŸŸ")
                viz_id = f"field_{neo4j_id}"
                nodes.append({
                    "id": viz_id,
                    "type": "field",
                    "label": name,
                    "data": {"name": name}
                })
                node_id_map[neo4j_id] = viz_id
                node_ids.add(neo4j_id)
            
            elif "Venue" in labels:
                name = node_data.get("name", "æœªçŸ¥ä¼šè®®/æœŸåˆŠ")
                viz_id = f"venue_{neo4j_id}"
                nodes.append({
                    "id": viz_id,
                    "type": "venue",
                    "label": name,
                    "data": {"name": name}
                })
                node_id_map[neo4j_id] = viz_id
                node_ids.add(neo4j_id)
            
            elif "Reference" in labels:
                title = node_data.get("title", "æœªçŸ¥å¼•ç”¨æ–‡çŒ®")
                ref_id = node_data.get("ref_id", f"ref_{neo4j_id}")
                viz_id = f"reference_{ref_id}"
                nodes.append({
                    "id": viz_id,
                    "type": "reference",
                    "label": title[:50] + "..." if len(title) > 50 else title,
                    "data": {
                        "ref_id": ref_id,
                        "title": title,
                        "authors": node_data.get("authors", ""),
                        "year": node_data.get("year"),
                        "venue": node_data.get("venue", "")
                    }
                })
                node_id_map[neo4j_id] = viz_id
                node_ids.add(neo4j_id)
        
        # å¤„ç†å…³ç³»
        for rel_data in graph_data.get('relationships', []):
            rel_id = rel_data.get("_neo4j_id")
            if not rel_id or rel_id in edge_ids:
                continue
            
            rel_type = rel_data.get("_type", "RELATED")
            start_neo4j_id = rel_data.get("_start_node_id")
            end_neo4j_id = rel_data.get("_end_node_id")
            
            # æŸ¥æ‰¾å¯¹åº”çš„å¯è§†åŒ–èŠ‚ç‚¹ ID
            source_id = node_id_map.get(start_neo4j_id)
            target_id = node_id_map.get(end_neo4j_id)
            
            if not source_id or not target_id:
                continue  # è·³è¿‡æ— æ•ˆå…³ç³»
            
            # å…³ç³»ç±»å‹ä¸­æ–‡æ ‡ç­¾
            label_map = {
                "AUTHORED": "ä½œè€…",
                "PUBLISHED_IN": "å‘è¡¨äº",
                "CITED": "å¼•ç”¨",
                "BELONGS_TO_FIELD": "é¢†åŸŸ",
                "HAS_FIELD": "ç ”ç©¶é¢†åŸŸ",
                "COLLABORATED": "åˆä½œ"
            }
            
            edges.append({
                "id": f"rel_{rel_id}",
                "source": source_id,
                "target": target_id,
                "type": rel_type,
                "label": label_map.get(rel_type, rel_type)
            })
            edge_ids.add(rel_id)
        
        return {
            "nodes": nodes,
            "edges": edges,
            "metadata": {
                "total_nodes": len(nodes),
                "total_edges": len(edges),
                "node_types": {
                    "paper": sum(1 for n in nodes if n["type"] == "paper"),
                    "author": sum(1 for n in nodes if n["type"] == "author"),
                    "field": sum(1 for n in nodes if n["type"] == "field"),
                    "venue": sum(1 for n in nodes if n["type"] == "venue"),
                    "reference": sum(1 for n in nodes if n["type"] == "reference")
                }
            }
        }
    
    def _format_response(
        self,
        results: List[Dict[str, Any]],
        intent: str,
        context: ToolContext,
        graph_data: Dict[str, List] = None
    ) -> str:
        """
        æ ¼å¼åŒ–æŸ¥è¯¢å“åº”
        
        Args:
            results: æŸ¥è¯¢ç»“æœï¼ˆæ¨¡å‹æ•°æ®ï¼Œå®Œå…¨æŒ‰ç…§ RETURN å­å¥ï¼‰
            intent: æŸ¥è¯¢æ„å›¾æè¿°
            context: å·¥å…·ä¸Šä¸‹æ–‡
            graph_data: å›¾è°±å¯è§†åŒ–æ•°æ®ï¼ˆç‹¬ç«‹æå–ï¼Œä¸å½±å“æ¨¡å‹ï¼‰
        """
        # å¯¼å…¥å…¨å±€åºå·ç®¡ç†å™¨ï¼ˆä¸å…¶ä»–æ£€ç´¢å·¥å…·å…±äº«ï¼‰
        from .knowledge_retrieval import GlobalReferenceMarkerManager
        marker_manager = GlobalReferenceMarkerManager()
        
        # æ ¼å¼åŒ–æ¯ä¸ªç»“æœ
        formatted_results = []
        for idx, result in enumerate(results, 1):
            # åˆ†é…å…¨å±€å”¯ä¸€åºå·
            global_marker = marker_manager.get_next_marker(context.session_id)
            
            # ğŸ”¥ æ–°æ¶æ„ï¼šæ•°æ®å·²ç»æ˜¯å¹²å‡€çš„ï¼ˆä¸åŒ…å«ä»»ä½•å›¾è°±ç»“æ„ï¼‰
            # æ— éœ€è¿‡æ»¤ï¼Œç›´æ¥ä½¿ç”¨
            
            # æ„å»ºæ ¼å¼åŒ–ç»“æœ
            formatted_item = {
                "index": idx,
                "ref_marker": global_marker,
                "data": result,  # âœ… åªåŒ…å«ä¸šåŠ¡æ•°æ®ï¼Œå®Œå…¨æŒ‰ç…§ RETURN å­å¥
                "source": "flexible_graph_query"
            }
            
            formatted_results.append(formatted_item)
        
        # ğŸ¨ æ„å»ºå›¾è°±å¯è§†åŒ–æ•°æ®ï¼ˆèŠ‚ç‚¹+è¾¹æ ¼å¼ï¼‰
        # ğŸ”¥ æ–°æ¶æ„ï¼šä½¿ç”¨ç‹¬ç«‹æå–çš„å›¾è°±æ•°æ®
        if graph_data:
            graph_visualization = self._build_graph_visualization_from_graph_data(graph_data)
        else:
            graph_visualization = {
                "nodes": [],
                "edges": [],
                "metadata": {"total_nodes": 0, "total_edges": 0, "node_types": {}}
            }
        
        # ğŸ”¥ æ ¸å¿ƒè§£è€¦ï¼šå°†å¯è§†åŒ–æ•°æ®å­˜å‚¨åˆ°Redisï¼ˆä¸è¿”å›ç»™LLMï¼ŒèŠ‚çœtokenï¼‰
        # streaming_managerä¼šåœ¨æµå¼å“åº”ç»“æŸåä»Redisæå–å¹¶å‘é€ç»™å‰ç«¯
        try:
            import asyncio
            from app.redis_client import get_redis
            from app.utils.llm.graph_viz_cache import GraphVisualizationCache
            
            # åŒæ­¥ç¯å¢ƒä¸­è°ƒç”¨å¼‚æ­¥å‡½æ•°
            async def store_viz():
                redis = await get_redis()
                await GraphVisualizationCache.store_visualization(
                    redis=redis,
                    session_id=context.session_id,
                    visualization_data=graph_visualization
                )
            
            # å°è¯•åœ¨å½“å‰äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œåˆ›å»ºä»»åŠ¡
                    asyncio.create_task(store_viz())
                else:
                    # å¦‚æœäº‹ä»¶å¾ªç¯æœªè¿è¡Œï¼Œç›´æ¥è¿è¡Œ
                    loop.run_until_complete(store_viz())
            except RuntimeError:
                # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                asyncio.run(store_viz())
            
            logger.info(f"âœ… å›¾è°±å¯è§†åŒ–æ•°æ®å·²å­˜å‚¨åˆ°Redis: session={context.session_id}, "
                       f"èŠ‚ç‚¹={len(graph_visualization['nodes'])}, è¾¹={len(graph_visualization['edges'])}")
        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨å›¾è°±å¯è§†åŒ–æ•°æ®åˆ°Rediså¤±è´¥ï¼ˆç»§ç»­æ‰§è¡Œï¼‰: {e}", exc_info=True)
        
        response = {
            "success": True,
            "total": len(formatted_results),
            "intent": intent,
            "results": formatted_results,
            "explanation": f"çµæ´»å›¾è°±æŸ¥è¯¢å®Œæˆï¼ˆ{intent}ï¼‰ï¼Œè¿”å› {len(formatted_results)} ä¸ªç»“æœ",
            # âœ… æ·»åŠ  graph_metadataï¼ˆç”¨äºå‰ç«¯è¯†åˆ«éœ€è¦æ¸²æŸ“å›¾è°±ï¼‰
            "graph_metadata": {
                "total_nodes": len(graph_visualization['nodes']),
                "total_edges": len(graph_visualization['edges']),
                "node_types": graph_visualization['metadata']['node_types']
            }
        }
        
        logger.info(f"âœ… çµæ´»å›¾è°±æŸ¥è¯¢å®Œæˆ: {len(formatted_results)} ä¸ªç»“æœ, "
                   f"{len(graph_visualization['nodes'])} ä¸ªèŠ‚ç‚¹, å¯è§†åŒ–æ•°æ®å·²ç¼“å­˜åˆ°Redis")
        
        return json.dumps(response, ensure_ascii=False, indent=2)

