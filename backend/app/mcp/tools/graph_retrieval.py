"""
çŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·ï¼ˆç‹¬ç«‹å·¥å…·ï¼Œä¸ä¾èµ–å‘é‡æ£€ç´¢ï¼‰

æ”¯æŒä¸¤ç§æ£€ç´¢æ¨¡å¼ï¼š
1. åŸºäºè®ºæ–‡IDæ‰©å±•ï¼šç»™å®šè®ºæ–‡IDï¼Œé€šè¿‡å¼•ç”¨é“¾/ä½œè€…/é¢†åŸŸæ‰©å±•ç›¸å…³è®ºæ–‡
2. ç›´æ¥å›¾è°±æœç´¢ï¼šé€šè¿‡ä½œè€…åã€é¢†åŸŸåã€å…³é”®è¯ç›´æ¥æœç´¢å›¾è°±

æ³¨æ„ï¼š
- ç‹¬ç«‹äºå‘é‡æ£€ç´¢å·¥å…·ï¼ˆknowledge_retrievalï¼‰
- ä»…å½“ Neo4j è¿æ¥å¯ç”¨æ—¶æ‰å¯ç”¨
- æ¨¡å‹å¯ä»¥æ ¹æ®éœ€æ±‚è‡ªä¸»å†³å®šæ˜¯å¦è°ƒç”¨æ­¤å·¥å…·
"""
from typing import Dict, Any, List, Optional
import json
import logging
from ..base import BaseTool, ToolMetadata, ToolContext, ToolExecutionError
from ...config import settings
from ...knowledge_graph.neo4j_client import get_client as get_neo4j_client, is_neo4j_available

logger = logging.getLogger(__name__)


class GraphRetrievalTool(BaseTool):
    """çŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·ï¼ˆç‹¬ç«‹å·¥å…·ï¼‰"""
    
    def __init__(self):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·"""
        self.neo4j_client = get_neo4j_client()
    
    def _check_availability(self) -> tuple[bool, str]:
        """
        æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨
        
        Returns:
            (æ˜¯å¦å¯ç”¨, åŸå› è¯´æ˜)
        """
        # 1. æ£€æŸ¥ Neo4j åº“æ˜¯å¦å®‰è£…
        if not is_neo4j_available():
            return False, "neo4jåº“æœªå®‰è£…ï¼ˆå¯é€‰åŠŸèƒ½ï¼Œå®‰è£…æ–¹å¼: pip install neo4jï¼‰"
        
        # 2. æ£€æŸ¥ Neo4j æ˜¯å¦è¿æ¥
        if not self.neo4j_client.is_connected():
            return False, "çŸ¥è¯†å›¾è°±æœªè¿æ¥ï¼ˆè¯·åœ¨é…ç½®ä¸­è®¾ç½® NEO4J_PASSWORDï¼‰"
        
        return True, "å¯ç”¨"
    
    def get_metadata(self, context: Optional[ToolContext] = None) -> Optional[ToolMetadata]:
        """
        è·å–å·¥å…·å…ƒæ•°æ®ï¼ˆåŠ¨æ€ç”Ÿæˆï¼‰
        
        Returns:
            ToolMetadata: å·¥å…·å…ƒæ•°æ®ï¼Œå¦‚æœä¸å¯ç”¨åˆ™è¿”å› None
        """
        # æ£€æŸ¥å¯ç”¨æ€§
        available, reason = self._check_availability()
        if not available:
            logger.debug(f"ğŸš« çŸ¥è¯†å›¾è°±æ£€ç´¢å·¥å…·ä¸å¯ç”¨: {reason}")
            return None
        
        # æ„å»ºå·¥å…·æè¿°
        description = """
            ä»çŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢å­¦æœ¯è®ºæ–‡ä¿¡æ¯ï¼ˆç‹¬ç«‹äºå‘é‡æ£€ç´¢ï¼‰ã€‚

            ğŸ” ä¸¤ç§æ£€ç´¢æ¨¡å¼ï¼š

            **æ¨¡å¼1: åŸºäºè®ºæ–‡IDæ‰©å±•**ï¼ˆé€‚åˆåœ¨å·²çŸ¥è®ºæ–‡IDåæ‰©å±•ä¸Šä¸‹æ–‡ï¼‰
            - æä¾› `paper_ids` å‚æ•°
            - é€šè¿‡å¼•ç”¨é“¾/ä½œè€…/é¢†åŸŸæ‰©å±•ç›¸å…³è®ºæ–‡
            - ä¾‹ï¼šæ‰¾åˆ°è®ºæ–‡Açš„æ‰€æœ‰å¼•ç”¨ã€åŒä½œè€…çš„å…¶ä»–è®ºæ–‡

            **æ¨¡å¼2: ç›´æ¥å›¾è°±æœç´¢**ï¼ˆé€‚åˆç›´æ¥æœç´¢ä½œè€…ã€é¢†åŸŸã€å…³é”®è¯ï¼‰
            - æä¾› `search_query` å‚æ•°
            - é€šè¿‡ä½œè€…åã€é¢†åŸŸåã€æ ‡é¢˜å…³é”®è¯æœç´¢
            - ä¾‹ï¼šæ‰¾"Yann LeCun"çš„æ‰€æœ‰è®ºæ–‡ã€"æ·±åº¦å­¦ä¹ "é¢†åŸŸçš„é«˜è¢«å¼•è®ºæ–‡

            ğŸ”— æ‰©å±•ç­–ç•¥ï¼ˆç”¨äºæ¨¡å¼1ï¼‰ï¼š
            - **citation**: å¼•ç”¨é“¾æ‰©å±•ï¼ˆæ‰¾å¼•ç”¨çš„å’Œè¢«å¼•çš„è®ºæ–‡ï¼‰
            - **author**: ä½œè€…ç›¸å…³æ‰©å±•ï¼ˆæ‰¾åŒä½œè€…çš„å…¶ä»–è®ºæ–‡ï¼‰
            - **field**: é¢†åŸŸæ‰©å±•ï¼ˆæ‰¾åŒé¢†åŸŸçš„é«˜å½±å“åŠ›è®ºæ–‡ï¼‰
            - **similar**: ç›¸ä¼¼è®ºæ–‡æ‰©å±•ï¼ˆæ‰¾å…±åŒä½œè€…/å¼•ç”¨çš„è®ºæ–‡ï¼‰

            ğŸ“Š é€‚ç”¨åœºæ™¯ï¼š
            - è¿½è¸ªè®ºæ–‡çš„å­¦æœ¯è„‰ç»œå’Œå¼•ç”¨é“¾
            - äº†è§£ä½œè€…çš„ç ”ç©¶èƒŒæ™¯å’Œåˆä½œç½‘ç»œ
            - å‘ç°ç›¸å…³é¢†åŸŸçš„é«˜å½±å“åŠ›å·¥ä½œ
            - æ¢ç´¢ç ”ç©¶ä¸»é¢˜çš„æ¼”è¿›å†å²

            ğŸ’¡ æç¤ºï¼š
            - å¯ä»¥ä¸ `knowledge_retrieval` å·¥å…·é…åˆä½¿ç”¨ï¼ˆå…ˆå‘é‡æ£€ç´¢è·å– paper_idï¼Œå†å›¾è°±æ‰©å±•ï¼‰
            - ä¹Ÿå¯ä»¥ç‹¬ç«‹ä½¿ç”¨ï¼ˆç›´æ¥æœç´¢ä½œè€…ã€é¢†åŸŸï¼‰
            - è¿”å›ç»“æœåŒ…å«å¼•ç”¨æ¬¡æ•°ã€å¹´ä»½ç­‰å­¦æœ¯æŒ‡æ ‡
            """.strip()
        
        # å®šä¹‰è¾“å…¥å‚æ•°
        input_schema = {
            "type": "object",
            "properties": {
                # æ¨¡å¼1: åŸºäºè®ºæ–‡IDæ‰©å±•
                "paper_ids": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "è®ºæ–‡IDåˆ—è¡¨ï¼ˆç”¨äºæ¨¡å¼1ï¼šåŸºäºå·²çŸ¥è®ºæ–‡æ‰©å±•ï¼‰"
                },
                "expansion_strategy": {
                    "type": "string",
                    "enum": ["citation", "author", "field", "similar"],
                    "description": """
æ‰©å±•ç­–ç•¥ï¼ˆä»…æ¨¡å¼1æœ‰æ•ˆï¼‰ï¼š
- citation: å¼•ç”¨é“¾æ‰©å±•ï¼ˆæ‰¾å¼•ç”¨çš„å’Œè¢«å¼•çš„è®ºæ–‡ï¼‰
- author: ä½œè€…ç›¸å…³æ‰©å±•ï¼ˆæ‰¾åŒä½œè€…çš„å…¶ä»–è®ºæ–‡ï¼‰
- field: é¢†åŸŸæ‰©å±•ï¼ˆæ‰¾åŒé¢†åŸŸçš„é«˜å½±å“åŠ›è®ºæ–‡ï¼‰
- similar: ç›¸ä¼¼è®ºæ–‡æ‰©å±•ï¼ˆæ‰¾å…±åŒä½œè€…/å¼•ç”¨çš„è®ºæ–‡ï¼‰
""".strip(),
                    "default": "citation"
                },
                
                # æ¨¡å¼2: ç›´æ¥å›¾è°±æœç´¢
                "search_query": {
                    "type": "string",
                    "description": "æœç´¢æŸ¥è¯¢ï¼ˆç”¨äºæ¨¡å¼2ï¼šç›´æ¥æœç´¢ä½œè€…ã€é¢†åŸŸã€æ ‡é¢˜å…³é”®è¯ï¼‰"
                },
                "search_type": {
                    "type": "string",
                    "enum": ["author", "field", "title", "auto"],
                    "description": """
æœç´¢ç±»å‹ï¼ˆä»…æ¨¡å¼2æœ‰æ•ˆï¼‰ï¼š
- author: æŒ‰ä½œè€…åæœç´¢
- field: æŒ‰ç ”ç©¶é¢†åŸŸæœç´¢
- title: æŒ‰æ ‡é¢˜å…³é”®è¯æœç´¢
- auto: è‡ªåŠ¨è¯†åˆ«ï¼ˆé»˜è®¤ï¼‰
""".strip(),
                    "default": "auto"
                },
                
                # é€šç”¨å‚æ•°
                "max_results": {
                    "type": "integer",
                    "description": "æœ€å¤§è¿”å›ç»“æœæ•°ï¼ˆé»˜è®¤10ï¼ŒèŒƒå›´1-50ï¼‰",
                    "minimum": 1,
                    "maximum": 50,
                    "default": 10
                },
                "min_citations": {
                    "type": "integer",
                    "description": "æœ€å°å¼•ç”¨æ¬¡æ•°è¿‡æ»¤ï¼ˆé»˜è®¤0ï¼Œä¸è¿‡æ»¤ï¼‰",
                    "minimum": 0,
                    "default": 0
                },
                "year_range": {
                    "type": "object",
                    "properties": {
                        "start": {"type": "integer", "description": "èµ·å§‹å¹´ä»½"},
                        "end": {"type": "integer", "description": "ç»“æŸå¹´ä»½"}
                    },
                    "description": "å¹´ä»½èŒƒå›´è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰"
                }
            },
            "oneOf": [
                {"required": ["paper_ids"]},
                {"required": ["search_query"]}
            ]
        }
        
        return ToolMetadata(
            name="graph_search_knowledge",
            description=description,
            input_schema=input_schema
        )
    
    async def execute(self, arguments: Dict[str, Any], context: ToolContext) -> str:
        """
        æ‰§è¡ŒçŸ¥è¯†å›¾è°±æ£€ç´¢
        
        Args:
            arguments: å¯ä»¥åŒ…å«ä»¥ä¸‹å‚æ•°ç»„åˆï¼š
                - æ¨¡å¼1: {"paper_ids": [...], "expansion_strategy": "citation"}
                - æ¨¡å¼2: {"search_query": "...", "search_type": "author"}
            context: å·¥å…·ä¸Šä¸‹æ–‡
        
        Returns:
            str: JSON æ ¼å¼çš„æ£€ç´¢ç»“æœ
        """
        # æ£€æŸ¥å¯ç”¨æ€§
        available, reason = self._check_availability()
        if not available:
            return json.dumps({
                "success": False,
                "error": f"çŸ¥è¯†å›¾è°±æ£€ç´¢ä¸å¯ç”¨: {reason}",
                "results": []
            }, ensure_ascii=False)
        
        # è§£æå‚æ•°
        paper_ids = arguments.get("paper_ids", [])
        search_query = arguments.get("search_query", "").strip()
        max_results = arguments.get("max_results", 10)
        min_citations = arguments.get("min_citations", 0)
        year_range = arguments.get("year_range")
        
        try:
            # åˆ¤æ–­æ£€ç´¢æ¨¡å¼
            if paper_ids:
                # æ¨¡å¼1: åŸºäºè®ºæ–‡IDæ‰©å±•
                expansion_strategy = arguments.get("expansion_strategy", "citation")
                logger.info(f"ğŸ” æ¨¡å¼1: åŸºäºè®ºæ–‡IDæ‰©å±• ({len(paper_ids)} ä¸ªè®ºæ–‡, ç­–ç•¥={expansion_strategy})")
                
                results = await self._expand_by_paper_ids(
                    paper_ids=paper_ids,
                    strategy=expansion_strategy,
                    max_results=max_results,
                    min_citations=min_citations,
                    year_range=year_range
                )
            
            elif search_query:
                # æ¨¡å¼2: ç›´æ¥å›¾è°±æœç´¢
                search_type = arguments.get("search_type", "auto")
                logger.info(f"ğŸ” æ¨¡å¼2: ç›´æ¥å›¾è°±æœç´¢ (query='{search_query}', type={search_type})")
                
                results = await self._direct_graph_search(
                    query=search_query,
                    search_type=search_type,
                    max_results=max_results,
                    min_citations=min_citations,
                    year_range=year_range
                )
            
            else:
                return json.dumps({
                    "success": False,
                    "error": "å¿…é¡»æä¾› paper_ids æˆ– search_query ä¹‹ä¸€",
                    "results": []
                }, ensure_ascii=False)
            
            # æ ¼å¼åŒ–å“åº”
            return await self._format_response(results, context, mode="expansion" if paper_ids else "search")
        
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†å›¾è°±æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
            return json.dumps({
                "success": False,
                "error": f"çŸ¥è¯†å›¾è°±æ£€ç´¢å¤±è´¥: {str(e)}",
                "results": []
            }, ensure_ascii=False)
    
    # ============ æ¨¡å¼1: åŸºäºè®ºæ–‡IDæ‰©å±• ============
    
    async def _expand_by_paper_ids(
        self,
        paper_ids: List[str],
        strategy: str,
        max_results: int,
        min_citations: int = 0,
        year_range: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """
        æ¨¡å¼1: åŸºäºè®ºæ–‡IDæ‰©å±•ç›¸å…³è®ºæ–‡
        
        Args:
            paper_ids: åˆå§‹è®ºæ–‡IDåˆ—è¡¨
            strategy: æ‰©å±•ç­–ç•¥ (citation/author/field/similar)
            max_results: æœ€å¤§è¿”å›æ•°é‡
            min_citations: æœ€å°å¼•ç”¨æ¬¡æ•°
            year_range: å¹´ä»½èŒƒå›´
        """
        if strategy == "citation":
            return await self._expand_by_citation(paper_ids, max_results, min_citations, year_range)
        elif strategy == "author":
            return await self._expand_by_author(paper_ids, max_results, min_citations, year_range)
        elif strategy == "field":
            return await self._expand_by_field(paper_ids, max_results, min_citations, year_range)
        elif strategy == "similar":
            return await self._expand_by_similar(paper_ids, max_results, min_citations, year_range)
        else:
            logger.warning(f"æœªçŸ¥çš„æ‰©å±•ç­–ç•¥: {strategy}ï¼Œä½¿ç”¨é»˜è®¤ citation")
            return await self._expand_by_citation(paper_ids, max_results, min_citations, year_range)
    
    async def _expand_by_citation(
        self,
        paper_ids: List[str],
        max_results: int,
        min_citations: int = 0,
        year_range: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """å¼•ç”¨é“¾æ‰©å±•ï¼šæ‰¾åˆ°è¿™äº›è®ºæ–‡å¼•ç”¨çš„å’Œè¢«å¼•ç”¨çš„é«˜å½±å“åŠ›è®ºæ–‡"""
        
        # æ„å»ºè¿‡æ»¤æ¡ä»¶ï¼ˆä½¿ç”¨COALESCEå¤„ç†NULLå€¼ï¼‰
        filters = []
        if min_citations > 0:
            filters.append(f"COALESCE(cited.n_citation, 0) >= {min_citations}")
            filters.append(f"COALESCE(citing.n_citation, 0) >= {min_citations}")
        if year_range:
            if year_range.get("start"):
                filters.append(f"COALESCE(cited.year, 0) >= {year_range['start']}")
                filters.append(f"COALESCE(citing.year, 0) >= {year_range['start']}")
            if year_range.get("end"):
                filters.append(f"COALESCE(cited.year, 0) <= {year_range['end']}")
                filters.append(f"COALESCE(citing.year, 0) <= {year_range['end']}")
        
        cited_filter = " AND " + " AND ".join([f for f in filters if "cited." in f]) if filters else ""
        citing_filter = " AND " + " AND ".join([f for f in filters if "citing." in f]) if filters else ""
        
        query = f"""
        MATCH (p:Paper)
        WHERE p.paper_id IN $paper_ids
        
        // æ‰¾åˆ°å®ƒå¼•ç”¨çš„é«˜è¢«å¼•è®ºæ–‡
        OPTIONAL MATCH (p)-[:CITED]->(cited:Paper)
        WHERE cited IS NOT NULL {cited_filter}
        WITH p, cited
        ORDER BY COALESCE(cited.n_citation, 0) DESC
        LIMIT $half_limit
        
        WITH collect({{paper: cited, source: 'cited_by_input'}}) as cited_papers, p
        
        // æ‰¾åˆ°å¼•ç”¨å®ƒçš„è®ºæ–‡
        OPTIONAL MATCH (citing:Paper)-[:CITED]->(p)
        WHERE citing IS NOT NULL {citing_filter}
        WITH cited_papers, citing
        ORDER BY COALESCE(citing.year, 0) DESC
        LIMIT $half_limit
        
        WITH cited_papers + collect({{paper: citing, source: 'citing_input'}}) as all_papers
        UNWIND all_papers as item
        
        WITH DISTINCT item.paper as paper, item.source as source
        WHERE paper IS NOT NULL
        
        RETURN 
            paper.paper_id as paper_id,
            paper.title as title,
            COALESCE(paper.abstract, '') as abstract,
            COALESCE(paper.year, 0) as year,
            COALESCE(paper.n_citation, 0) as citations,
            source,
            'citation_expansion' as retrieval_mode
        LIMIT $max_results
        """
        
        half_limit = max(1, max_results // 2)
        results = self.neo4j_client.execute_query(query, {
            "paper_ids": paper_ids,
            "half_limit": half_limit,
            "max_results": max_results
        })
        
        return self._format_graph_results(results)
    
    async def _expand_by_author(
        self,
        paper_ids: List[str],
        max_results: int,
        min_citations: int = 0,
        year_range: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """ä½œè€…ç›¸å…³æ‰©å±•ï¼šæ‰¾åˆ°åŒä½œè€…çš„å…¶ä»–é«˜å½±å“åŠ›è®ºæ–‡"""
        
        filters = ["NOT other.paper_id IN $paper_ids"]
        if min_citations > 0:
            filters.append(f"COALESCE(other.n_citation, 0) >= {min_citations}")
        if year_range:
            if year_range.get("start"):
                filters.append(f"COALESCE(other.year, 0) >= {year_range['start']}")
            if year_range.get("end"):
                filters.append(f"COALESCE(other.year, 0) <= {year_range['end']}")
        
        where_clause = " AND ".join(filters)
        
        query = f"""
        MATCH (p:Paper)<-[:AUTHORED]-(a:Author)
        WHERE p.paper_id IN $paper_ids
        
        // æ‰¾åˆ°åŒä½œè€…çš„å…¶ä»–é«˜è¢«å¼•è®ºæ–‡
        MATCH (a)-[:AUTHORED]->(other:Paper)
        WHERE {where_clause}
        
        RETURN DISTINCT
            other.paper_id as paper_id,
            other.title as title,
            COALESCE(other.abstract, '') as abstract,
            COALESCE(other.year, 0) as year,
            COALESCE(other.n_citation, 0) as citations,
            collect(DISTINCT a.name)[0..3] as authors,
            'author_expansion' as source,
            'author_expansion' as retrieval_mode
        ORDER BY COALESCE(other.n_citation, 0) DESC
        LIMIT $max_results
        """
        
        results = self.neo4j_client.execute_query(query, {
            "paper_ids": paper_ids,
            "max_results": max_results
        })
        
        return self._format_graph_results(results)
    
    async def _expand_by_field(
        self,
        paper_ids: List[str],
        max_results: int,
        min_citations: int = 0,
        year_range: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """é¢†åŸŸæ‰©å±•ï¼šæ‰¾åˆ°ç›¸åŒé¢†åŸŸçš„é«˜å½±å“åŠ›è®ºæ–‡"""
        
        filters = ["NOT other.paper_id IN $paper_ids"]
        if min_citations > 0:
            filters.append(f"COALESCE(other.n_citation, 0) >= {min_citations}")
        if year_range:
            if year_range.get("start"):
                filters.append(f"COALESCE(other.year, 0) >= {year_range['start']}")
            if year_range.get("end"):
                filters.append(f"COALESCE(other.year, 0) <= {year_range['end']}")
        
        where_clause = " AND ".join(filters)
        
        query = f"""
        MATCH (p:Paper)-[:BELONGS_TO_FIELD]->(f:FieldOfStudy)
        WHERE p.paper_id IN $paper_ids
        
        // æ‰¾åˆ°åŒé¢†åŸŸçš„å…¶ä»–é«˜è¢«å¼•è®ºæ–‡
        MATCH (f)<-[:BELONGS_TO_FIELD]-(other:Paper)
        WHERE {where_clause}
        
        RETURN DISTINCT
            other.paper_id as paper_id,
            other.title as title,
            COALESCE(other.abstract, '') as abstract,
            COALESCE(other.year, 0) as year,
            COALESCE(other.n_citation, 0) as citations,
            collect(DISTINCT f.name)[0..3] as fields,
            'field_expansion' as source,
            'field_expansion' as retrieval_mode
        ORDER BY COALESCE(other.n_citation, 0) DESC
        LIMIT $max_results
        """
        
        results = self.neo4j_client.execute_query(query, {
            "paper_ids": paper_ids,
            "max_results": max_results
        })
        
        return self._format_graph_results(results)
    
    async def _expand_by_similar(
        self,
        paper_ids: List[str],
        max_results: int,
        min_citations: int = 0,
        year_range: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """ç›¸ä¼¼è®ºæ–‡æ‰©å±•ï¼šåŸºäºå…±åŒä½œè€…ã€å…±åŒå¼•ç”¨"""
        
        filters = ["NOT similar.paper_id IN $paper_ids"]
        if min_citations > 0:
            filters.append(f"COALESCE(similar.n_citation, 0) >= {min_citations}")
        if year_range:
            if year_range.get("start"):
                filters.append(f"COALESCE(similar.year, 0) >= {year_range['start']}")
            if year_range.get("end"):
                filters.append(f"COALESCE(similar.year, 0) <= {year_range['end']}")
        
        where_clause = " AND ".join(filters)
        
        query = f"""
        MATCH (p:Paper)
        WHERE p.paper_id IN $paper_ids
        
        // åŸºäºå…±åŒä½œè€…æ‰¾ç›¸ä¼¼è®ºæ–‡
        MATCH (p)<-[:AUTHORED]-(a:Author)-[:AUTHORED]->(similar:Paper)
        WHERE {where_clause}
        
        WITH similar, count(DISTINCT a) as common_authors
        
        // è®¡ç®—å…±åŒå¼•ç”¨
        OPTIONAL MATCH (p)-[:CITED]->(ref)<-[:CITED]-(similar)
        WITH similar, common_authors, count(DISTINCT ref) as common_refs
        
        WITH similar, (common_authors * 2 + common_refs) as similarity_score
        WHERE similarity_score > 0
        
        RETURN 
            similar.paper_id as paper_id,
            similar.title as title,
            COALESCE(similar.abstract, '') as abstract,
            COALESCE(similar.year, 0) as year,
            COALESCE(similar.n_citation, 0) as citations,
            similarity_score,
            'similar_paper' as source,
            'similar_expansion' as retrieval_mode
        ORDER BY similarity_score DESC, COALESCE(similar.n_citation, 0) DESC
        LIMIT $max_results
        """
        
        results = self.neo4j_client.execute_query(query, {
            "paper_ids": paper_ids,
            "max_results": max_results
        })
        
        return self._format_graph_results(results)
    
    # ============ æ¨¡å¼2: ç›´æ¥å›¾è°±æœç´¢ ============
    
    async def _direct_graph_search(
        self,
        query: str,
        search_type: str,
        max_results: int,
        min_citations: int = 0,
        year_range: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """
        æ¨¡å¼2: ç›´æ¥å›¾è°±æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            search_type: æœç´¢ç±»å‹ (author/field/title/auto)
            max_results: æœ€å¤§è¿”å›æ•°é‡
            min_citations: æœ€å°å¼•ç”¨æ¬¡æ•°
            year_range: å¹´ä»½èŒƒå›´
        """
        if search_type == "auto":
            # è‡ªåŠ¨è¯†åˆ«æœç´¢ç±»å‹ï¼ˆç®€å•å¯å‘å¼ï¼‰
            if any(keyword in query.lower() for keyword in ["é¢†åŸŸ", "field", "å­¦ç§‘", "æ–¹å‘"]):
                search_type = "field"
            elif any(keyword in query.lower() for keyword in ["ä½œè€…", "author", "å­¦è€…", "ç ”ç©¶è€…"]):
                search_type = "author"
            else:
                search_type = "title"
        
        if search_type == "author":
            return await self._search_by_author(query, max_results, min_citations, year_range)
        elif search_type == "field":
            return await self._search_by_field(query, max_results, min_citations, year_range)
        elif search_type == "title":
            return await self._search_by_title(query, max_results, min_citations, year_range)
        else:
            logger.warning(f"æœªçŸ¥çš„æœç´¢ç±»å‹: {search_type}")
            return []
    
    async def _search_by_author(
        self,
        author_name: str,
        max_results: int,
        min_citations: int = 0,
        year_range: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """æŒ‰ä½œè€…åæœç´¢"""
        
        filters = []
        if min_citations > 0:
            filters.append(f"COALESCE(p.n_citation, 0) >= {min_citations}")
        if year_range:
            if year_range.get("start"):
                filters.append(f"COALESCE(p.year, 0) >= {year_range['start']}")
            if year_range.get("end"):
                filters.append(f"COALESCE(p.year, 0) <= {year_range['end']}")
        
        where_clause = (" AND " + " AND ".join(filters)) if filters else ""
        
        query = f"""
        MATCH (a:Author)-[:AUTHORED]->(p:Paper)
        WHERE a.name = $author_name
        {where_clause}
        
        RETURN DISTINCT
            p.paper_id as paper_id,
            p.title as title,
            COALESCE(p.abstract, '') as abstract,
            COALESCE(p.year, 0) as year,
            COALESCE(p.n_citation, 0) as citations,
            collect(DISTINCT a.name)[0..5] as authors,
            'author_search' as source,
            'direct_search' as retrieval_mode
        ORDER BY COALESCE(p.n_citation, 0) DESC
        LIMIT $max_results
        """
        
        results = self.neo4j_client.execute_query(query, {
            "author_name": author_name,
            "max_results": max_results
        })
        
        return self._format_graph_results(results)
    
    async def _search_by_field(
        self,
        field_name: str,
        max_results: int,
        min_citations: int = 0,
        year_range: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """æŒ‰ç ”ç©¶é¢†åŸŸæœç´¢"""
        
        filters = []
        if min_citations > 0:
            filters.append(f"COALESCE(p.n_citation, 0) >= {min_citations}")
        if year_range:
            if year_range.get("start"):
                filters.append(f"COALESCE(p.year, 0) >= {year_range['start']}")
            if year_range.get("end"):
                filters.append(f"COALESCE(p.year, 0) <= {year_range['end']}")
        
        where_clause = (" AND " + " AND ".join(filters)) if filters else ""
        
        query = f"""
        MATCH (f:FieldOfStudy)<-[:BELONGS_TO_FIELD]-(p:Paper)
        WHERE toLower(f.name) CONTAINS toLower($field_name)
        {where_clause}
        
        RETURN DISTINCT
            p.paper_id as paper_id,
            p.title as title,
            COALESCE(p.abstract, '') as abstract,
            COALESCE(p.year, 0) as year,
            COALESCE(p.n_citation, 0) as citations,
            collect(DISTINCT f.name)[0..3] as fields,
            'field_search' as source,
            'direct_search' as retrieval_mode
        ORDER BY COALESCE(p.n_citation, 0) DESC
        LIMIT $max_results
        """
        
        results = self.neo4j_client.execute_query(query, {
            "field_name": field_name,
            "max_results": max_results
        })
        
        return self._format_graph_results(results)
    
    async def _search_by_title(
        self,
        title_keyword: str,
        max_results: int,
        min_citations: int = 0,
        year_range: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """æŒ‰æ ‡é¢˜å…³é”®è¯æœç´¢"""
        
        filters = []
        if min_citations > 0:
            filters.append(f"COALESCE(p.n_citation, 0) >= {min_citations}")
        if year_range:
            if year_range.get("start"):
                filters.append(f"COALESCE(p.year, 0) >= {year_range['start']}")
            if year_range.get("end"):
                filters.append(f"COALESCE(p.year, 0) <= {year_range['end']}")
        
        where_clause = (" AND " + " AND ".join(filters)) if filters else ""
        
        query = f"""
        MATCH (p:Paper)
        WHERE toLower(p.title) CONTAINS toLower($keyword)
        {where_clause}
        
        RETURN DISTINCT
            p.paper_id as paper_id,
            p.title as title,
            COALESCE(p.abstract, '') as abstract,
            COALESCE(p.year, 0) as year,
            COALESCE(p.n_citation, 0) as citations,
            'title_search' as source,
            'direct_search' as retrieval_mode
        ORDER BY COALESCE(p.n_citation, 0) DESC
        LIMIT $max_results
        """
        
        results = self.neo4j_client.execute_query(query, {
            "keyword": title_keyword,
            "max_results": max_results
        })
        
        return self._format_graph_results(results)
    
    # ============ å·¥å…·æ–¹æ³• ============
    
    def _format_graph_results(self, raw_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ ¼å¼åŒ–å›¾è°±æŸ¥è¯¢ç»“æœ"""
        formatted = []
        
        for item in raw_results:
            formatted.append({
                "paper_id": item.get("paper_id"),
                "title": item.get("title"),
                "content": item.get("abstract", ""),
                "year": item.get("year"),
                "citations": item.get("citations", 0),
                "source": item.get("source", "graph"),
                "retrieval_mode": item.get("retrieval_mode", "unknown"),
                "authors": item.get("authors", []),
                "fields": item.get("fields", []),
                "similarity_score": item.get("similarity_score", 0)
            })
        
        return formatted
    
    def _build_graph_visualization(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ„å»ºå›¾è°±å¯è§†åŒ–æ•°æ®ï¼ˆèŠ‚ç‚¹+è¾¹æ ¼å¼ï¼‰
        
        Args:
            results: æ£€ç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            å›¾è°±å¯è§†åŒ–æ•°æ® {nodes: [...], edges: [...]}
        """
        nodes = []
        edges = []
        node_ids = set()  # å»é‡
        
        for result in results:
            paper_id = result.get("paper_id", "")
            if not paper_id:
                continue
            
            # æ·»åŠ è®ºæ–‡èŠ‚ç‚¹
            if paper_id not in node_ids:
                nodes.append({
                    "id": f"paper_{paper_id}",
                    "type": "paper",
                    "label": result.get("title", "")[:50] + "...",  # æ ‡é¢˜æˆªæ–­
                    "data": {
                        "paper_id": paper_id,
                        "title": result.get("title", ""),
                        "year": result.get("year"),
                        "citations": result.get("citations", 0),
                        "abstract": result.get("content", "")[:200] + "..."  # æ‘˜è¦æˆªæ–­
                    }
                })
                node_ids.add(paper_id)
            
            # æ·»åŠ ä½œè€…èŠ‚ç‚¹å’Œå…³ç³»
            authors = result.get("authors", [])
            for author_name in authors[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªä½œè€…
                author_id = f"author_{hash(author_name) % 10000000}"  # ç®€å•hashé¿å…é‡å¤
                
                if author_id not in node_ids:
                    nodes.append({
                        "id": author_id,
                        "type": "author",
                        "label": author_name,
                        "data": {"name": author_name}
                    })
                    node_ids.add(author_id)
                
                # æ·»åŠ ä½œè€…->è®ºæ–‡çš„è¾¹
                edges.append({
                    "id": f"{author_id}_authored_{paper_id}",
                    "source": author_id,
                    "target": f"paper_{paper_id}",
                    "type": "AUTHORED",
                    "label": "ä½œè€…"
                })
            
            # æ·»åŠ é¢†åŸŸèŠ‚ç‚¹å’Œå…³ç³»
            fields = result.get("fields", [])
            for field_name in fields[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªé¢†åŸŸ
                field_id = f"field_{hash(field_name) % 10000000}"
                
                if field_id not in node_ids:
                    nodes.append({
                        "id": field_id,
                        "type": "field",
                        "label": field_name,
                        "data": {"name": field_name}
                    })
                    node_ids.add(field_id)
                
                # æ·»åŠ è®ºæ–‡->é¢†åŸŸçš„è¾¹
                edges.append({
                    "id": f"{paper_id}_belongs_{field_id}",
                    "source": f"paper_{paper_id}",
                    "target": field_id,
                    "type": "BELONGS_TO_FIELD",
                    "label": "é¢†åŸŸ"
                })
            
            # å¦‚æœæœ‰å¼•ç”¨å…³ç³»ä¿¡æ¯ï¼Œæ·»åŠ å¼•ç”¨è¾¹
            cited_papers = result.get("cited_papers", [])
            for cited_id in cited_papers[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ªå¼•ç”¨
                if cited_id in node_ids:
                    edges.append({
                        "id": f"{paper_id}_cites_{cited_id}",
                        "source": f"paper_{paper_id}",
                        "target": f"paper_{cited_id}",
                        "type": "CITED",
                        "label": "å¼•ç”¨"
                    })
        
        return {
            "nodes": nodes,
            "edges": edges,
            "metadata": {
                "total_nodes": len(nodes),
                "total_edges": len(edges),
                "node_types": {
                    "paper": sum(1 for n in nodes if n["type"] == "paper"),
                    "author": sum(1 for n in nodes if n["type"] == "author"),
                    "field": sum(1 for n in nodes if n["type"] == "field")
                }
            }
        }
    
    async def _format_response(
        self,
        results: List[Dict[str, Any]],
        context: ToolContext,
        mode: str
    ) -> str:
        """
        æ ¼å¼åŒ–æœ€ç»ˆå“åº”ï¼ˆåŒ…å«å›¾è°±å¯è§†åŒ–æ•°æ®ï¼‰
        
        Args:
            results: æ£€ç´¢ç»“æœ
            context: å·¥å…·ä¸Šä¸‹æ–‡
            mode: æ£€ç´¢æ¨¡å¼ (expansion/search)
        """
        # å¯¼å…¥å…¨å±€åºå·ç®¡ç†å™¨ï¼ˆä¸ knowledge_retrieval å…±äº«ï¼‰
        from .knowledge_retrieval import GlobalReferenceMarkerManager
        marker_manager = GlobalReferenceMarkerManager()
        
        # æ ¼å¼åŒ–æ¯ä¸ªç»“æœ
        formatted_results = []
        for idx, result in enumerate(results, 1):
            # åˆ†é…å…¨å±€å”¯ä¸€åºå·
            global_marker = marker_manager.get_next_marker(context.session_id)
            
            # æ„å»ºæ¥æºæ ‡ç­¾
            source = result.get("source", "")
            retrieval_mode = result.get("retrieval_mode", "")
            
            source_map = {
                "cited_by_input": "å¼•ç”¨çš„è®ºæ–‡",
                "citing_input": "è¢«å¼•ç”¨çš„è®ºæ–‡",
                "author_expansion": "åŒä½œè€…è®ºæ–‡",
                "field_expansion": "åŒé¢†åŸŸè®ºæ–‡",
                "similar_expansion": "ç›¸ä¼¼è®ºæ–‡",
                "author_search": "ä½œè€…æœç´¢",
                "field_search": "é¢†åŸŸæœç´¢",
                "title_search": "æ ‡é¢˜æœç´¢"
            }
            source_label = source_map.get(source, f"å›¾è°±æ£€ç´¢ ({retrieval_mode})")
            
            formatted_results.append({
                "index": idx,
                "ref_marker": global_marker,
                "paper_id": result.get("paper_id", ""),
                "title": result.get("title", ""),
                "content": result.get("content", ""),
                "year": result.get("year"),
                "citations": result.get("citations", 0),
                "source_label": source_label,
                "metadata": {
                    "authors": result.get("authors", []),
                    "fields": result.get("fields", []),
                    "similarity_score": result.get("similarity_score", 0)
                }
            })
        
        # ğŸ¨ æ„å»ºå›¾è°±å¯è§†åŒ–æ•°æ®ï¼ˆèŠ‚ç‚¹+è¾¹æ ¼å¼ï¼‰
        graph_visualization = self._build_graph_visualization(results)
        
        # ğŸ”¥ æ ¸å¿ƒè§£è€¦ï¼šå°†å¯è§†åŒ–æ•°æ®å­˜å‚¨åˆ°Redisï¼ˆä¸è¿”å›ç»™LLMï¼ŒèŠ‚çœtokenï¼‰
        # streaming_managerä¼šåœ¨æµå¼å“åº”ç»“æŸåä»Redisæå–å¹¶å‘é€ç»™å‰ç«¯
        try:
            from app.redis_client import get_redis
            from app.utils.llm.graph_viz_cache import GraphVisualizationCache
            
            redis = await get_redis()
            await GraphVisualizationCache.store_visualization(
                redis=redis,
                session_id=context.session_id,
                visualization_data=graph_visualization
            )
            logger.info(f"âœ… å›¾è°±å¯è§†åŒ–æ•°æ®å·²å­˜å‚¨åˆ°Redis: session={context.session_id}")
        except Exception as e:
            logger.error(f"âŒ å­˜å‚¨å›¾è°±å¯è§†åŒ–æ•°æ®åˆ°Rediså¤±è´¥ï¼ˆç»§ç»­æ‰§è¡Œï¼‰: {e}", exc_info=True)
        
        # ğŸ”¥ è¿”å›ç»™LLMçš„å“åº”ï¼šä¸åŒ…å«graph_visualizationï¼ˆèŠ‚çœæ•°åƒtokenï¼‰
        response = {
            "success": True,
            "total": len(formatted_results),
            "mode": mode,
            "results": formatted_results,
            "explanation": f"çŸ¥è¯†å›¾è°±æ£€ç´¢å®Œæˆï¼ˆ{mode}æ¨¡å¼ï¼‰ï¼Œè¿”å› {len(formatted_results)} ä¸ªç»“æœ"
            # âŒ ç§»é™¤ï¼šä¸å†åŒ…å« graph_visualizationï¼ˆå‰ç«¯é€šè¿‡WebSocketå•ç‹¬æ¥æ”¶ï¼‰
        }
        
        logger.info(f"âœ… çŸ¥è¯†å›¾è°±æ£€ç´¢å®Œæˆ: {len(formatted_results)} ä¸ªç»“æœ, {len(graph_visualization['nodes'])} ä¸ªèŠ‚ç‚¹, å¯è§†åŒ–æ•°æ®å·²ç¼“å­˜åˆ°Redis")
        
        return json.dumps(response, ensure_ascii=False, indent=2)

