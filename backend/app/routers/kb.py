from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Body
from fastapi import Depends
from typing import Optional
import os
import re
import uuid
import hashlib
import logging
import asyncio
from pathlib import Path
from datetime import datetime
from motor.motor_asyncio import AsyncIOMotorClient
from bson import ObjectId

logger = logging.getLogger(__name__)

# âš¡ å»¶è¿Ÿå¯¼å…¥é‡é‡çº§æ¨¡å—ï¼Œé¿å…å¯åŠ¨æ—¶åŠ è½½ï¼š
# - ChromaVectorStoreï¼ˆChromaDB å¯¼å…¥è€—æ—¶çº¦10ç§’ï¼‰
# - ArkEmbeddingsï¼ˆvolcengine SDK å¯¼å…¥è€—æ—¶çº¦20ç§’ï¼‰
# - MiniLMEmbeddingsï¼ˆtorch + sentence-transformers å¯¼å…¥è€—æ—¶çº¦45ç§’ï¼‰
# - RecursiveCharacterTextSplitterï¼ˆlangchain_text_splitters å¯¼å…¥è€—æ—¶çº¦7ç§’ï¼‰
# - OllamaEmbeddingsï¼ˆå¯¼å…¥è¾ƒå¿«ï¼‰
# è¿™äº›æ¨¡å—å°†åœ¨å®é™…ä½¿ç”¨æ—¶æ‰å¯¼å…¥
from ..utils.embedding.pipeline import TextIngestionPipeline
from ..utils.auth import get_current_user
from ..models.user import User
from ..database import get_database
from ..config import settings

from ..utils.embedding.pipeline import Retriever
from ..utils.distance_utils import calculate_score_from_distance
from pydantic import BaseModel
from typing import List, Dict, Any

# å¯¼å…¥æ–°çš„æ–‡æ¡£ä¸Šä¼ æœåŠ¡
from ..services.document_upload_service import get_document_upload_service

# å¯¼å…¥çŸ¥è¯†åº“æœåŠ¡å’Œæ¨¡å‹
from ..services.knowledge_base_service import KnowledgeBaseService
from ..models.knowledge_base import (
    KnowledgeBaseCreate,
    KnowledgeBaseCreateRequest,
    KnowledgeBaseUpdate,
    KnowledgeBaseResponse,
    DocumentResponse,
    KBStatistics,
    KBSearchRequest,
    KBSearchResponse,
    KBSearchResult,
    MultiKBSearchRequest,
    MultiKBSearchResult,
    MultiKBSearchResponse
)

class KnowledgeRetrievalRequest(BaseModel):
	query: str
	kb_settings: dict
	top_k: Optional[int] = 3

class KnowledgeRetrievalResponse(BaseModel):
	success: bool
	results: List[Dict[str, Any]]
	error: Optional[str] = None

router = APIRouter()


@router.get("/debug/vectorstore-stats")
async def get_vectorstore_stats(
    current_user: User = Depends(get_current_user)
):
    """
    è°ƒè¯•ç«¯ç‚¹ï¼šæŸ¥çœ‹å½“å‰ VectorStore è¿æ¥çŠ¶æ€
    """
    try:
        from ..services.vectorstore_manager import get_vectorstore_manager
        manager = get_vectorstore_manager()
        stats = manager.get_stats()
        return {
            "success": True,
            "stats": stats
        }
    except Exception as e:
        logger.error(f"è·å– VectorStore ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def _sanitize_collection_name(name: str) -> str:
	"""
	Chroma constraints:
	- 3-63 chars
	- start/end alphanumeric
	- allowed: alnum, '_', '-'
	- no consecutive periods; we avoid '.' entirely
	- not an IPv4 address (we avoid by using letters)
	"""
	original_name = name  # ä¿å­˜åŸå§‹åç§°ç”¨äºç”Ÿæˆç¡®å®šæ€§å“ˆå¸Œ
	if not name:
		name = "kb"
	# Replace unsupported chars with '-'
	name = re.sub(r"[^A-Za-z0-9_-]", "-", name)
	# Collapse multiple '-' or '_' to single '-'
	name = re.sub(r"[-_]{2,}", "-", name)
	# Trim non-alnum from ends
	name = re.sub(r"^[^A-Za-z0-9]+|[^A-Za-z0-9]+$", "", name)
	# Ensure minimum length by padding with deterministic suffix
	if len(name) < 3:
		# ä½¿ç”¨åŸå§‹åç§°çš„å“ˆå¸Œå€¼ç”Ÿæˆç¡®å®šæ€§çš„åç¼€
		original_hash = hashlib.md5(original_name.encode('utf-8')).hexdigest()[:6]
		name = f"kb-{original_hash}"
	# Enforce max length 63
	if len(name) > 63:
		name = name[:63]
	# Final guard: if ends with non-alnum after slice, fix
	name = re.sub(r"^[^A-Za-z0-9]+|[^A-Za-z0-9]+$", "", name)
	# If empty again, fallback with deterministic hash
	if not name:
		# ä½¿ç”¨åŸå§‹è¾“å…¥åç§°ç”Ÿæˆç¡®å®šæ€§çš„åç§°
		original_hash = hashlib.md5(original_name.encode('utf-8')).hexdigest()[:6]
		name = f"kb-{original_hash}"
	return name




# å…è®¸ Unicode çš„æ–‡ä»¶å¤¹åæ¸…æ´—ï¼ˆä»…å»é™¤æ–‡ä»¶ç³»ç»Ÿä¸å…è®¸æˆ–å±é™©å­—ç¬¦ï¼‰
_def_fs_forbidden = r"[<>:\\/\|?*]"

def _sanitize_folder_name(name: str) -> str:
	name = name or "kb"
	# å»é™¤éæ³•å­—ç¬¦
	name = re.sub(_def_fs_forbidden, "-", name)
	# å»æ‰é¦–å°¾ç©ºç™½åŠç‚¹/ç©ºæ ¼ï¼ˆWindows æœ«å°¾ç‚¹ä¸ç©ºæ ¼ä¸åˆæ³•ï¼‰
	name = name.strip().strip(". ")
	# é¿å…ç©ºå­—ç¬¦ä¸²
	if not name:
		name = f"kb-{uuid.uuid4().hex[:6]}"
	# é™é•¿ï¼Œé¿å…è¿‡é•¿è·¯å¾„
	if len(name) > 100:
		name = name[:100].rstrip(". ")
	return name


def _get_kb_components(kb_settings: dict):
	"""
	æ ¹æ®çŸ¥è¯†åº“é…ç½®è·å–ç»„ä»¶ï¼ˆä½¿ç”¨å…¨å±€å•ä¾‹ç®¡ç†å™¨ï¼‰
	
	Returns:
		(splitter, vectorstore, embeddings)
	"""
	# âš¡ å»¶è¿Ÿå¯¼å…¥é‡é‡çº§æ¨¡å—
	from langchain_text_splitters import RecursiveCharacterTextSplitter
	from ..utils.embedding.path_utils import (
		build_chroma_persist_dir, get_chroma_collection_name,
		build_faiss_persist_dir, get_faiss_collection_name
	)
	from ..services.embedding_manager import get_embedding_manager
	from ..services.vectorstore_manager import get_vectorstore_manager
	
	if not kb_settings or not kb_settings.get("enabled"):
		raise HTTPException(status_code=400, detail="çŸ¥è¯†åº“æœªå¯ç”¨æˆ–é…ç½®ä¸ºç©º")

	# 1. è§£æé…ç½®
	embeddings_config = kb_settings.get("embeddings") or {}
	provider = embeddings_config.get("provider", "ollama")
	embed_model = embeddings_config.get("model")
	base_url = embeddings_config.get("base_url")
	api_key = embeddings_config.get("api_key")
	local_model_path = embeddings_config.get("local_model_path")

	# 2. è·å– Embedding å®ä¾‹ï¼ˆå…¨å±€å…±äº«ï¼Œä¸ä¼šé‡å¤åŠ è½½ï¼‰
	embedding_manager = get_embedding_manager()
	try:
		embeddings = embedding_manager.get_or_create(
			provider=provider,
			model=embed_model,
			base_url=base_url,
			api_key=api_key,
			local_model_path=local_model_path,
			max_length=512,
			batch_size=8,
			normalize=True
		)
	except (ValueError, FileNotFoundError, RuntimeError) as e:
		raise HTTPException(status_code=400, detail=str(e))

	# 3. åˆ›å»º Splitterï¼ˆè½»é‡çº§ï¼Œæ¯æ¬¡åˆ›å»ºï¼‰
	sp = kb_settings.get("split_params") or {}
	chunk_size = int(sp.get("chunk_size", 500))
	chunk_overlap = int(sp.get("chunk_overlap", 100))
	separators = sp.get("separators") or ["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", " ", ""]
	splitter = RecursiveCharacterTextSplitter(
		chunk_size=chunk_size,
		chunk_overlap=chunk_overlap,
		separators=list(separators),
	)

	# 4. è§£ææœç´¢å‚æ•°ï¼ˆåŒ…å«è·ç¦»åº¦é‡ï¼‰
	search_params = kb_settings.get("search_params") or {}
	distance_metric = search_params.get("distance_metric", "cosine")  # é»˜è®¤ä½¿ç”¨ä½™å¼¦è·ç¦»
	
	# 5. è·å– VectorStore å®ä¾‹ï¼ˆå…¨å±€å…±äº«ï¼‰
	vector_db = kb_settings.get("vector_db", "chroma")  # é»˜è®¤ä½¿ç”¨chromaï¼Œæ”¯æŒfaiss
	if vector_db not in ["chroma", "faiss"]:
		raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„å‘é‡æ•°æ®åº“ç±»å‹: {vector_db}ï¼Œä»…æ”¯æŒ: chroma, faiss")
	
	collection_name_raw = kb_settings.get("collection_name") or "default"
	
	# æ ¹æ®å‘é‡æ•°æ®åº“ç±»å‹é€‰æ‹©è·¯å¾„æ„å»ºå‡½æ•°
	if vector_db == "chroma":
		collection_name = get_chroma_collection_name(collection_name_raw)
		persist_dir = build_chroma_persist_dir(collection_name_raw)
	elif vector_db == "faiss":
		collection_name = get_faiss_collection_name(collection_name_raw)
		persist_dir = build_faiss_persist_dir(collection_name_raw)
	else:
		raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„å‘é‡æ•°æ®åº“ç±»å‹: {vector_db}")
	
	vectorstore_manager = get_vectorstore_manager()
	try:
		vectorstore = vectorstore_manager.get_or_create(
			collection_name=collection_name,
			persist_dir=persist_dir,
			embedding_function=embeddings,
			vector_db_type=vector_db,
			distance_metric=distance_metric  # ğŸ¯ ä¼ é€’è·ç¦»åº¦é‡å‚æ•°
		)
	except (ValueError, RuntimeError) as e:
		raise HTTPException(status_code=400, detail=str(e))

	return splitter, vectorstore, embeddings


@router.post("/kb/upload_and_ingest")
async def upload_and_ingest(
	file: UploadFile = File(...),
	kb_settings_json: str = Form(...),
	session_id: Optional[str] = Form(default=None),
	priority: Optional[str] = Form(default="NORMAL"),
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database),
):
	"""
	ä¸Šä¼ å•ä¸ªæ–‡ä»¶å¹¶å¼‚æ­¥å¤„ç†ï¼ˆæ¨èï¼‰
	
	ä½¿ç”¨ä¼ä¸šçº§å¼‚æ­¥å¤„ç†ï¼Œç«‹å³è¿”å›ä»»åŠ¡IDï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹ã€‚
	
	Args:
		file: ä¸Šä¼ çš„æ–‡ä»¶
		kb_settings_json: çŸ¥è¯†åº“é…ç½®ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰
		session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
		priority: ä»»åŠ¡ä¼˜å…ˆçº§ LOW/NORMAL/HIGHï¼ˆé»˜è®¤NORMALï¼‰
		
	Returns:
		{
			"ok": true,
			"task_id": "uuid",
			"status": "processing",
			"message": "æ–‡æ¡£æ­£åœ¨åå°å¤„ç†ä¸­...",
			"metadata": {...}
		}
	"""
	import json
	
	# 1. è§£æçŸ¥è¯†åº“é…ç½®
	try:
		kb_settings = json.loads(kb_settings_json)
	except Exception:
		raise HTTPException(status_code=400, detail="kb_settings_json ä¸æ˜¯åˆæ³•çš„ JSON")

	if not file.filename:
		raise HTTPException(status_code=422, detail="ç¼ºå°‘æ–‡ä»¶å")
	
	# 2. ç«‹å³æ›´æ–°ä¼šè¯çš„ kb_settingsï¼ˆä¸ç­‰å¾…æ–‡æ¡£å¤„ç†å®Œæˆï¼‰
	if session_id:
		doc_service = get_document_upload_service()
		success, error = await doc_service.update_session_kb_config(
			db=db,
			session_id=session_id,
			user_id=str(current_user.id),
			kb_settings=kb_settings,
			kb_parsed=False
		)
		if not success:
			raise HTTPException(status_code=404, detail=error)
	
	# 3. è¯»å–æ–‡ä»¶å†…å®¹
	content_bytes = await file.read()
	
	# 4. ä½¿ç”¨æ–‡æ¡£ä¸Šä¼ æœåŠ¡å¼‚æ­¥å¤„ç†
	doc_service = get_document_upload_service()
	result = await doc_service.upload_and_process_async(
		content=content_bytes,
		filename=file.filename,
		kb_settings=kb_settings,
		session_id=session_id,
		user_id=str(current_user.id),
		priority=priority,
		timeout=600.0,
		max_retries=3
	)
	
	if not result.success:
		raise HTTPException(status_code=500, detail=result.error)
	
	return result.to_dict()


@router.get("/kb/supported_formats")
async def get_supported_formats():
	"""è·å–æ”¯æŒçš„æ–‡æ¡£æ ¼å¼ä¿¡æ¯"""
	try:
		from ..utils.document_parsers import get_supported_formats_info
		return get_supported_formats_info()
	except Exception as e:
		logger.error(f"è·å–æ”¯æŒæ ¼å¼ä¿¡æ¯å¤±è´¥: {str(e)}")
		raise HTTPException(status_code=500, detail=f"è·å–æ”¯æŒæ ¼å¼ä¿¡æ¯å¤±è´¥: {str(e)}")


@router.get("/kb/task_status/{task_id}")
async def get_task_status(
	task_id: str,
	current_user: User = Depends(get_current_user)
):
	"""è·å–ä»»åŠ¡çŠ¶æ€å’Œè¿›åº¦"""
	try:
		from ..utils.embedding.task_queue import get_task_queue
		
		task_queue = await get_task_queue()
		task_info = await task_queue.get_task_status(task_id)
		
		if not task_info:
			raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
		
		# æ£€æŸ¥æƒé™ï¼ˆåªèƒ½æŸ¥çœ‹è‡ªå·±çš„ä»»åŠ¡ï¼‰
		if task_info.metadata.get("user_id") != str(current_user.id):
			raise HTTPException(status_code=403, detail="æ— æƒé™è®¿é—®æ­¤ä»»åŠ¡")
		
		return {
			"task_id": task_info.task_id,
			"status": task_info.status.value,
			"progress": task_info.progress,
			"created_at": task_info.created_at.isoformat(),
			"started_at": task_info.started_at.isoformat() if task_info.started_at else None,
			"completed_at": task_info.completed_at.isoformat() if task_info.completed_at else None,
			"result": task_info.result,
			"error": task_info.error,
			"retry_count": task_info.retry_count,
			"metadata": task_info.metadata
		}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
		raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")


@router.post("/kb/cancel_task/{task_id}")
async def cancel_task(
	task_id: str,
	current_user: User = Depends(get_current_user)
):
	"""å–æ¶ˆä»»åŠ¡"""
	try:
		from ..utils.embedding.task_queue import get_task_queue
		
		task_queue = await get_task_queue()
		task_info = await task_queue.get_task_status(task_id)
		
		if not task_info:
			raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
		
		# æ£€æŸ¥æƒé™
		if task_info.metadata.get("user_id") != str(current_user.id):
			raise HTTPException(status_code=403, detail="æ— æƒé™æ“ä½œæ­¤ä»»åŠ¡")
		
		success = await task_queue.cancel_task(task_id)
		
		return {
			"ok": success,
			"message": "ä»»åŠ¡å·²å–æ¶ˆ" if success else "ä»»åŠ¡æ— æ³•å–æ¶ˆï¼ˆå¯èƒ½å·²å®Œæˆæˆ–ä¸å­˜åœ¨ï¼‰"
		}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")
		raise HTTPException(status_code=500, detail=f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")


@router.get("/kb/queue_stats")
async def get_queue_stats(
	current_user: User = Depends(get_current_user)
):
	"""è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯ï¼ˆç®¡ç†å‘˜åŠŸèƒ½ï¼‰"""
	try:
		from ..utils.embedding.task_queue import get_task_queue
		
		task_queue = await get_task_queue()
		stats = task_queue.get_stats()
		
		return {
			"ok": True,
			"stats": stats
		}
		
	except Exception as e:
		logger.error(f"è·å–é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥: {str(e)}")
		raise HTTPException(status_code=500, detail=f"è·å–é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥: {str(e)}")


@router.post("/kb/retrieve", response_model=KnowledgeRetrievalResponse)
async def retrieve_knowledge(
	request: KnowledgeRetrievalRequest,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database),
):
	"""
	æ ¹æ®æŸ¥è¯¢æ–‡æœ¬å’Œä¼šè¯çš„çŸ¥è¯†åº“é…ç½®è¿›è¡Œå‘é‡æ£€ç´¢ï¼Œè¿”å›ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
	"""
	try:
		# æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å¯ç”¨
		if not request.kb_settings or not request.kb_settings.get("enabled"):
			return KnowledgeRetrievalResponse(
				success=True,
				results=[],
				error="çŸ¥è¯†åº“æœªå¯ç”¨"
			)
		
		# æ„å»ºçŸ¥è¯†åº“ç»„ä»¶ï¼ˆä½¿ç”¨å…¨å±€å•ä¾‹ï¼‰
		_, vectorstore, _ = _get_kb_components(request.kb_settings)
		
		# ä»é…ç½®ä¸­è·å–ç›¸ä¼¼åº¦é˜ˆå€¼å’Œè·ç¦»åº¦é‡ç±»å‹
		similarity_threshold = request.kb_settings.get("similarity_threshold", 0.5) if isinstance(request.kb_settings, dict) else 0.5
		search_params = request.kb_settings.get("search_params") or {}
		distance_metric = search_params.get("distance_metric", "cosine")
		
		# åˆ›å»ºæ£€ç´¢å™¨ï¼Œåº”ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼å’Œè·ç¦»åº¦é‡
		retriever = Retriever(
			vector_store=vectorstore, 
			top_k=request.top_k, 
			similarity_threshold=similarity_threshold,
			distance_metric=distance_metric
		)
		
		# æ‰§è¡Œæ£€ç´¢ - âœ… ä½¿ç”¨å¼‚æ­¥æ–¹æ³•ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
		search_results = await retriever.search(request.query, top_k=request.top_k)
		
		# æ ¼å¼åŒ–ç»“æœ
		formatted_results = []
		for doc, score in search_results:
			formatted_results.append({
				"content": doc.page_content,
				"score": float(score),
				"metadata": doc.metadata
			})
		
		return KnowledgeRetrievalResponse(
			success=True,
			results=formatted_results
		)
		
	except Exception as e:
		return KnowledgeRetrievalResponse(
			success=False,
			results=[],
			error=f"æ£€ç´¢å¤±è´¥: {str(e)}"
		) 

@router.post("/kb/resolve_references")
async def resolve_references(
	payload: dict,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database),
):
	"""
	å°†ç²¾ç®€å¼•ç”¨ [{document_id, chunk_id}] å±•å¼€ä¸ºå¯Œå¼•ç”¨ã€‚
	è¾“å…¥ç¤ºä¾‹ï¼š{"kb_settings": {...}, "items": [{"document_id":"path/file.txt","chunk_id":"uuid"}, ...]}
	"""
	try:
		items = payload.get("items") or []
		kb_settings = payload.get("kb_settings") or {}
		if not items:
			return {"success": True, "results": []}

		# æ„å»ºå‘é‡åº“ï¼ˆå¿…é¡»ä¸å…¥åº“æ—¶ä¸€è‡´ï¼Œä½¿ç”¨å…¨å±€å•ä¾‹ï¼‰
		_, vectorstore, _ = _get_kb_components(kb_settings)
		if not hasattr(vectorstore, "get_by_ids"):
			raise HTTPException(status_code=400, detail="å‘é‡åº“æœªå®ç° get_by_idsï¼Œæ— æ³•è§£æå¼•ç”¨")

		ids = [it.get("chunk_id") for it in items if it.get("chunk_id")]
		if not ids:
			return {"success": True, "results": []}

		# âœ… ä½¿ç”¨å¼‚æ­¥æ–¹æ³•ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
		docs = await vectorstore.get_by_ids(ids)
		results = []
		# å°†è¿”å›çš„æ–‡æ¡£ä¸è¾“å…¥çš„ items æŒ‰ chunk_id å¯¹é½
		id_to_doc = {doc.metadata.get("chunk_id"): doc for doc in docs}
		for it in items:
			chunk_id = it.get("chunk_id")
			doc = id_to_doc.get(chunk_id)
			if not doc:
				continue
			meta = doc.metadata or {}
			results.append({
				"document_id": meta.get("document_id") or it.get("document_id"),
				"chunk_id": chunk_id,
				"content": doc.page_content,
				"metadata": meta,
			})

		return {"success": True, "results": results}
	except HTTPException:
		raise
	except Exception as e:
		raise HTTPException(status_code=500, detail=f"è§£æå¼•ç”¨å¤±è´¥: {str(e)}")


# ================================
# çŸ¥è¯†åº“ç®¡ç† APIï¼ˆæ–°å¢ï¼‰
# ================================

@router.post("/kb/create", response_model=KnowledgeBaseResponse)
async def create_knowledge_base(
	request_data: KnowledgeBaseCreateRequest,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	åˆ›å»ºçŸ¥è¯†åº“
	
	ç‰¹æ€§ï¼š
	- å®Œå…¨å¼‚æ­¥æ“ä½œ
	- è‡ªåŠ¨éªŒè¯æƒé™
	- æ”¯æŒé«˜å¹¶å‘
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		
		# å°†å‰ç«¯æ ¼å¼è½¬æ¢ä¸ºåç«¯æ ¼å¼
		kb_settings = {
			"enabled": True,
			"vector_db": request_data.vector_db,
			"collection_name": request_data.collection_name or _sanitize_collection_name(request_data.name),
			"embeddings": request_data.embedding_config.model_dump(exclude_none=True),
			"split_params": request_data.split_params.model_dump(exclude_none=True),
			"search_params": request_data.search_params.model_dump(exclude_none=True) if request_data.search_params else {},
			# å…¼å®¹æ—§ç‰ˆå­—æ®µ
			"similarity_threshold": request_data.similarity_threshold,
			"top_k": request_data.top_k
		}
		
		kb_data = KnowledgeBaseCreate(
			name=request_data.name,
			description=request_data.description,
			kb_settings=kb_settings
		)
		
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		result = await kb_service.create_knowledge_base(
			user_id=current_user.id,
			kb_data=kb_data
		)
		
		return result
		
	except ValueError as e:
		raise HTTPException(status_code=400, detail=str(e))
	except Exception as e:
		logger.error(f"åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥: {str(e)}")


@router.get("/kb/list")
async def list_knowledge_bases(
	skip: int = 0,
	limit: int = 100,
	include_pulled: bool = False,  # æ–°å¢å‚æ•°ï¼šæ˜¯å¦åŒ…å«æ‹‰å–çš„çŸ¥è¯†åº“
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	è·å–ç”¨æˆ·çš„çŸ¥è¯†åº“åˆ—è¡¨
	
	ç‰¹æ€§ï¼š
	- æ”¯æŒåˆ†é¡µ
	- å¼‚æ­¥æŸ¥è¯¢
	- æŒ‰åˆ›å»ºæ—¶é—´å€’åº
	- é»˜è®¤åªè¿”å›ç”¨æˆ·è‡ªå·±åˆ›å»ºçš„çŸ¥è¯†åº“ï¼Œå¯é€šè¿‡ include_pulled=true åŒ…å«æ‹‰å–çš„çŸ¥è¯†åº“
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from ..services.kb_marketplace_service import KBMarketplaceService
		
		# è·å–ç”¨æˆ·è‡ªå·±çš„çŸ¥è¯†åº“
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		own_kbs = await kb_service.get_knowledge_bases(
			user_id=current_user.id,
			skip=skip,
			limit=limit
		)
		
		pulled_kbs = []
		
		# å¦‚æœéœ€è¦åŒ…å«æ‹‰å–çš„çŸ¥è¯†åº“
		if include_pulled:
			# è·å–ç”¨æˆ·æ‹‰å–çš„çŸ¥è¯†åº“
			marketplace_service = KBMarketplaceService(db[settings.mongodb_db_name])
			pulled_result = await marketplace_service.list_pulled_knowledge_bases(
				user_id=current_user.id,
				skip=0,
				limit=1000  # è·å–æ‰€æœ‰æ‹‰å–çš„çŸ¥è¯†åº“
			)
			
			# å°†æ‹‰å–çš„çŸ¥è¯†åº“è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œæ·»åŠ æ ‡è®°
			for pulled_kb in pulled_result["items"]:
				if pulled_kb.enabled:  # åªè¿”å›å¯ç”¨çš„
					# å¤„ç†æ—¶é—´å­—æ®µï¼šç¡®ä¿æ˜¯å­—ç¬¦ä¸²æ ¼å¼
					created_at = pulled_kb.pulled_at
					if isinstance(created_at, datetime):
						created_at = created_at.isoformat()
					
					pulled_kbs.append({
						"id": pulled_kb.id,
						"name": f"[å…±äº«] {pulled_kb.name}",  # æ·»åŠ æ ‡è®°
						"description": pulled_kb.description,
						"document_count": pulled_kb.document_count,
						"chunk_count": pulled_kb.chunk_count,
						"created_at": created_at,
						"is_pulled": True,  # æ ‡è®°ä¸ºæ‹‰å–çš„çŸ¥è¯†åº“
						"owner_account": pulled_kb.owner_account,
						"kb_settings": {
							"collection_name": pulled_kb.collection_name,
							"vector_db": pulled_kb.vector_db,
							"embeddings": pulled_kb.embedding_config,
							"split_params": pulled_kb.split_params,
							"similarity_threshold": pulled_kb.similarity_threshold,
							"top_k": pulled_kb.top_k
						}
					})
		
		# åˆå¹¶ä¸¤ä¸ªåˆ—è¡¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
		all_kbs = own_kbs + pulled_kbs
		
		return {
			"success": True,
			"knowledge_bases": all_kbs,
			"own_count": len(own_kbs),
			"pulled_count": len(pulled_kbs)
		}
		
	except Exception as e:
		logger.error(f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/kb/statistics", response_model=KBStatistics)
async def get_statistics(
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	è·å–ç”¨æˆ·çš„çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯
	
	ç‰¹æ€§ï¼š
	- èšåˆæŸ¥è¯¢
	- å¼‚æ­¥è®¡ç®—
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		result = await kb_service.get_statistics(current_user.id)
		
		return result
		
	except Exception as e:
		logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


@router.get("/kb/system/stats")
async def get_system_stats(
	current_user: User = Depends(get_current_user)
):
	"""
	è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ï¼ˆç®¡ç†å‘˜åŠŸèƒ½ï¼‰
	
	è¿”å›ï¼š
	- ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
	- æ€§èƒ½æŒ‡æ ‡
	- èµ„æºä½¿ç”¨æƒ…å†µ
	"""
	try:
		from ..services.async_task_processor import get_task_processor
		
		processor = get_task_processor()
		stats = processor.get_statistics()
		
		return {
			"success": True,
			"stats": stats,
			"timestamp": datetime.utcnow().isoformat()
		}
		
	except Exception as e:
		logger.error(f"è·å–ç³»ç»Ÿç»Ÿè®¡å¤±è´¥: {str(e)}")
		raise HTTPException(status_code=500, detail=f"è·å–ç³»ç»Ÿç»Ÿè®¡å¤±è´¥: {str(e)}")


@router.get("/kb/{kb_id}", response_model=KnowledgeBaseResponse)
async def get_knowledge_base(
	kb_id: str,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	è·å–å•ä¸ªçŸ¥è¯†åº“è¯¦æƒ…
	
	ç‰¹æ€§ï¼š
	- è‡ªåŠ¨æƒé™éªŒè¯
	- å¼‚æ­¥æŸ¥è¯¢
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		result = await kb_service.get_knowledge_base(
			kb_id=kb_id,
			user_id=current_user.id
		)
		
		if not result:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		return result
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"è·å–çŸ¥è¯†åº“å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"è·å–çŸ¥è¯†åº“å¤±è´¥: {str(e)}")


@router.put("/kb/{kb_id}", response_model=KnowledgeBaseResponse)
async def update_knowledge_base(
	kb_id: str,
	kb_data: KnowledgeBaseUpdate,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	æ›´æ–°çŸ¥è¯†åº“
	
	ç‰¹æ€§ï¼š
	- åŸå­æ“ä½œ
	- æƒé™éªŒè¯
	- å¼‚æ­¥æ›´æ–°
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		result = await kb_service.update_knowledge_base(
			kb_id=kb_id,
			user_id=current_user.id,
			kb_data=kb_data
		)
		
		if not result:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		return result
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"æ›´æ–°çŸ¥è¯†åº“å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"æ›´æ–°çŸ¥è¯†åº“å¤±è´¥: {str(e)}")


@router.delete("/kb/{kb_id}")
async def delete_knowledge_base(
	kb_id: str,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	åˆ é™¤çŸ¥è¯†åº“
	
	ç‰¹æ€§ï¼š
	- åˆ é™¤æ‰€æœ‰å…³è”æ–‡æ¡£
	- å¼‚æ­¥åˆ é™¤å‘é‡æ•°æ®ï¼ˆåå°ä»»åŠ¡ï¼‰
	- åŸå­æ“ä½œ
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		success = await kb_service.delete_knowledge_base(
			kb_id=kb_id,
			user_id=current_user.id
		)
		
		if not success:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		return {"success": True, "message": "çŸ¥è¯†åº“å·²åˆ é™¤"}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"åˆ é™¤çŸ¥è¯†åº“å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"åˆ é™¤çŸ¥è¯†åº“å¤±è´¥: {str(e)}")


@router.get("/kb/{kb_id}/documents")
async def list_documents(
	kb_id: str,
	skip: int = 0,
	limit: int = 100,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	è·å–çŸ¥è¯†åº“çš„æ–‡æ¡£åˆ—è¡¨
	
	ç‰¹æ€§ï¼š
	- æ”¯æŒåˆ†é¡µ
	- å¼‚æ­¥æŸ¥è¯¢
	- æŒ‰åˆ›å»ºæ—¶é—´å€’åº
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		
		# è·å–æ–‡æ¡£åˆ—è¡¨
		result = await kb_service.get_documents(
			kb_id=kb_id,
			user_id=current_user.id,
			skip=skip,
			limit=limit
		)
		
		# è·å–æ–‡æ¡£æ€»æ•°ï¼ˆç”¨äºåˆ†é¡µï¼‰
		total = await kb_service.count_documents(kb_id, current_user.id)
		
		return {
			"success": True,
			"documents": result,
			"pagination": {
				"page": (skip // limit) + 1,
				"page_size": limit,
				"total": total,
				"total_pages": (total + limit - 1) // limit if limit > 0 else 0
			}
		}
		
	except Exception as e:
		logger.error(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.post("/kb/{kb_id}/upload")
async def upload_document(
	kb_id: str,
	file: UploadFile = File(...),
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	ã€æ–°ã€‘ä»…ä¸Šä¼ æ–‡æ¡£åˆ°æœåŠ¡å™¨ï¼ˆä¸è§£æï¼‰
	
	æµç¨‹ï¼š
	1. éªŒè¯æ–‡ä»¶æ ¼å¼
	2. ä¸Šä¼ åˆ° MinIOï¼ˆç”¨æˆ·éš”ç¦»ï¼‰
	3. åˆ›å»ºæ–‡æ¡£è®°å½•ï¼ˆstatus=uploadedï¼‰
	4. è¿”å›æ–‡æ¡£ä¿¡æ¯
	
	ç”¨æˆ·éœ€è¦æ‰‹åŠ¨è°ƒç”¨ /parse æ¥å£è¿›è¡Œè§£æ
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from ..services.document_upload_service import DocumentUploadService
		from ..utils.minio_client import minio_client
		import mimetypes
		
		# éªŒè¯çŸ¥è¯†åº“å­˜åœ¨
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
		if not kb:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		# è·å–çŸ¥è¯†åº“çš„ collection_nameï¼ˆç”¨äº MinIO è·¯å¾„ï¼‰
		collection_name = kb.collection_name
		if not collection_name:
			raise HTTPException(status_code=500, detail="çŸ¥è¯†åº“é…ç½®é”™è¯¯ï¼šç¼ºå°‘ collection_name")
		
		# éªŒè¯æ–‡ä»¶æ ¼å¼
		upload_service = DocumentUploadService()
		is_valid, error = upload_service.validate_file(file.filename)
		if not is_valid:
			raise HTTPException(status_code=400, detail=error)
		
		# è¯»å–æ–‡ä»¶å†…å®¹
		file_content = await file.read()
		file_size = len(file_content)
		file_type = Path(file.filename).suffix.lower()
		
		# åˆ›å»ºæ–‡æ¡£è®°å½•ï¼ˆstatus=uploadedï¼‰
		doc = await kb_service.create_document(
			kb_id=kb_id,
			user_id=current_user.id,
			filename=file.filename,
			file_size=file_size,
			file_type=file_type
		)
		
		# ä¸Šä¼ æ–‡ä»¶åˆ° MinIOï¼ˆç”¨æˆ·éš”ç¦»ï¼‰
		# ä½¿ç”¨ collection_name ä½œä¸ºè·¯å¾„å‰ç¼€ï¼ˆè€Œé kb_idï¼‰ï¼Œå› ä¸ºç”¨æˆ·å¯èƒ½ä¿®æ”¹çŸ¥è¯†åº“åç§°
		content_type = mimetypes.guess_type(file.filename)[0] or "application/octet-stream"
		file_url = minio_client.upload_kb_document(
			file_data=file_content,
			user_id=current_user.id,
			collection_name=collection_name,  # ä½¿ç”¨ collection_name ä»£æ›¿ kb_id
			doc_id=str(doc.id),
			filename=file.filename,
			content_type=content_type
		)
		
		# æ›´æ–°æ–‡æ¡£è®°å½•ï¼Œæ·»åŠ  file_url å’Œ status=uploaded
		await kb_service.update_document_file_url(
			doc_id=str(doc.id),
			file_url=file_url,
			status="uploaded"
		)
		
		logger.info(f"âœ… æ–‡æ¡£ä¸Šä¼ æˆåŠŸ: {file.filename}, doc_id={doc.id}")
		
		return {
			"success": True,
			"message": "æ–‡æ¡£ä¸Šä¼ æˆåŠŸï¼Œè¯·ç‚¹å‡»è§£ææŒ‰é’®å¼€å§‹å¤„ç†",
			"doc_id": str(doc.id),
			"filename": file.filename,
			"file_size": file_size,
			"file_url": file_url,
			"status": "uploaded"
		}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"ä¸Šä¼ æ–‡æ¡£å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"ä¸Šä¼ æ–‡æ¡£å¤±è´¥: {str(e)}")


@router.post("/kb/{kb_id}/documents/{doc_id}/parse")
async def parse_document(
	kb_id: str,
	doc_id: str,
	priority: str = "normal",
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	ã€æ–°ã€‘è§£æå·²ä¸Šä¼ çš„æ–‡æ¡£ï¼ˆä» MinIO è¯»å–ï¼‰
	
	æµç¨‹ï¼š
	1. éªŒè¯æ–‡æ¡£å­˜åœ¨ä¸”çŠ¶æ€ä¸º uploaded
	2. ä» MinIO ä¸‹è½½æ–‡æ¡£
	3. æäº¤è§£æä»»åŠ¡åˆ°åå°é˜Ÿåˆ—
	4. è¿”å›ä»»åŠ¡ID
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from ..services.document_processor import get_document_processor
		from ..services.async_task_processor import TaskPriority
		from ..utils.minio_client import minio_client
		import tempfile
		import os
		
		# éªŒè¯çŸ¥è¯†åº“å­˜åœ¨
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
		if not kb:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		# è·å–æ–‡æ¡£è®°å½•
		doc = await kb_service.get_document(doc_id)
		if not doc:
			raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
		
		if doc.get("kb_id") != kb_id:
			raise HTTPException(status_code=403, detail="æ–‡æ¡£ä¸å±äºæ­¤çŸ¥è¯†åº“")
		
		# æ£€æŸ¥æ–‡æ¡£çŠ¶æ€
		if not doc.get("file_url"):
			raise HTTPException(status_code=400, detail="æ–‡æ¡£å°šæœªä¸Šä¼ åˆ°æœåŠ¡å™¨")
		
		# ä» MinIO ä¸‹è½½æ–‡æ¡£
		file_content = minio_client.download_kb_document(doc["file_url"])
		
		# ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•ï¼ˆä¾›è§£æå™¨ä½¿ç”¨ï¼‰
		temp_dir = tempfile.gettempdir()
		file_hash = hashlib.md5(file_content).hexdigest()
		file_path = os.path.join(temp_dir, f"{file_hash}_{doc['filename']}")
		
		with open(file_path, 'wb') as f:
			f.write(file_content)
		
		# æäº¤åˆ°å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå†…éƒ¨ä¼šæ›´æ–°çŠ¶æ€ä¸º processingï¼‰
		processor = await get_document_processor(db[settings.mongodb_db_name])
		
		# è½¬æ¢ä¼˜å…ˆçº§
		priority_map = {
			"low": TaskPriority.LOW,
			"normal": TaskPriority.NORMAL,
			"high": TaskPriority.HIGH,
			"urgent": TaskPriority.URGENT
		}
		task_priority = priority_map.get(priority.lower(), TaskPriority.NORMAL)
		
		try:
			task_id = await processor.submit_document_processing(
				kb_id=kb_id,
				doc_id=doc_id,
				user_id=current_user.id,
				file_path=file_path,
				filename=doc["filename"],
				kb_settings=kb.kb_settings,
				priority=task_priority
			)
			
			# æ›´æ–°ä»»åŠ¡ID
			await kb_service.update_document_task_id(doc_id, task_id)
		except Exception as e:
			# ä»»åŠ¡æäº¤å¤±è´¥ï¼Œç¡®ä¿æ–‡æ¡£çŠ¶æ€ä¸ä¼šå¡åœ¨ processing
			await kb_service.update_document_status(
				doc_id,
				"failed",
				error_message=str(e)
			)
			raise
		
		logger.info(f"âœ… æ–‡æ¡£è§£æä»»åŠ¡å·²æäº¤: {doc['filename']}, task_id={task_id}")
		
		return {
			"success": True,
			"message": "æ–‡æ¡£è§£æä»»åŠ¡å·²æäº¤",
			"task_id": task_id,
			"doc_id": doc_id,
			"status": "processing"
		}
		
	except HTTPException:
		raise
	except RuntimeError as e:
		raise HTTPException(status_code=429, detail=str(e))
	except Exception as e:
		logger.error(f"è§£ææ–‡æ¡£å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"è§£ææ–‡æ¡£å¤±è´¥: {str(e)}")


@router.post("/kb/{kb_id}/documents/batch-parse")
async def batch_parse_documents(
	kb_id: str,
	doc_ids: List[str] = Body(..., embed=True),
	priority: str = "normal",
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	æ‰¹é‡è§£æå·²ä¸Šä¼ çš„æ–‡æ¡£
	
	Args:
		kb_id: çŸ¥è¯†åº“ID
		doc_ids: æ–‡æ¡£IDåˆ—è¡¨
		priority: ä»»åŠ¡ä¼˜å…ˆçº§ (low/normal/high/urgent)
	
	Returns:
		{
			"success": True,
			"message": "æ‰¹é‡è§£æä»»åŠ¡å·²æäº¤",
			"total": æ€»æ–‡æ¡£æ•°,
			"submitted": æˆåŠŸæäº¤æ•°,
			"failed": å¤±è´¥æ•°,
			"task_ids": [ä»»åŠ¡IDåˆ—è¡¨],
			"errors": [é”™è¯¯ä¿¡æ¯åˆ—è¡¨]
		}
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from ..services.document_processor import get_document_processor
		from ..services.async_task_processor import TaskPriority
		from ..utils.minio_client import minio_client
		import tempfile
		import os
		
		# éªŒè¯å‚æ•°
		if not doc_ids:
			raise HTTPException(status_code=422, detail="æ–‡æ¡£IDåˆ—è¡¨ä¸èƒ½ä¸ºç©º")
		
		logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡è§£ææ–‡æ¡£: kb_id={kb_id}, æ–‡æ¡£æ•°={len(doc_ids)}")
		
		# éªŒè¯çŸ¥è¯†åº“å­˜åœ¨
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
		if not kb:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		# è·å–æ–‡æ¡£å¤„ç†å™¨
		processor = await get_document_processor(db[settings.mongodb_db_name])
		
		# è½¬æ¢ä¼˜å…ˆçº§
		priority_map = {
			"low": TaskPriority.LOW,
			"normal": TaskPriority.NORMAL,
			"high": TaskPriority.HIGH,
			"urgent": TaskPriority.URGENT
		}
		task_priority = priority_map.get(priority.lower(), TaskPriority.NORMAL)
		
		# æ‰¹é‡å¤„ç†æ–‡æ¡£ï¼ˆå¹¶å‘å¤„ç†ä»¥æé«˜æ•ˆç‡ï¼‰
		results = {
			"submitted": 0,
			"failed": 0,
			"task_ids": [],
			"errors": []
		}
		
		async def process_single_document(doc_id: str):
			"""å¤„ç†å•ä¸ªæ–‡æ¡£çš„å¼‚æ­¥å‡½æ•°"""
			try:
				# è·å–æ–‡æ¡£è®°å½•
				doc = await kb_service.get_document(doc_id)
				if not doc:
					return {"success": False, "error": f"æ–‡æ¡£ {doc_id} ä¸å­˜åœ¨"}
				
				if doc.get("kb_id") != kb_id:
					return {"success": False, "error": f"æ–‡æ¡£ {doc_id} ä¸å±äºæ­¤çŸ¥è¯†åº“"}
				
				# æ£€æŸ¥æ–‡æ¡£çŠ¶æ€
				if not doc.get("file_url"):
					return {"success": False, "error": f"æ–‡æ¡£ {doc['filename']} å°šæœªä¸Šä¼ åˆ°æœåŠ¡å™¨"}
				
				# ä» MinIO ä¸‹è½½æ–‡æ¡£
				file_content = minio_client.download_kb_document(doc["file_url"])
				
				# ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•ï¼ˆä¾›è§£æå™¨ä½¿ç”¨ï¼‰
				temp_dir = tempfile.gettempdir()
				file_hash = hashlib.md5(file_content).hexdigest()
				file_path = os.path.join(temp_dir, f"{file_hash}_{doc['filename']}")
				
				with open(file_path, 'wb') as f:
					f.write(file_content)
				
				# æäº¤åˆ°å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå†…éƒ¨ä¼šæ›´æ–°çŠ¶æ€ä¸º processingï¼‰
				task_id = await processor.submit_document_processing(
					kb_id=kb_id,
					doc_id=doc_id,
					user_id=current_user.id,
					file_path=file_path,
					filename=doc["filename"],
					kb_settings=kb.kb_settings,
					priority=task_priority
				)
				
				# æ›´æ–°ä»»åŠ¡ID
				await kb_service.update_document_task_id(doc_id, task_id)
				
				logger.info(f"âœ… æ–‡æ¡£è§£æä»»åŠ¡å·²æäº¤: {doc['filename']}, task_id={task_id}")
				return {"success": True, "task_id": task_id, "filename": doc['filename']}
				
			except Exception as e:
				error_msg = f"æ–‡æ¡£ {doc_id} å¤„ç†å¤±è´¥: {str(e)}"
				logger.error(error_msg)
				return {"success": False, "error": error_msg}
		
		# ğŸš€ å¹¶å‘å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼ˆä½¿ç”¨ asyncio.gatherï¼‰
		logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘æäº¤ {len(doc_ids)} ä¸ªæ–‡æ¡£è§£æä»»åŠ¡")
		processing_results = await asyncio.gather(
			*[process_single_document(doc_id) for doc_id in doc_ids],
			return_exceptions=True
		)
		
		# ç»Ÿè®¡ç»“æœ
		for result in processing_results:
			if isinstance(result, Exception):
				results["failed"] += 1
				results["errors"].append(f"å¼‚å¸¸: {str(result)}")
			elif result.get("success"):
				results["submitted"] += 1
				results["task_ids"].append(result["task_id"])
			else:
				results["failed"] += 1
				error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
				results["errors"].append(error_msg)
				logger.error(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {error_msg}", exc_info=True)
				# æ³¨æ„ï¼šå•ä¸ªæ–‡æ¡£å¤„ç†å¤±è´¥æ—¶ï¼Œé”™è¯¯å¤„ç†å·²åœ¨process_single_documentä¸­å®Œæˆ
				# è¿™é‡Œä¸éœ€è¦å†æ¬¡å›æ»šçŠ¶æ€
		
		logger.info(f"âœ… æ‰¹é‡è§£æå®Œæˆ: æäº¤={results['submitted']}, å¤±è´¥={results['failed']}")
		
		return {
			"success": True,
			"message": f"æ‰¹é‡è§£æä»»åŠ¡å·²æäº¤: æˆåŠŸ {results['submitted']} ä¸ªï¼Œå¤±è´¥ {results['failed']} ä¸ª",
			"total": len(doc_ids),
			"submitted": results["submitted"],
			"failed": results["failed"],
			"task_ids": results["task_ids"],
			"errors": results["errors"]
		}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"æ‰¹é‡è§£ææ–‡æ¡£å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"æ‰¹é‡è§£ææ–‡æ¡£å¤±è´¥: {str(e)}")


@router.post("/kb/{kb_id}/documents/batch-parse-all")
async def batch_parse_all_documents(
	kb_id: str,
	priority: str = "normal",
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	æ‰¹é‡è§£æçŸ¥è¯†åº“ä¸­æ‰€æœ‰æœªè§£æçš„æ–‡æ¡£ï¼ˆä¸å—åˆ†é¡µé™åˆ¶ï¼‰
	
	è‡ªåŠ¨ç­›é€‰å‡ºçŠ¶æ€ä¸º 'uploaded' çš„æ–‡æ¡£è¿›è¡Œè§£æ
	
	Args:
		kb_id: çŸ¥è¯†åº“ID
		priority: ä»»åŠ¡ä¼˜å…ˆçº§ (low/normal/high/urgent)
	
	Returns:
		{
			"success": True,
			"message": "æ‰¹é‡è§£æä»»åŠ¡å·²æäº¤",
			"total": æ€»æ–‡æ¡£æ•°,
			"submitted": æˆåŠŸæäº¤æ•°,
			"failed": å¤±è´¥æ•°,
			"task_ids": [ä»»åŠ¡IDåˆ—è¡¨],
			"errors": [é”™è¯¯ä¿¡æ¯åˆ—è¡¨]
		}
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from ..services.document_processor import get_document_processor
		from ..services.async_task_processor import TaskPriority
		from ..utils.minio_client import minio_client
		import tempfile
		import os
		
		logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡è§£ææ‰€æœ‰æ–‡æ¡£: kb_id={kb_id}")
		
		# éªŒè¯çŸ¥è¯†åº“å­˜åœ¨
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
		if not kb:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		# è·å–æ‰€æœ‰çŠ¶æ€ä¸º 'uploaded' çš„æ–‡æ¡£ï¼ˆä¸åˆ†é¡µï¼ŒæŸ¥è¯¢å…¨éƒ¨ï¼‰
		collection = db[settings.mongodb_db_name].documents
		cursor = collection.find({
			"kb_id": kb_id,
			"status": "uploaded"
		})
		
		unparsed_docs = await cursor.to_list(length=None)  # length=None è¡¨ç¤ºè·å–å…¨éƒ¨
		
		if not unparsed_docs:
			return {
				"success": True,
				"message": "æ²¡æœ‰éœ€è¦è§£æçš„æ–‡æ¡£",
				"total": 0,
				"submitted": 0,
				"failed": 0,
				"task_ids": [],
				"errors": []
			}
		
		doc_ids = [str(doc["_id"]) for doc in unparsed_docs]
		logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(doc_ids)} ä¸ªæœªè§£æçš„æ–‡æ¡£")
		
		# è·å–æ–‡æ¡£å¤„ç†å™¨
		processor = await get_document_processor(db[settings.mongodb_db_name])
		
		# è½¬æ¢ä¼˜å…ˆçº§
		priority_map = {
			"low": TaskPriority.LOW,
			"normal": TaskPriority.NORMAL,
			"high": TaskPriority.HIGH,
			"urgent": TaskPriority.URGENT
		}
		task_priority = priority_map.get(priority.lower(), TaskPriority.NORMAL)
		
		# æ‰¹é‡å¤„ç†æ–‡æ¡£ï¼ˆå¹¶å‘å¤„ç†ä»¥æé«˜æ•ˆç‡ï¼‰
		results = {
			"submitted": 0,
			"failed": 0,
			"task_ids": [],
			"errors": []
		}
		
		async def process_single_document(doc_id: str):
			"""å¤„ç†å•ä¸ªæ–‡æ¡£çš„å¼‚æ­¥å‡½æ•°"""
			try:
				# è·å–æ–‡æ¡£è®°å½•
				doc = await kb_service.get_document(doc_id)
				if not doc:
					return {"success": False, "error": f"æ–‡æ¡£ {doc_id} ä¸å­˜åœ¨"}
				
				if doc.get("kb_id") != kb_id:
					return {"success": False, "error": f"æ–‡æ¡£ {doc_id} ä¸å±äºæ­¤çŸ¥è¯†åº“"}
				
				# æ£€æŸ¥æ–‡æ¡£çŠ¶æ€
				if not doc.get("file_url"):
					return {"success": False, "error": f"æ–‡æ¡£ {doc['filename']} å°šæœªä¸Šä¼ åˆ°æœåŠ¡å™¨"}
				
				# ä» MinIO ä¸‹è½½æ–‡æ¡£
				file_content = minio_client.download_kb_document(doc["file_url"])
				
				# ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•ï¼ˆä¾›è§£æå™¨ä½¿ç”¨ï¼‰
				temp_dir = tempfile.gettempdir()
				file_hash = hashlib.md5(file_content).hexdigest()
				file_path = os.path.join(temp_dir, f"{file_hash}_{doc['filename']}")
				
				with open(file_path, 'wb') as f:
					f.write(file_content)
				
				# æäº¤åˆ°å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå†…éƒ¨ä¼šæ›´æ–°çŠ¶æ€ä¸º processingï¼‰
				task_id = await processor.submit_document_processing(
					kb_id=kb_id,
					doc_id=doc_id,
					user_id=current_user.id,
					file_path=file_path,
					filename=doc["filename"],
					kb_settings=kb.kb_settings,
					priority=task_priority
				)
				
				# æ›´æ–°ä»»åŠ¡ID
				await kb_service.update_document_task_id(doc_id, task_id)
				
				logger.info(f"âœ… æ–‡æ¡£è§£æä»»åŠ¡å·²æäº¤: {doc['filename']}, task_id={task_id}")
				return {"success": True, "task_id": task_id, "filename": doc['filename']}
				
			except Exception as e:
				error_msg = f"æ–‡æ¡£ {doc_id} å¤„ç†å¤±è´¥: {str(e)}"
				logger.error(error_msg)
				return {"success": False, "error": error_msg}
		
		# ğŸš€ å¹¶å‘å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼ˆä½¿ç”¨ asyncio.gatherï¼‰
		logger.info(f"ğŸš€ å¼€å§‹å¹¶å‘æäº¤ {len(doc_ids)} ä¸ªæ–‡æ¡£è§£æä»»åŠ¡")
		processing_results = await asyncio.gather(
			*[process_single_document(doc_id) for doc_id in doc_ids],
			return_exceptions=True
		)
		
		# ç»Ÿè®¡ç»“æœ
		for result in processing_results:
			if isinstance(result, Exception):
				results["failed"] += 1
				results["errors"].append(f"å¼‚å¸¸: {str(result)}")
			elif result.get("success"):
				results["submitted"] += 1
				results["task_ids"].append(result["task_id"])
			else:
				results["failed"] += 1
				error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
				results["errors"].append(error_msg)
				logger.error(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {error_msg}", exc_info=True)
		
		logger.info(f"âœ… æ‰¹é‡è§£æå®Œæˆ: æäº¤={results['submitted']}, å¤±è´¥={results['failed']}")
		
		return {
			"success": True,
			"message": f"æ‰¹é‡è§£æä»»åŠ¡å·²æäº¤: æˆåŠŸ {results['submitted']} ä¸ªï¼Œå¤±è´¥ {results['failed']} ä¸ª",
			"total": len(doc_ids),
			"submitted": results["submitted"],
			"failed": results["failed"],
			"task_ids": results["task_ids"],
			"errors": results["errors"]
		}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"æ‰¹é‡è§£ææ‰€æœ‰æ–‡æ¡£å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"æ‰¹é‡è§£ææ‰€æœ‰æ–‡æ¡£å¤±è´¥: {str(e)}")


@router.post("/kb/{kb_id}/documents/{doc_id}/reset-status")
async def reset_document_status(
    kb_id: str,
    doc_id: str,
    current_user: User = Depends(get_current_user),
    db: AsyncIOMotorClient = Depends(get_database)
):
    """
    é‡ç½®æ–‡æ¡£çŠ¶æ€ï¼ˆå°† processing æˆ– failed çŠ¶æ€é‡ç½®ä¸º uploadedï¼‰
    
    ç”¨äºæ¸…ç†å¡ä½çš„æ–‡æ¡£ï¼Œä½¿å…¶å¯ä»¥é‡æ–°è§£æ
    """
    try:
        from ..services.knowledge_base_service import KnowledgeBaseService
        
        kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
        
        # éªŒè¯çŸ¥è¯†åº“å­˜åœ¨
        kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
        if not kb:
            raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
        
        # è·å–æ–‡æ¡£è®°å½•
        doc = await kb_service.get_document(doc_id)
        if not doc:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
        
        if doc.get("kb_id") != kb_id:
            raise HTTPException(status_code=403, detail="æ–‡æ¡£ä¸å±äºæ­¤çŸ¥è¯†åº“")
        
        current_status = doc.get("status")
        
        # åªå…è®¸é‡ç½® processing æˆ– failed çŠ¶æ€çš„æ–‡æ¡£
        if current_status not in ["processing", "failed"]:
            raise HTTPException(
                status_code=400,
                detail=f"åªèƒ½é‡ç½® processing æˆ– failed çŠ¶æ€çš„æ–‡æ¡£ï¼Œå½“å‰çŠ¶æ€: {current_status}"
            )
        
        # é‡ç½®ä¸º uploaded çŠ¶æ€
        await kb_service.update_document_status(
            doc_id,
            "uploaded",
            error_message=None
        )
        
        # æ¸…é™¤ä»»åŠ¡ID
        await db[settings.mongodb_db_name].kb_documents.update_one(
            {"_id": ObjectId(doc_id)},
            {
                "$unset": {"task_id": ""},
                "$set": {"updated_at": datetime.utcnow().isoformat()}
            }
        )
        
        logger.info(f"âœ… æ–‡æ¡£çŠ¶æ€å·²é‡ç½®: {doc['filename']} ({current_status} -> uploaded)")
        
        return {
            "success": True,
            "message": f"æ–‡æ¡£çŠ¶æ€å·²é‡ç½®ä¸º uploadedï¼Œå¯ä»¥é‡æ–°è§£æ",
            "doc_id": doc_id,
            "old_status": current_status,
            "new_status": "uploaded"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é‡ç½®æ–‡æ¡£çŠ¶æ€å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é‡ç½®æ–‡æ¡£çŠ¶æ€å¤±è´¥: {str(e)}")


@router.get("/kb/{kb_id}/documents/{doc_id}/download")
async def download_document(
	kb_id: str,
	doc_id: str,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	ã€æ–°ã€‘ä¸‹è½½åŸå§‹æ–‡æ¡£ï¼ˆä» MinIOï¼‰
	
	è¿”å›åŸå§‹æ–‡ä»¶ä¾›ç”¨æˆ·ä¸‹è½½
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from ..utils.minio_client import minio_client
		from fastapi.responses import StreamingResponse
		from bson import ObjectId
		import io
		
		# éªŒè¯çŸ¥è¯†åº“å­˜åœ¨ï¼ˆå…ˆå°è¯•ç”¨æˆ·è‡ªå·±çš„çŸ¥è¯†åº“ï¼‰
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
		
		# å¦‚æœæ‰¾ä¸åˆ°ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯æ‹‰å–çš„çŸ¥è¯†åº“ï¼ˆé€šè¿‡ original_kb_id æŸ¥æ‰¾ï¼‰
		has_access = False
		if kb:
			has_access = True
		else:
			# æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ‹‰å–äº†è¿™ä¸ªçŸ¥è¯†åº“
			pulled_kb = await db[settings.mongodb_db_name].pulled_knowledge_bases.find_one({
				"user_id": current_user.id,
				"original_kb_id": kb_id,
				"enabled": True
			})
			if pulled_kb:
				has_access = True
		
		if not has_access:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		# è·å–æ–‡æ¡£è®°å½•
		doc = await kb_service.get_document(doc_id)
		if not doc:
			raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
		
		if doc.get("kb_id") != kb_id:
			raise HTTPException(status_code=403, detail="æ–‡æ¡£ä¸å±äºæ­¤çŸ¥è¯†åº“")
		
		if not doc.get("file_url"):
			raise HTTPException(status_code=400, detail="æ–‡æ¡£åŸæ–‡ä»¶ä¸å­˜åœ¨")
		
		# ä» MinIO ä¸‹è½½æ–‡æ¡£
		file_content = minio_client.download_kb_document(doc["file_url"])
		
		# è¿”å›æ–‡ä»¶æµ
		import mimetypes
		content_type = mimetypes.guess_type(doc["filename"])[0] or "application/octet-stream"
		
		return StreamingResponse(
			io.BytesIO(file_content),
			media_type=content_type,
			headers={
				"Content-Disposition": f'attachment; filename="{doc["filename"]}"'
			}
		)
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"ä¸‹è½½æ–‡æ¡£å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"ä¸‹è½½æ–‡æ¡£å¤±è´¥: {str(e)}")


@router.get("/kb/{kb_id}/documents/{doc_id}/content")
async def get_document_content(
	kb_id: str,
	doc_id: str,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	ã€æ–°ã€‘è·å–æ–‡æ¡£åŸæ–‡å†…å®¹ï¼ˆç”¨äºå‰ç«¯é¢„è§ˆï¼‰
	
	è¿”å›æ–‡æ¡£çš„åŸæ–‡å†…å®¹ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰ï¼Œç”¨äºåœ¨å‰ç«¯æ˜¾ç¤º
	ä¸ä¸‹è½½æ¥å£ä¸åŒï¼Œæ­¤æ¥å£è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å«æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from ..utils.minio_client import minio_client
		from app.utils.document_parsers import DocumentParserFactory
		from bson import ObjectId
		
		# éªŒè¯çŸ¥è¯†åº“å­˜åœ¨ï¼ˆå…ˆå°è¯•ç”¨æˆ·è‡ªå·±çš„çŸ¥è¯†åº“ï¼‰
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
		
		# å¦‚æœæ‰¾ä¸åˆ°ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯æ‹‰å–çš„çŸ¥è¯†åº“ï¼ˆé€šè¿‡ original_kb_id æŸ¥æ‰¾ï¼‰
		has_access = False
		if kb:
			has_access = True
		else:
			# æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ‹‰å–äº†è¿™ä¸ªçŸ¥è¯†åº“
			pulled_kb = await db[settings.mongodb_db_name].pulled_knowledge_bases.find_one({
				"user_id": current_user.id,
				"original_kb_id": kb_id,
				"enabled": True
			})
			if pulled_kb:
				has_access = True
		
		if not has_access:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		# è·å–æ–‡æ¡£è®°å½•
		doc = await kb_service.get_document(doc_id)
		if not doc:
			raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
		
		if doc.get("kb_id") != kb_id:
			raise HTTPException(status_code=403, detail="æ–‡æ¡£ä¸å±äºæ­¤çŸ¥è¯†åº“")
		
		if not doc.get("file_url"):
			raise HTTPException(status_code=400, detail="æ–‡æ¡£åŸæ–‡ä»¶ä¸å­˜åœ¨")
		
		# ä» MinIO ä¸‹è½½æ–‡æ¡£
		file_content = minio_client.download_kb_document(doc["file_url"])
		
		# è§£ææ–‡æ¡£å†…å®¹ï¼ˆæå–æ–‡æœ¬ï¼‰
		# åˆå§‹åŒ–è§£æå™¨ï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
		if not hasattr(DocumentParserFactory, '_initialized'):
			DocumentParserFactory.initialize_default_parsers()
			DocumentParserFactory._initialized = True
		
		# è§£ææ–‡æ¡£
		parse_result = await DocumentParserFactory.parse_document(
			file_content,
			doc["filename"]
		)
		
		if not parse_result.success:
			raise HTTPException(status_code=500, detail=f"æ–‡æ¡£è§£æå¤±è´¥: {parse_result.error_message}")
		
		# è¿”å›æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®
		return {
			"success": True,
			"document": {
				"id": str(doc["_id"]),
				"kb_id": kb_id,
				"filename": doc["filename"],
				"file_type": doc.get("file_type"),
				"file_size": doc.get("file_size"),
				"content": parse_result.text,
				"chunk_count": doc.get("chunk_count", 0),
				"upload_time": doc.get("created_at"),
				"metadata": parse_result.metadata
			}
		}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"è·å–æ–‡æ¡£å†…å®¹å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£å†…å®¹å¤±è´¥: {str(e)}")


@router.get("/kb/{kb_id}/documents/{doc_id}/chunks")
async def get_document_chunks(
	kb_id: str,
	doc_id: str,
	page: int = 1,
	page_size: int = 20,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	è·å–æ–‡æ¡£çš„åˆ†ç‰‡åˆ—è¡¨
	
	ç‰¹æ€§ï¼š
	- ä»ChromaDBè·å–åˆ†ç‰‡æ•°æ®
	- æ”¯æŒåˆ†é¡µ
	- å¼‚æ­¥éé˜»å¡
	- åŒ…å«åˆ†ç‰‡å†…å®¹å’Œå…ƒæ•°æ®
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from bson import ObjectId
		import asyncio
		
		# éªŒè¯çŸ¥è¯†åº“å­˜åœ¨å’Œæƒé™ï¼ˆå…ˆå°è¯•ç”¨æˆ·è‡ªå·±çš„çŸ¥è¯†åº“ï¼‰
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
		
		# å¦‚æœæ‰¾ä¸åˆ°ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯æ‹‰å–çš„çŸ¥è¯†åº“ï¼ˆé€šè¿‡ original_kb_id æŸ¥æ‰¾ï¼‰
		has_access = False
		if kb:
			has_access = True
		else:
			# æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ‹‰å–äº†è¿™ä¸ªçŸ¥è¯†åº“
			pulled_kb = await db[settings.mongodb_db_name].pulled_knowledge_bases.find_one({
				"user_id": current_user.id,
				"original_kb_id": kb_id,
				"enabled": True
			})
			if pulled_kb:
				has_access = True
		
		if not has_access:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		# éªŒè¯æ–‡æ¡£å­˜åœ¨
		doc = await kb_service.get_document(doc_id)
		if not doc:
			raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
		
		if doc.get("kb_id") != kb_id:
			raise HTTPException(status_code=403, detail="æ–‡æ¡£ä¸å±äºæ­¤çŸ¥è¯†åº“")
		
		# æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²è§£æ
		if doc.get("status") != "completed":
			raise HTTPException(
				status_code=400, 
				detail=f"æ–‡æ¡£å°šæœªå®Œæˆè§£æï¼Œå½“å‰çŠ¶æ€: {doc.get('status', 'unknown')}"
			)
		
		# ä»ChromaDBè·å–åˆ†ç‰‡ï¼ˆå¼‚æ­¥éé˜»å¡ï¼‰
		kb_settings = kb.kb_settings if kb.kb_settings else {}
		
		async def get_chunks_from_vectorstore():
			"""å¼‚æ­¥è·å–å‘é‡å­˜å‚¨ä¸­çš„åˆ†ç‰‡"""
			loop = asyncio.get_event_loop()
			
			def _get_chunks():
				"""åŒæ­¥è·å–åˆ†ç‰‡ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
				import time
				
				# è·å–vectorstoreç»„ä»¶
				_, vectorstore, _ = _get_kb_components(kb_settings)
				vector_db = kb_settings.get("vector_db", "chroma")
				
				# æ ¹æ®ä¸åŒçš„å‘é‡æ•°æ®åº“ç±»å‹é‡‡ç”¨ä¸åŒçš„è·å–æ–¹å¼
				if vector_db == "faiss":
					# ========== FAISS è·å–æ–¹å¼ ==========
					try:
						chunks = []
						
						# FAISS ä½¿ç”¨ docstore å­˜å‚¨æ–‡æ¡£ï¼Œéå†æ‰€æœ‰æ–‡æ¡£æŸ¥æ‰¾åŒ¹é…çš„ doc_id
						if hasattr(vectorstore._store, 'docstore') and vectorstore._store.docstore:
							docstore = vectorstore._store.docstore
							
							# éå† docstore ä¸­çš„æ‰€æœ‰æ–‡æ¡£
							for chunk_id, doc in docstore._dict.items():
								metadata = doc.metadata if hasattr(doc, 'metadata') else {}
								
								# æ£€æŸ¥æ˜¯å¦å±äºè¯¥æ–‡æ¡£
								if metadata.get('doc_id') == doc_id:
									chunk = {
										"id": chunk_id,
										"content": doc.page_content if hasattr(doc, 'page_content') else "",
										"metadata": metadata,
										"chunk_index": metadata.get('chunk_index', 0)
									}
									chunks.append(chunk)
							
							# æŒ‰ chunk_index æ’åº
							chunks.sort(key=lambda x: x['chunk_index'])
							logger.info(f"âœ… ä» FAISS æˆåŠŸè¯»å– {len(chunks)} ä¸ªåˆ†ç‰‡")
							return chunks
						else:
							logger.error("âŒ FAISS vectorstore ç¼ºå°‘ docstore")
							return []
							
					except Exception as e:
						logger.error(f"âŒ ä» FAISS è·å–åˆ†ç‰‡å¤±è´¥: {e}", exc_info=True)
						raise
						
				else:
					# ========== ChromaDB è·å–æ–¹å¼ ==========
					max_retries = 3
					retry_delay = 2.0  # æ¯æ¬¡é‡è¯•ç­‰å¾…2ç§’
					
					for attempt in range(max_retries):
						try:
							# è·å–ChromaDB collection (ChromaVectorStore._store._collection)
							chroma_collection = vectorstore._store._collection
							
							# ğŸ”¥ åœ¨è¯»å–å‰å…ˆè§¦å‘ä¸€æ¬¡compactionï¼ˆé€šè¿‡count()ï¼‰å¹¶ç­‰å¾…
							if attempt == 0:
								try:
									doc_count = chroma_collection.count()
									logger.info(f"ğŸ“– [è¯»å–å‰æ£€æŸ¥] collectionæ–‡æ¡£æ•°: {doc_count}ï¼Œç­‰å¾…compactionå®Œæˆ...")
									time.sleep(2.0)  # ç­‰å¾…2ç§’è®©compactionå®Œæˆ
								except Exception as check_err:
									logger.warning(f"âš ï¸ è¯»å–å‰æ£€æŸ¥å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {check_err}")
							
							# æŸ¥è¯¢è¯¥æ–‡æ¡£çš„æ‰€æœ‰chunks
							results = chroma_collection.get(
								where={"doc_id": doc_id},
								include=["metadatas", "documents"]  # åŒ…å«å…ƒæ•°æ®å’Œæ–‡æ¡£å†…å®¹
							)
							
							if not results or not results['ids']:
								return []
							
							# æ„å»ºåˆ†ç‰‡åˆ—è¡¨
							chunks = []
							for idx, chunk_id in enumerate(results['ids']):
								chunk = {
									"id": chunk_id,
									"content": results['documents'][idx] if idx < len(results['documents']) else "",
									"metadata": results['metadatas'][idx] if idx < len(results['metadatas']) else {},
									"chunk_index": results['metadatas'][idx].get('chunk_index', idx) if idx < len(results['metadatas']) else idx
								}
								chunks.append(chunk)
							
							# æŒ‰chunk_indexæ’åº
							chunks.sort(key=lambda x: x['chunk_index'])
							
							logger.info(f"âœ… ä» ChromaDB æˆåŠŸè¯»å– {len(chunks)} ä¸ªåˆ†ç‰‡")
							return chunks
							
						except Exception as e:
							error_msg = str(e)
							is_compaction_error = (
								"Error loading hnsw index" in error_msg or
								"Error constructing hnsw segment reader" in error_msg or
								"Error sending backfill request to compactor" in error_msg
							)
							
							if is_compaction_error and attempt < max_retries - 1:
								logger.warning(
									f"âš ï¸ æ£€æµ‹åˆ°compactionæœªå®Œæˆé”™è¯¯ï¼ˆç¬¬{attempt + 1}æ¬¡å°è¯•ï¼‰ï¼Œ"
									f"ç­‰å¾…{retry_delay}ç§’åé‡è¯•..."
								)
								time.sleep(retry_delay)
								continue  # é‡è¯•
							else:
								# ä¸æ˜¯compactioné”™è¯¯ï¼Œæˆ–è€…å·²ç»é‡è¯•æ¬¡æ•°ç”¨å®Œ
								logger.error(f"âŒ ä»ChromaDBè·å–åˆ†ç‰‡å¤±è´¥: {error_msg}", exc_info=True)
								raise
			
			# åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ“ä½œ
			return await loop.run_in_executor(None, _get_chunks)
		
		# å¼‚æ­¥è·å–æ‰€æœ‰åˆ†ç‰‡
		all_chunks = await get_chunks_from_vectorstore()
		
		# åˆ†é¡µå¤„ç†
		total_chunks = len(all_chunks)
		start_idx = (page - 1) * page_size
		end_idx = start_idx + page_size
		chunks = all_chunks[start_idx:end_idx]
		
		return {
			"success": True,
			"document": {
				"id": str(doc["_id"]),
				"filename": doc["filename"],
				"file_type": doc.get("file_type"),
			},
			"chunks": chunks,
			"pagination": {
				"page": page,
				"page_size": page_size,
				"total": total_chunks,
				"total_pages": (total_chunks + page_size - 1) // page_size
			}
		}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"è·å–æ–‡æ¡£åˆ†ç‰‡å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£åˆ†ç‰‡å¤±è´¥: {str(e)}")


@router.delete("/kb/{kb_id}/documents/{doc_id}")
async def delete_document(
	kb_id: str,
	doc_id: str,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	åˆ é™¤æ–‡æ¡£
	
	ç‰¹æ€§ï¼š
	- åˆ é™¤æ–‡æ¡£è®°å½•
	- åˆ é™¤ MinIO ä¸­çš„åŸæ–‡ä»¶
	- å¼‚æ­¥åˆ é™¤å‘é‡æ•°æ®
	- æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from ..utils.minio_client import minio_client
		
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		
		# è·å–æ–‡æ¡£ä¿¡æ¯ï¼ˆç”¨äºåˆ é™¤ MinIO æ–‡ä»¶ï¼‰
		doc = await kb_service.get_document(doc_id)
		if doc and doc.get("file_url"):
			# åˆ é™¤ MinIO ä¸­çš„æ–‡ä»¶
			minio_client.delete_kb_document(doc["file_url"])
		
		# åˆ é™¤æ–‡æ¡£è®°å½•å’Œå‘é‡æ•°æ®
		success = await kb_service.delete_document(
			doc_id=doc_id,
			kb_id=kb_id,
			user_id=current_user.id
		)
		
		if not success:
			raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		return {"success": True, "message": "æ–‡æ¡£å·²åˆ é™¤"}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")


@router.post("/kb/{kb_id}/search", response_model=KBSearchResponse)
async def search_knowledge_base(
	kb_id: str,
	search_request: KBSearchRequest,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	æœç´¢çŸ¥è¯†åº“ï¼ˆè¯­ä¹‰æœç´¢ï¼‰
	
	ç‰¹æ€§ï¼š
	- å¼‚æ­¥å‘é‡æœç´¢
	- ä¸é˜»å¡å…¶ä»–ç”¨æˆ·
	- æ”¯æŒæ··åˆæœç´¢
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		
		# éªŒè¯çŸ¥è¯†åº“å­˜åœ¨
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
		if not kb:
			raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")
		
		# æ‰§è¡Œå¼‚æ­¥æœç´¢
		from ..utils.embedding.pipeline import Retriever
		from ..utils.embedding.path_utils import build_chroma_persist_dir, get_chroma_collection_name
		from ..services.embedding_manager import get_embedding_manager
		from ..services.vectorstore_manager import get_vectorstore_manager
		
		# æ„å»ºçŸ¥è¯†åº“ç»„ä»¶ï¼ˆä½¿ç”¨å…¨å±€å•ä¾‹ï¼‰
		_, vectorstore, _ = _get_kb_components(kb.kb_settings)
		
		# è·å–è·ç¦»åº¦é‡å’Œé˜ˆå€¼ï¼ˆä¼˜å…ˆä½¿ç”¨è¯·æ±‚å‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨çŸ¥è¯†åº“é…ç½®ï¼‰
		distance_metric = search_request.distance_metric
		if distance_metric is None:
			search_params = kb.kb_settings.get("search_params", {})
			distance_metric = search_params.get("distance_metric", "cosine")
		
		similarity_threshold = search_request.similarity_threshold
		if similarity_threshold is None:
			similarity_threshold = kb.kb_settings.get("similarity_threshold")
		
		retriever = Retriever(
			vector_store=vectorstore,
			similarity_threshold=similarity_threshold,
			distance_metric=distance_metric
		)
		
		# ğŸ› æ‰“å°è°ƒè¯•ä¿¡æ¯
		logger.info(f"ğŸ” [æ£€ç´¢è°ƒè¯•] æŸ¥è¯¢æ–‡æœ¬: {search_request.query[:100]}")
		logger.info(f"ğŸ” [æ£€ç´¢è°ƒè¯•] top_k: {search_request.top_k}, ç›¸ä¼¼åº¦é˜ˆå€¼: {similarity_threshold}, è·ç¦»åº¦é‡: {distance_metric}")
		
		# ç›´æ¥æ‰§è¡Œå¼‚æ­¥æœç´¢ï¼ˆä¼ å…¥é˜ˆå€¼å’Œtop_kï¼‰
		results = await retriever.search(
			query=search_request.query,
			top_k=search_request.top_k,
			similarity_threshold=similarity_threshold
		)
		
		logger.info(f"ğŸ” [æ£€ç´¢è°ƒè¯•] åŸå§‹ç»“æœæ•°: {len(results)}")
		
		# æ ¼å¼åŒ–ç»“æœ + æ‰¹é‡æŸ¥è¯¢æ–‡æ¡£åç§°
		search_results = []
		
		# ğŸ”§ æ”¶é›†æ‰€æœ‰ doc_idï¼Œæ‰¹é‡æŸ¥è¯¢æ–‡æ¡£åç§°
		doc_ids = []
		for doc, _ in results:
			doc_id = doc.metadata.get("doc_id")
			if doc_id:
				doc_ids.append(doc_id)
		
		# æ‰¹é‡æŸ¥è¯¢æ–‡æ¡£åç§°
		filename_map = {}
		if doc_ids:
			try:
				from bson import ObjectId
				docs_cursor = db[settings.mongodb_db_name].documents.find(
					{"_id": {"$in": [ObjectId(did) for did in doc_ids if ObjectId.is_valid(did)]}},
					{"_id": 1, "filename": 1}
				)
				async for doc_record in docs_cursor:
					filename_map[str(doc_record["_id"])] = doc_record.get("filename", "")
			except Exception as e:
				logger.warning(f"âš ï¸ æ‰¹é‡æŸ¥è¯¢filenameå¤±è´¥: {e}")
		
		for idx, (doc, distance) in enumerate(results):
			# æ ¹æ®è·ç¦»åº¦é‡ç±»å‹è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
			similarity_score = calculate_score_from_distance(float(distance), distance_metric)
			
			# ğŸ› æ‰“å°æ¯ä¸ªç»“æœçš„è¯¦ç»†ä¿¡æ¯
			logger.info(f"ğŸ” [ç»“æœ {idx+1}] è·ç¦»={distance:.4f}, ç›¸ä¼¼åº¦={similarity_score:.4f}, å†…å®¹å‰50å­—: {doc.page_content[:50]}")
			
			# è·å–æ–‡æ¡£åç§°
			doc_id = doc.metadata.get("doc_id")
			filename = doc.metadata.get("filename") or filename_map.get(doc_id, "")
			
			# ğŸ†• æ·»åŠ  document_name å­—æ®µï¼ˆå‰ç«¯éœ€è¦ï¼‰
			metadata_with_name = doc.metadata.copy()
			if filename:
				metadata_with_name["filename"] = filename
			
			search_results.append(
				KBSearchResult(
					content=doc.page_content,
					score=similarity_score,
					distance=float(distance),
					metadata=metadata_with_name,
					chunk_id=doc.metadata.get("chunk_id"),
					doc_id=doc_id,
					document_name=filename or doc.metadata.get("source", "æœªçŸ¥æ–‡æ¡£")  # ğŸ†• æ·»åŠ æ–‡æ¡£åç§°
				)
			)
		
		return KBSearchResponse(
			success=True,
			results=search_results,
			total=len(search_results)
		)
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"æœç´¢å¤±è´¥: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")


@router.post("/kb/multi-search", response_model=MultiKBSearchResponse)
async def search_multiple_knowledge_bases(
	search_request: MultiKBSearchRequest,
	current_user: User = Depends(get_current_user),
	db: AsyncIOMotorClient = Depends(get_database)
):
	"""
	å¤šçŸ¥è¯†åº“å¹¶è¡Œæ£€ç´¢ï¼ˆä¼ä¸šçº§é«˜æ€§èƒ½ï¼‰
	
	ç‰¹æ€§ï¼š
	âœ… å®Œå…¨å¼‚æ­¥å¹¶è¡Œ - ä¸é˜»å¡ä¸»çº¿ç¨‹
	âœ… ä¿¡å·é‡æ§åˆ¶å¹¶å‘ - é¿å…èµ„æºè€—å°½
	âœ… æ™ºèƒ½ç»“æœåˆå¹¶ - æ”¯æŒå¤šç§ç­–ç•¥
	âœ… ç”¨æˆ·çº§éš”ç¦» - äº’ä¸å½±å“
	
	ä½¿ç”¨åœºæ™¯ï¼š
	- åŒæ—¶æ£€ç´¢"è®ºæ–‡åº“"å’Œ"äººå·¥æ™ºèƒ½åº“"
	- è·¨å¤šä¸ªçŸ¥è¯†åº“æŸ¥æ‰¾ç›¸å…³å†…å®¹
	- æé«˜æ£€ç´¢è¦†ç›–ç‡
	
	Args:
		search_request: å¤šçŸ¥è¯†åº“æ£€ç´¢è¯·æ±‚
			- kb_ids: çŸ¥è¯†åº“IDåˆ—è¡¨
			- query: æŸ¥è¯¢æ–‡æœ¬
			- top_k_per_kb: æ¯ä¸ªåº“è¿”å›ç»“æœæ•°
			- final_top_k: æœ€ç»ˆè¿”å›æ€»æ•°
			- merge_strategy: åˆå¹¶ç­–ç•¥
	
	Returns:
		MultiKBSearchResponse: åˆå¹¶åçš„æ£€ç´¢ç»“æœ
	"""
	try:
		from ..services.knowledge_base_service import KnowledgeBaseService
		from ..services.multi_kb_retriever import get_multi_kb_retriever
		
		logger.info(f"ğŸ” å¤šçŸ¥è¯†åº“æ£€ç´¢è¯·æ±‚: user={current_user.id}, kb_count={len(search_request.kb_ids)}, "
		           f"query='{search_request.query[:50]}...'")
		
		# 1. éªŒè¯å¹¶è·å–æ‰€æœ‰çŸ¥è¯†åº“é…ç½®
		kb_service = KnowledgeBaseService(db[settings.mongodb_db_name])
		kb_configs = []
		
		for kb_id in search_request.kb_ids:
			# éªŒè¯çŸ¥è¯†åº“å­˜åœ¨ä¸”æœ‰æƒé™
			kb = await kb_service.get_knowledge_base(kb_id, current_user.id)
			if not kb:
				logger.warning(f"âš ï¸ çŸ¥è¯†åº“ {kb_id} ä¸å­˜åœ¨æˆ–æ— æƒé™,è·³è¿‡")
				continue
			
			kb_configs.append({
				'kb_id': kb_id,
				'kb_name': kb.name,
				'kb_settings': kb.kb_settings
			})
		
		if not kb_configs:
			raise HTTPException(
				status_code=404,
				detail="æ‰€æœ‰æŒ‡å®šçš„çŸ¥è¯†åº“éƒ½ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®"
			)
		
		# 2. è·å–å¤šçŸ¥è¯†åº“æ£€ç´¢å™¨å•ä¾‹
		retriever = await get_multi_kb_retriever()
		
		# 3. å¹¶è¡Œæ£€ç´¢ï¼ˆå®Œå…¨å¼‚æ­¥,ä¸é˜»å¡ï¼‰
		results = await retriever.retrieve_from_multiple_kbs(
			query=search_request.query,
			kb_configs=kb_configs,
			top_k_per_kb=search_request.top_k_per_kb,
			similarity_threshold=search_request.similarity_threshold,
			merge_strategy=search_request.merge_strategy,
			final_top_k=search_request.final_top_k
		)
		
		# 4. æ ¼å¼åŒ–å“åº”
		formatted_results = retriever.format_results_for_api(results)
		
		logger.info(f"âœ… å¤šçŸ¥è¯†åº“æ£€ç´¢å®Œæˆ: è¿”å› {len(formatted_results)} ä¸ªç»“æœ")
		
		return MultiKBSearchResponse(
			success=True,
			results=formatted_results,
			total_results=len(formatted_results),
			kb_count=len(kb_configs),
			merge_strategy=search_request.merge_strategy
		)
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"âŒ å¤šçŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
		raise HTTPException(status_code=500, detail=f"å¤šçŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {str(e)}")


@router.get("/kb/task/{task_id}/status")
async def get_task_status_detail(
	task_id: str,
	current_user: User = Depends(get_current_user)
):
	"""
	è·å–ä»»åŠ¡è¯¦ç»†çŠ¶æ€
	
	ç‰¹æ€§ï¼š
	- å®æ—¶æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
	- ä¸é˜»å¡ä¸»æœåŠ¡
	"""
	try:
		from ..services.async_task_processor import get_task_processor
		
		processor = get_task_processor()
		status = await processor.get_task_status(task_id)
		
		if not status:
			raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
		
		return {
			"success": True,
			**status
		}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
		raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")


@router.post("/kb/task/{task_id}/cancel")
async def cancel_task_detail(
	task_id: str,
	current_user: User = Depends(get_current_user)
):
	"""
	å–æ¶ˆä»»åŠ¡
	
	ç‰¹æ€§ï¼š
	- å¼‚æ­¥å–æ¶ˆ
	- æ›´æ–°æ–‡æ¡£çŠ¶æ€
	"""
	try:
		from ..services.async_task_processor import get_task_processor
		
		processor = get_task_processor()
		success = await processor.cancel_task(task_id)
		
		if not success:
			raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æ³•å–æ¶ˆ")
		
		return {
			"success": True,
			"message": "ä»»åŠ¡å·²å–æ¶ˆ"
		}
		
	except HTTPException:
		raise
	except Exception as e:
		logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")
		raise HTTPException(status_code=500, detail=f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")