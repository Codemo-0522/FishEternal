"""
å…¨å±€ Embedding æ¨¡å‹å®ä¾‹ç®¡ç†å™¨
ç¡®ä¿åŒä¸€ä¸ªæ¨¡å‹é…ç½®åªåŠ è½½ä¸€æ¬¡åˆ°å†…å­˜ï¼Œæ‰€æœ‰ç”¨æˆ·å…±äº«åŒä¸€ä¸ªå®ä¾‹
"""
import logging
import threading
from typing import Dict, Tuple, Any, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class EmbeddingKey:
    """Embedding æ¨¡å‹çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆç”¨ä½œç¼“å­˜ keyï¼‰"""
    provider: str  # "ollama", "local", "ark"
    model: str     # æ¨¡å‹åç§°æˆ–è·¯å¾„
    base_url: Optional[str] = None  # API æœåŠ¡åœ°å€ï¼ˆollama/arkï¼‰
    
    def __hash__(self):
        return hash((self.provider, self.model, self.base_url))


class EmbeddingManager:
    """
    å…¨å±€ Embedding å®ä¾‹ç®¡ç†å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    èŒè´£ï¼š
    1. ç®¡ç†æ‰€æœ‰ Embedding æ¨¡å‹å®ä¾‹çš„ç”Ÿå‘½å‘¨æœŸ
    2. ç¡®ä¿ç›¸åŒé…ç½®çš„æ¨¡å‹åªåŠ è½½ä¸€æ¬¡
    3. çº¿ç¨‹å®‰å…¨çš„å®ä¾‹è·å–
    4. æ”¯æŒæ‰€æœ‰ provider: ollama, local, ark
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, '_initialized'):
            self._instances: Dict[EmbeddingKey, Any] = {}
            self._instance_lock = threading.Lock()
            self._initialized = True
            logger.info("âœ… EmbeddingManager åˆå§‹åŒ–å®Œæˆ")
    
    def get_or_create(
        self,
        provider: str,
        model: Optional[str] = None,
        base_url: Optional[str] = None,
        api_key: Optional[str] = None,
        local_model_path: Optional[str] = None,
        **kwargs
    ) -> Any:
        """
        è·å–æˆ–åˆ›å»º Embedding å®ä¾‹
        
        Args:
            provider: æä¾›å•† ("ollama", "local", "ark")
            model: æ¨¡å‹åç§°
            base_url: API æœåŠ¡åœ°å€ï¼ˆollama/arkï¼‰
            api_key: API å¯†é’¥ï¼ˆarkï¼‰
            local_model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆlocalï¼‰
            **kwargs: å…¶ä»–æ¨¡å‹ç‰¹å®šå‚æ•°
            
        Returns:
            Embedding å®ä¾‹ï¼ˆæ‰€æœ‰ç”¨æˆ·å…±äº«ï¼‰
            
        Raises:
            ValueError: å‚æ•°é”™è¯¯
            RuntimeError: æ¨¡å‹åŠ è½½å¤±è´¥
        """
        # 1. æ ‡å‡†åŒ–å‚æ•°
        provider = provider.lower()
        
        if provider == "ollama":
            base_url = base_url or "http://localhost:11434"
            model = model or "nomic-embed-text:v1.5"
            cache_key = EmbeddingKey(provider="ollama", model=model, base_url=base_url)
            
        elif provider == "local":
            # ç¡®å®šå®é™…æ¨¡å‹è·¯å¾„
            if local_model_path:
                model_path = local_model_path
            elif model:
                model_path = f"checkpoints/embeddings/{model}"
            else:
                model_path = "checkpoints/embeddings/all-MiniLM-L6-v2"
            
            # ä½¿ç”¨è·¯å¾„ä½œä¸º key
            cache_key = EmbeddingKey(provider="local", model=model_path)
            
        elif provider == "ark":
            if not api_key:
                raise ValueError("ArkEmbeddings éœ€è¦æä¾› api_key")
            model = model or "doubao-embedding-large-text-250515"
            # api_key ä¸ä½œä¸º keyï¼Œå› ä¸ºåŒä¸€ä¸ªæ¨¡å‹çš„ api_key åº”è¯¥ç›¸åŒ
            cache_key = EmbeddingKey(provider="ark", model=model, base_url=base_url)
            
        else:
            raise ValueError(f"æœªçŸ¥çš„ provider: {provider}")
        
        # 2. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŒé‡æ£€æŸ¥é”å®šï¼‰
        if cache_key in self._instances:
            logger.info(f"â™»ï¸ å¤ç”¨å·²åŠ è½½çš„ Embedding å®ä¾‹: {cache_key}")
            return self._instances[cache_key]
        
        # 3. åŠ è½½æ–°å®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        with self._instance_lock:
            # å†æ¬¡æ£€æŸ¥ï¼ˆå¯èƒ½å…¶ä»–çº¿ç¨‹å·²åˆ›å»ºï¼‰
            if cache_key in self._instances:
                logger.info(f"â™»ï¸ å¤ç”¨å·²åŠ è½½çš„ Embedding å®ä¾‹: {cache_key}")
                return self._instances[cache_key]
            
            logger.info(f"â³ å¼€å§‹åŠ è½½ Embedding æ¨¡å‹: {cache_key}")
            
            try:
                instance = self._create_instance(
                    provider=provider,
                    model=model,
                    base_url=base_url,
                    api_key=api_key,
                    local_model_path=local_model_path,
                    cache_key=cache_key,
                    **kwargs
                )
                
                self._instances[cache_key] = instance
                logger.info(f"âœ… Embedding æ¨¡å‹åŠ è½½æˆåŠŸ: {cache_key}")
                logger.info(f"ğŸ“Š å½“å‰å·²åŠ è½½æ¨¡å‹æ•°é‡: {len(self._instances)}")
                
                return instance
                
            except Exception as e:
                logger.error(f"âŒ Embedding æ¨¡å‹åŠ è½½å¤±è´¥: {cache_key} - {e}")
                raise RuntimeError(f"Embedding æ¨¡å‹åŠ è½½å¤±è´¥: {e}") from e
    
    def _create_instance(
        self,
        provider: str,
        model: Optional[str],
        base_url: Optional[str],
        api_key: Optional[str],
        local_model_path: Optional[str],
        cache_key: EmbeddingKey,
        **kwargs
    ) -> Any:
        """
        å®é™…åˆ›å»º Embedding å®ä¾‹çš„æ–¹æ³•
        
        è¿™é‡Œå»¶è¿Ÿå¯¼å…¥é‡é‡çº§æ¨¡å—ï¼Œé¿å…å¯åŠ¨æ—¶åŠ è½½
        """
        import os
        
        if provider == "ollama":
            from ..utils.embedding.ollama_embedding import OllamaEmbeddings
            return OllamaEmbeddings(model=model, base_url=base_url)
        
        elif provider == "local":
            from ..utils.embedding.all_mini_embedding import MiniLMEmbeddings
            
            # ç¡®å®šæœ€ç»ˆè·¯å¾„
            if local_model_path:
                model_path = local_model_path
            elif model:
                model_path = f"checkpoints/embeddings/{model}"
            else:
                model_path = "checkpoints/embeddings/all-MiniLM-L6-v2"
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(model_path):
                raise FileNotFoundError(
                    f"æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}ã€‚è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²ä¸‹è½½åˆ°è¯¥ç›®å½•ã€‚"
                )
            
            # è·å–æ¨¡å‹å‚æ•°
            max_length = kwargs.get('max_length', 512)
            batch_size = kwargs.get('batch_size', 8)
            normalize = kwargs.get('normalize', True)
            
            return MiniLMEmbeddings(
                model_name_or_path=model_path,
                max_length=max_length,
                batch_size=batch_size,
                normalize=normalize
            )
        
        elif provider == "ark":
            from ..utils.embedding.volcengine_embedding import ArkEmbeddings
            return ArkEmbeddings(api_key=api_key, model=model)
        
        else:
            raise ValueError(f"æœªçŸ¥çš„ provider: {provider}")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "loaded_models": len(self._instances),
            "models": [
                {
                    "provider": key.provider,
                    "model": key.model,
                    "base_url": key.base_url
                }
                for key in self._instances.keys()
            ]
        }
    
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜çš„å®ä¾‹ï¼ˆä»…ç”¨äºæµ‹è¯•æˆ–é‡å¯ï¼‰"""
        with self._instance_lock:
            count = len(self._instances)
            self._instances.clear()
            logger.warning(f"âš ï¸ å·²æ¸…ç©ºæ‰€æœ‰ Embedding å®ä¾‹ (å…± {count} ä¸ª)")


# å…¨å±€å•ä¾‹å®ä¾‹
_embedding_manager: Optional[EmbeddingManager] = None


def get_embedding_manager() -> EmbeddingManager:
    """è·å–å…¨å±€ EmbeddingManager å•ä¾‹"""
    global _embedding_manager
    if _embedding_manager is None:
        _embedding_manager = EmbeddingManager()
    return _embedding_manager

