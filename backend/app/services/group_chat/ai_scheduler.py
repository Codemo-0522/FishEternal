"""
AIè°ƒåº¦å™¨

è´Ÿè´£AIå›å¤å†³ç­–ã€å»¶è¿Ÿé˜Ÿåˆ—ç®¡ç†ã€æŠ¢ç­”æ§åˆ¶
"""
import asyncio
import random
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from collections import defaultdict
from ...models.group_chat import (
    GroupMessage, GroupMember, AIReplyDecision,
    GroupChatContext, MemberType
)
from .filters import FilterChain, create_default_filter_chain

logger = logging.getLogger(__name__)


class DelayedReply:
    """å»¶è¿Ÿå›å¤ä»»åŠ¡"""
    
    def __init__(
        self,
        ai_member_id: str,
        session_id: str,
        message: GroupMessage,
        delay_seconds: float,
        context: GroupChatContext
    ):
        self.ai_member_id = ai_member_id
        self.session_id = session_id
        self.message = message
        self.delay_seconds = delay_seconds
        self.context = context
        self.scheduled_time = datetime.now() + timedelta(seconds=delay_seconds)
        self.cancelled = False
    
    async def execute(self, callback):
        """
        æ‰§è¡Œå»¶è¿Ÿå›å¤ï¼ˆæ”¯æŒä¸­é€”å–æ¶ˆï¼‰
        
        ç­–ç•¥ï¼šå°†å»¶è¿Ÿåˆ†æˆå°å—ï¼ˆæ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦è¢«å–æ¶ˆï¼‰
        """
        remaining_time = self.delay_seconds
        check_interval = 0.5  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡å–æ¶ˆçŠ¶æ€
        
        while remaining_time > 0 and not self.cancelled:
            sleep_time = min(check_interval, remaining_time)
            await asyncio.sleep(sleep_time)
            remaining_time -= sleep_time
        
        # æœ€ç»ˆå†æ¬¡æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
        if not self.cancelled:
            await callback(self)


class AIScheduler:
    """AIè°ƒåº¦å™¨"""
    
    def __init__(self):
        self.filter_chain = create_default_filter_chain()
        
        # å»¶è¿Ÿé˜Ÿåˆ—ï¼šgroup_id -> List[DelayedReply]
        self.delay_queues: Dict[str, List[DelayedReply]] = defaultdict(list)
        
        # ç¾¤ç»„å›å¤é”ï¼šé˜²æ­¢åŒä¸€æ—¶é—´å¤šä¸ªAIæŠ¢ç­”
        self.group_locks: Dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_messages": 0,
            "filtered_candidates": 0,
            "llm_calls": 0,
            "actual_replies": 0
        }
    
    async def process_message(
        self,
        message: GroupMessage,
        ai_members: List[GroupMember],
        context: GroupChatContext,
        base_reply_probability: float = 1.0,
        unrestricted_mode: bool = False
    ) -> List[AIReplyDecision]:
        """
        å¤„ç†æ–°æ¶ˆæ¯ï¼Œè¿”å›éœ€è¦å›å¤çš„AIå†³ç­–åˆ—è¡¨
        
        Args:
            message: å½“å‰æ¶ˆæ¯
            ai_members: æ‰€æœ‰åœ¨çº¿çš„AIæˆå‘˜
            context: ç¾¤èŠä¸Šä¸‹æ–‡
            base_reply_probability: åŸºç¡€å›å¤æ¦‚ç‡ï¼ˆç”±å¯¹è¯æ§åˆ¶å™¨æä¾›ï¼Œ0.0-1.0ï¼‰
            unrestricted_mode: æ˜¯å¦å¼€å¯æ— é™åˆ¶æ¨¡å¼ï¼ˆè·³è¿‡é‡‡æ ·ï¼‰
        
        Returns:
            æœ€ç»ˆå†³ç­–åˆ—è¡¨ï¼ˆéœ€è¦è°ƒç”¨LLMçš„AIï¼‰
        """
        self.stats["total_messages"] += 1
        group_id = message.group_id
        
        logger.info(
            f"\n{'='*60}\n"
            f"ğŸ“¨ æ–°æ¶ˆæ¯å¤„ç† | ç¾¤ç»„: {group_id}\n"
            f"å‘é€è€…: {message.sender_name} ({message.sender_type})\n"
            f"å†…å®¹: {message.content[:100]}\n"
            f"åœ¨çº¿AIæ•°é‡: {len(ai_members)}\n"
            f"åŸºç¡€å›å¤æ¦‚ç‡: {base_reply_probability:.2f}\n"
            f"{'='*60}"
        )
        
        # ç¬¬ä¸€é˜¶æ®µï¼šè½»é‡çº§è¿‡æ»¤
        candidate_decisions = await self._lightweight_filter(message, ai_members, context)
        
        if not candidate_decisions:
            logger.info("âŒ æ— AIé€šè¿‡è½»é‡çº§è¿‡æ»¤å™¨ï¼Œè·³è¿‡LLMè°ƒç”¨")
            return []
        
        # åº”ç”¨åŸºç¡€å›å¤æ¦‚ç‡è°ƒæ•´
        if base_reply_probability < 1.0:
            for decision in candidate_decisions:
                decision.probability_score *= base_reply_probability
                logger.debug(
                    f"  - {decision.ai_member_id}: æ¦‚ç‡è°ƒæ•´ "
                    f"{decision.probability_score / base_reply_probability:.2f} -> {decision.probability_score:.2f}"
                )
        
        self.stats["filtered_candidates"] += len(candidate_decisions)
        
        # ç¬¬äºŒé˜¶æ®µï¼šéšæœºé‡‡æ ·å†³ç­–ï¼ˆé¿å…æ‰€æœ‰AIéƒ½è°ƒç”¨LLMï¼‰
        # ğŸ”¥ unrestricted_modeï¼šè·³è¿‡é‡‡æ ·ï¼Œæ‰€æœ‰å€™é€‰AIéƒ½å›å¤
        if unrestricted_mode:
            sampled_decisions = candidate_decisions
            logger.info(f"ğŸ”“ æ— é™åˆ¶æ¨¡å¼ï¼šè·³è¿‡é‡‡æ ·ï¼Œæ‰€æœ‰{len(candidate_decisions)}ä¸ªå€™é€‰AIå°†å›å¤")
        else:
            sampled_decisions = await self._sample_candidates(candidate_decisions)
        
        logger.info(
            f"âœ… è½»é‡çº§è¿‡æ»¤å®Œæˆ: {len(ai_members)} AI -> {len(candidate_decisions)} å€™é€‰ -> {len(sampled_decisions)} é‡‡æ ·"
        )
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šä¸ºæ¯ä¸ªå€™é€‰æ·»åŠ å»¶è¿Ÿ
        for decision in sampled_decisions:
            decision.delay_seconds = self._calculate_delay(decision, message)
            decision.scheduled_time = datetime.now() + timedelta(seconds=decision.delay_seconds)
        
        # æŒ‰å»¶è¿Ÿæ’åº
        sampled_decisions.sort(key=lambda d: d.delay_seconds)
        
        return sampled_decisions
    
    async def _lightweight_filter(
        self,
        message: GroupMessage,
        ai_members: List[GroupMember],
        context: GroupChatContext
    ) -> List[AIReplyDecision]:
        """è½»é‡çº§è¿‡æ»¤é˜¶æ®µ"""
        
        # æ„å»ºè¿‡æ»¤å™¨ä¸Šä¸‹æ–‡
        filter_context = {
            "recent_messages": context.recent_messages,
            "online_members": context.online_members,
            "current_message": message
        }
        
        # è¿è¡Œè¿‡æ»¤å™¨é“¾
        decisions = self.filter_chain.evaluate(message, ai_members, filter_context)
        
        return decisions
    
    async def _sample_candidates(
        self,
        candidate_decisions: List[AIReplyDecision]
    ) -> List[AIReplyDecision]:
        """
        éšæœºé‡‡æ ·å€™é€‰AIï¼ˆåŸºäºæ¦‚ç‡ï¼‰
        
        ç­–ç•¥ï¼š
        0. **å…œåº•ç­–ç•¥ï¼šAIæ•°é‡ â‰¤ 3 æ—¶ï¼Œç›´æ¥å…¨éƒ¨æ”¾è¡Œ**
        1. è¢«@çš„AIï¼š100%ä¿ç•™ï¼ˆåŒ…æ‹¬å½“å‰è¢«@å’Œè¿‘æœŸè¢«@ï¼‰
        2. é«˜æ¦‚ç‡AIï¼ˆ>0.7ï¼‰ï¼š80%ä¿ç•™
        3. ä¸­æ¦‚ç‡AIï¼ˆ0.3-0.7ï¼‰ï¼šæ ¹æ®æ¦‚ç‡é‡‡æ ·
        4. ä½æ¦‚ç‡AIï¼ˆ<0.3ï¼‰ï¼š30%é‡‡æ ·
        5. å…œåº•ç­–ç•¥2ï¼šå¦‚æœæ²¡æœ‰AIè¢«é‡‡æ ·ï¼Œè‡³å°‘é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ä¸€ä¸ª
        """
        # ğŸ”¥ å…œåº•ç­–ç•¥ï¼šAIæ•°é‡ â‰¤ 3 æ—¶ï¼Œç›´æ¥å…¨éƒ¨æ”¾è¡Œï¼Œä¸è¿‡æ»¤
        if len(candidate_decisions) <= 3:
            logger.info(
                f"ğŸ¯ AIæ•°é‡ â‰¤ 3ï¼ˆå½“å‰{len(candidate_decisions)}ä¸ªï¼‰ï¼Œç›´æ¥å…¨éƒ¨æ”¾è¡Œï¼Œä¸è¿›è¡Œé‡‡æ ·è¿‡æ»¤"
            )
            return candidate_decisions
        
        sampled = []
        mentioned_ais = []  # è®°å½•è¢«@çš„AI
        
        for decision in candidate_decisions:
            # è¢«@çš„AIï¼ˆä»decision_reasonåˆ¤æ–­ï¼šåŒ…æ‹¬"å½“å‰è¢«@"å’Œ"è¿‘æœŸè¢«@"ï¼‰
            if "è¢«@" in decision.decision_reason or "è¿‘æœŸè¢«@" in decision.decision_reason:
                sampled.append(decision)
                mentioned_ais.append(decision.ai_member_id)
                logger.debug(f"âœ… é‡‡æ ·ä¿ç•™ï¼ˆè¢«@ï¼‰: {decision.ai_member_id} | {decision.decision_reason}")
                continue
            
            # æ ¹æ®æ¦‚ç‡é‡‡æ ·
            prob = decision.probability_score
            
            if prob >= 0.7:
                # é«˜æ¦‚ç‡ï¼š80%ä¿ç•™
                if random.random() < 0.8:
                    sampled.append(decision)
                    logger.debug(f"âœ… é‡‡æ ·ä¿ç•™ï¼ˆé«˜æ¦‚ç‡ï¼‰: {decision.ai_member_id} | {prob:.2%}")
            elif prob >= 0.3:
                # ä¸­æ¦‚ç‡ï¼šæŒ‰æ¦‚ç‡é‡‡æ ·
                if random.random() < prob:
                    sampled.append(decision)
                    logger.debug(f"âœ… é‡‡æ ·ä¿ç•™ï¼ˆä¸­æ¦‚ç‡ï¼‰: {decision.ai_member_id} | {prob:.2%}")
            else:
                # ä½æ¦‚ç‡ï¼š30%é‡‡æ ·
                if random.random() < 0.3:
                    sampled.append(decision)
                    logger.debug(f"âœ… é‡‡æ ·ä¿ç•™ï¼ˆä½æ¦‚ç‡ï¼‰: {decision.ai_member_id} | {prob:.2%}")
        
        # å…œåº•ç­–ç•¥2ï¼šå¦‚æœæ²¡æœ‰AIè¢«é‡‡æ ·ï¼Œè‡³å°‘é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ä¸€ä¸ª
        if not sampled and candidate_decisions:
            best_candidate = max(candidate_decisions, key=lambda d: d.probability_score)
            sampled.append(best_candidate)
            logger.info(
                f"ğŸ² å…œåº•ç­–ç•¥2ï¼šé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„AI - {best_candidate.ai_member_id} "
                f"(æ¦‚ç‡={best_candidate.probability_score:.2%})"
            )
        
        # è®°å½•è¢«@çš„AIæ•°é‡
        if mentioned_ais:
            logger.info(f"ğŸ¯ é‡‡æ ·é˜¶æ®µä¿ç•™è¢«@çš„AI: {len(mentioned_ais)}ä¸ª - {mentioned_ais}")
        
        return sampled
    
    def _calculate_delay(
        self,
        decision: AIReplyDecision,
        message: GroupMessage
    ) -> float:
        """
        è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼ˆæ¨¡æ‹Ÿäººç±»æ€è€ƒå»¶è¿Ÿï¼‰
        
        è§„åˆ™ï¼š
        1. è¢«@çš„AIï¼šçŸ­å»¶è¿Ÿï¼ˆ0.5-2ç§’ï¼‰
        2. é«˜å…´è¶£AIï¼šä¸­ç­‰å»¶è¿Ÿï¼ˆ1-3ç§’ï¼‰
        3. æ™®é€šAIï¼šé•¿å»¶è¿Ÿï¼ˆ2-5ç§’ï¼‰
        """
        
        # è¢«@ï¼šå¿«é€Ÿå“åº”
        if "è¢«@æåŠ" in decision.decision_reason:
            return random.uniform(0.5, 2.0)
        
        # é«˜æ¦‚ç‡ï¼šä¸­ç­‰å»¶è¿Ÿ
        if decision.probability_score >= 0.7:
            return random.uniform(1.0, 3.0)
        
        # æ™®é€šï¼šé•¿å»¶è¿Ÿ
        return random.uniform(2.0, 5.0)
    
    async def schedule_reply(
        self,
        decision: AIReplyDecision,
        message: GroupMessage,
        context: GroupChatContext,
        reply_callback
    ) -> DelayedReply:
        """
        è°ƒåº¦ä¸€ä¸ªå»¶è¿Ÿå›å¤ä»»åŠ¡
        
        Args:
            decision: AIå†³ç­–
            message: åŸå§‹æ¶ˆæ¯
            context: ç¾¤èŠä¸Šä¸‹æ–‡
            reply_callback: å›å¤å›è°ƒå‡½æ•° async def(DelayedReply)
        
        Returns:
            å»¶è¿Ÿå›å¤ä»»åŠ¡
        """
        delayed_reply = DelayedReply(
            ai_member_id=decision.ai_member_id,
            session_id=decision.session_id,
            message=message,
            delay_seconds=decision.delay_seconds,
            context=context
        )
        
        group_id = message.group_id
        self.delay_queues[group_id].append(delayed_reply)
        
        logger.info(
            f"â° è°ƒåº¦å»¶è¿Ÿå›å¤: AI={decision.ai_member_id} | "
            f"å»¶è¿Ÿ={decision.delay_seconds:.2f}s | "
            f"é¢„è®¡æ—¶é—´={delayed_reply.scheduled_time.strftime('%H:%M:%S')}"
        )
        
        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
        asyncio.create_task(delayed_reply.execute(reply_callback))
        
        return delayed_reply
    
    async def cancel_pending_replies(
        self,
        group_id: str,
        ai_member_id: Optional[str] = None
    ):
        """
        å–æ¶ˆå¾…å¤„ç†çš„å›å¤ä»»åŠ¡
        
        Args:
            group_id: ç¾¤ç»„ID
            ai_member_id: AIæˆå‘˜IDï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™å–æ¶ˆè¯¥ç¾¤æ‰€æœ‰ä»»åŠ¡ï¼‰
        """
        if group_id not in self.delay_queues:
            logger.debug(f"ğŸ” æ— å¾…å–æ¶ˆä»»åŠ¡: ç¾¤ç»„={group_id} (é˜Ÿåˆ—ä¸ºç©º)")
            return
        
        cancelled_count = 0
        cancelled_ais = []
        
        for delayed_reply in self.delay_queues[group_id]:
            if ai_member_id is None or delayed_reply.ai_member_id == ai_member_id:
                delayed_reply.cancelled = True
                cancelled_count += 1
                cancelled_ais.append(delayed_reply.ai_member_id)
        
        # æ¸…ç†å·²å–æ¶ˆçš„ä»»åŠ¡
        self.delay_queues[group_id] = [
            dr for dr in self.delay_queues[group_id]
            if not dr.cancelled
        ]
        
        if cancelled_count > 0:
            logger.info(
                f"âŒ å–æ¶ˆå»¶è¿Ÿå›å¤: ç¾¤ç»„={group_id} | "
                f"AI={ai_member_id or 'ALL'} | "
                f"æ•°é‡={cancelled_count} | "
                f"AIåˆ—è¡¨={cancelled_ais}"
            )
        else:
            logger.debug(f"ğŸ” æ— åŒ¹é…ä»»åŠ¡éœ€å–æ¶ˆ: ç¾¤ç»„={group_id}")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            "active_delay_queues": {
                group_id: len(queue)
                for group_id, queue in self.delay_queues.items()
                if queue
            }
        }
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.stats = {
            "total_messages": 0,
            "filtered_candidates": 0,
            "llm_calls": 0,
            "actual_replies": 0
        }


class ReplyController:
    """å›å¤æ§åˆ¶å™¨ï¼ˆæŠ¢ç­”æ§åˆ¶ï¼‰"""
    
    def __init__(self, max_concurrent_replies: int = 2):
        """
        Args:
            max_concurrent_replies: å•æ¡æ¶ˆæ¯çš„æœ€å¤§å¹¶å‘å›å¤æ•°
        """
        self.max_concurrent_replies = max_concurrent_replies
        
        # æ¶ˆæ¯ID -> å·²å›å¤AIæ•°é‡
        self.message_reply_counts: Dict[str, int] = defaultdict(int)
        
        # æ¶ˆæ¯ID -> é”
        self.message_locks: Dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)
    
    async def should_allow_reply(self, message_id: str, max_concurrent_replies: int = None) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦å…è®¸å›å¤ï¼ˆæŠ¢ç­”æ§åˆ¶ï¼‰
        
        Args:
            message_id: æ¶ˆæ¯ID
            max_concurrent_replies: æœ€å¤§å¹¶å‘å›å¤æ•°ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å®ä¾‹é»˜è®¤å€¼ï¼‰
        
        Returns:
            True: å…è®¸å›å¤
            False: å·²è¾¾åˆ°å¹¶å‘é™åˆ¶
        """
        # ä½¿ç”¨ä¼ å…¥çš„å€¼æˆ–å®ä¾‹é»˜è®¤å€¼
        limit = max_concurrent_replies if max_concurrent_replies is not None else self.max_concurrent_replies
        
        async with self.message_locks[message_id]:
            current_count = self.message_reply_counts[message_id]
            
            if current_count >= limit:
                logger.warning(
                    f"ğŸš« æŠ¢ç­”é™åˆ¶: æ¶ˆæ¯ {message_id} å·²æœ‰ {current_count} ä¸ªAIå›å¤ï¼Œæ‹’ç»æ–°å›å¤ (é™åˆ¶={limit})"
                )
                return False
            
            # å…è®¸å›å¤ï¼Œè®¡æ•°+1
            self.message_reply_counts[message_id] += 1
            logger.info(
                f"âœ… å…è®¸å›å¤: æ¶ˆæ¯ {message_id} | å½“å‰å›å¤æ•° {self.message_reply_counts[message_id]}/{limit}"
            )
            return True
    
    def cleanup_old_messages(self, max_age_seconds: int = 3600):
        """æ¸…ç†æ—§æ¶ˆæ¯çš„è®¡æ•°ï¼ˆé¿å…å†…å­˜æ³„æ¼ï¼‰"""
        # ç®€å•å®ç°ï¼šå®šæœŸæ¸…ç©ºï¼ˆç”Ÿäº§ç¯å¢ƒåº”åŸºäºæ—¶é—´æˆ³ï¼‰
        if len(self.message_reply_counts) > 1000:
            logger.info("ğŸ§¹ æ¸…ç†æ—§æ¶ˆæ¯å›å¤è®¡æ•°")
            self.message_reply_counts.clear()
            self.message_locks.clear()


# å…¨å±€å•ä¾‹
_ai_scheduler = None
_reply_controller = None


def get_ai_scheduler() -> AIScheduler:
    """è·å–å…¨å±€AIè°ƒåº¦å™¨å•ä¾‹"""
    global _ai_scheduler
    if _ai_scheduler is None:
        _ai_scheduler = AIScheduler()
    return _ai_scheduler


def get_reply_controller() -> ReplyController:
    """è·å–å…¨å±€å›å¤æ§åˆ¶å™¨å•ä¾‹"""
    global _reply_controller
    if _reply_controller is None:
        _reply_controller = ReplyController(max_concurrent_replies=3)
    return _reply_controller

