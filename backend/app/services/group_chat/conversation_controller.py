"""
ç¾¤èŠå¯¹è¯æ§åˆ¶å™¨

è´Ÿè´£ç®¡ç†AI-to-AIå¯¹è¯çš„æµç¨‹æ§åˆ¶ï¼Œé˜²æ­¢æ— é™å¯¹è¯å’Œæˆæœ¬å¤±æ§ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¯¹è¯è½®æ¬¡è¿½è¸ªå’Œé™åˆ¶
2. å†·å´æœŸç®¡ç†
3. æ‰‹åŠ¨ä¸­æ–­æ§åˆ¶
4. æˆæœ¬ä¼°ç®—å’Œé¢„è­¦
"""
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Optional, List
from collections import defaultdict, deque
from ...models.group_chat import GroupMessage, MemberType

logger = logging.getLogger(__name__)


class ConversationState:
    """å•ä¸ªç¾¤ç»„çš„å¯¹è¯çŠ¶æ€"""
    
    def __init__(self, group_id: str, controller_config: Dict = None):
        self.group_id = group_id
        self.controller_config = controller_config or {}  # ä¿å­˜æ§åˆ¶å™¨é…ç½®å¼•ç”¨
        
        # è°ƒè¯•æ—¥å¿—
        logger.debug(
            f"ğŸ”§ åˆ›å»ºConversationState | ç¾¤ç»„={group_id} | "
            f"has_recovery_callback={bool(self.controller_config.get('recovery_callback'))}"
        )
        
        # å¯¹è¯è½®æ¬¡è¿½è¸ªï¼ˆæœ€è¿‘Næ¡æ¶ˆæ¯çš„å‘é€è€…ç±»å‹ï¼‰
        self.recent_senders = deque(maxlen=10)  # æœ€è¿‘10æ¡æ¶ˆæ¯
        
        # AIè¿ç»­å›å¤è®¡æ•°
        self.ai_consecutive_count = 0
        
        # æœ€åä¸€æ¬¡ç”¨æˆ·æ¶ˆæ¯æ—¶é—´
        self.last_human_message_time: Optional[datetime] = None
        
        # æœ€åä¸€æ¬¡AIæ¶ˆæ¯æ—¶é—´
        self.last_ai_message_time: Optional[datetime] = None
        
        # å†·å´æœŸçŠ¶æ€
        self.in_cooldown = False
        self.cooldown_until: Optional[datetime] = None
        self.cooldown_recovery_count = 0  # å†·å´æœŸæ¢å¤æ¬¡æ•°
        self.max_cooldown_recoveries = 3  # æœ€å¤§å…è®¸æ¢å¤æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
        
        # æ‰‹åŠ¨ä¸­æ–­æ ‡å¿—
        self.manually_stopped = False
        
        # æœ¬è½®å¯¹è¯çš„æ¶ˆæ¯è®¡æ•°
        self.current_round_message_count = 0
        self.current_round_start_time: Optional[datetime] = None
        
        # æˆæœ¬ä¼°ç®—ï¼ˆæŒ‰tokenæ•°ï¼‰
        self.estimated_tokens_used = 0
        
    def add_message(self, sender_type: MemberType, estimated_tokens: int = 0):
        """æ·»åŠ æ¶ˆæ¯è®°å½•"""
        now = datetime.now()
        
        self.recent_senders.append(sender_type)
        self.estimated_tokens_used += estimated_tokens
        
        if sender_type == MemberType.AI:
            self.ai_consecutive_count += 1
            self.last_ai_message_time = now
        else:
            # äººç±»æ¶ˆæ¯ï¼šé‡ç½®AIè¿ç»­è®¡æ•°å’Œå†·å´æœŸæ¢å¤è®¡æ•°
            self.ai_consecutive_count = 0
            self.cooldown_recovery_count = 0  # é‡ç½®æ¢å¤è®¡æ•°ï¼Œå…è®¸æ–°ä¸€è½®å¯¹è¯
            self.last_human_message_time = now
            
            # æ–°çš„ä¸€è½®å¯¹è¯å¼€å§‹
            if self.in_cooldown or self.current_round_message_count > 0:
                logger.info(f"ğŸ‘¤ äººç±»æ¶ˆæ¯ï¼Œé‡ç½®å¯¹è¯è½®æ¬¡å’Œæ¢å¤è®¡æ•° | ç¾¤ç»„={self.group_id}")
                self.current_round_message_count = 0
                self.current_round_start_time = now
                self.in_cooldown = False
                self.manually_stopped = False
        
        self.current_round_message_count += 1
        if not self.current_round_start_time:
            self.current_round_start_time = now
    
    def should_allow_ai_response(self, config: Dict) -> tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦å…è®¸AIå›å¤
        
        Returns:
            (æ˜¯å¦å…è®¸, åŸå› è¯´æ˜)
        """
        now = datetime.now()
        
        # 1. æ£€æŸ¥æ‰‹åŠ¨ä¸­æ–­
        if self.manually_stopped:
            return False, "å¯¹è¯å·²è¢«æ‰‹åŠ¨ä¸­æ–­"
        
        # 2. æ£€æŸ¥å†·å´æœŸæ¢å¤æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
        if self.cooldown_recovery_count >= self.max_cooldown_recoveries:
            logger.warning(
                f"â›” å†·å´æœŸæ¢å¤æ¬¡æ•°è¾¾åˆ°ä¸Šé™ | ç¾¤ç»„={self.group_id} | "
                f"æ¢å¤æ¬¡æ•°={self.cooldown_recovery_count} | åœæ­¢è‡ªåŠ¨æ¢å¤"
            )
            return False, f"å†·å´æœŸæ¢å¤æ¬¡æ•°è¾¾åˆ°ä¸Šé™ï¼ˆ{self.max_cooldown_recoveries}æ¬¡ï¼‰ï¼Œåœæ­¢è‡ªåŠ¨å¯¹è¯"
        
        # 3. æ£€æŸ¥å†·å´æœŸ
        if self.in_cooldown and self.cooldown_until:
            if now < self.cooldown_until:
                remaining = (self.cooldown_until - now).total_seconds()
                return False, f"å†·å´æœŸä¸­ï¼ˆå‰©ä½™{remaining:.0f}ç§’ï¼‰"
            else:
                # å†·å´æœŸç»“æŸï¼Œé‡ç½®çŠ¶æ€
                self.in_cooldown = False
                self.cooldown_until = None
                self.ai_consecutive_count = 0  # é‡ç½®AIè¿ç»­è®¡æ•°
                logger.info(f"âœ… å†·å´æœŸç»“æŸï¼Œå¯¹è¯çŠ¶æ€å·²é‡ç½® | ç¾¤ç»„={self.group_id}")
                # è¿”å›ä¸€ä¸ªç‰¹æ®Šæ ‡è®°ï¼Œè¡¨ç¤ºå†·å´æœŸåˆšç»“æŸ
                return True, "å†·å´æœŸåˆšç»“æŸï¼Œå…è®¸æ¢å¤å¯¹è¯"
        
        # 4. æ£€æŸ¥AIè¿ç»­å›å¤é™åˆ¶
        max_ai_consecutive = config.get("max_ai_consecutive_replies", 3)
        if self.ai_consecutive_count >= max_ai_consecutive:
            # è§¦å‘å†·å´æœŸ
            cooldown_seconds = config.get("cooldown_seconds", 30)
            self.in_cooldown = True
            self.cooldown_until = now + timedelta(seconds=cooldown_seconds)
            self.cooldown_recovery_count += 1  # å¢åŠ æ¢å¤è®¡æ•°
            
            logger.warning(
                f"ğŸš« AIè¿ç»­å›å¤è¾¾åˆ°ä¸Šé™ | ç¾¤ç»„={self.group_id} | "
                f"è¿ç»­æ¬¡æ•°={self.ai_consecutive_count} | æ¢å¤æ¬¡æ•°={self.cooldown_recovery_count}/{self.max_cooldown_recoveries} | "
                f"è¿›å…¥å†·å´æœŸ{cooldown_seconds}ç§’"
            )
            
            # åªåœ¨æœªè¾¾åˆ°æœ€å¤§æ¢å¤æ¬¡æ•°æ—¶æ‰è°ƒåº¦æ¢å¤ä»»åŠ¡
            if self.cooldown_recovery_count < self.max_cooldown_recoveries:
                recovery_callback = self.controller_config.get("recovery_callback")
                if recovery_callback:
                    self.schedule_cooldown_recovery(recovery_callback, cooldown_seconds)
                else:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°recovery_callbackï¼Œæ— æ³•è°ƒåº¦æ¢å¤ä»»åŠ¡ | ç¾¤ç»„={self.group_id}")
            else:
                logger.warning(
                    f"â›” å·²è¾¾åˆ°æœ€å¤§å†·å´æœŸæ¢å¤æ¬¡æ•°ï¼Œä¸å†è°ƒåº¦æ¢å¤ä»»åŠ¡ | ç¾¤ç»„={self.group_id}"
                )
            
            return False, f"AIè¿ç»­å›å¤è¾¾åˆ°ä¸Šé™ï¼ˆ{max_ai_consecutive}æ¬¡ï¼‰ï¼Œè¿›å…¥å†·å´æœŸ"
        
        # 4. æ£€æŸ¥æœ¬è½®æ€»æ¶ˆæ¯æ•°é™åˆ¶
        max_round_messages = config.get("max_messages_per_round", 20)
        if self.current_round_message_count >= max_round_messages:
            # è§¦å‘å†·å´æœŸ
            cooldown_seconds = config.get("cooldown_seconds", 60)
            self.in_cooldown = True
            self.cooldown_until = now + timedelta(seconds=cooldown_seconds)
            
            logger.warning(
                f"ğŸš« æœ¬è½®å¯¹è¯æ¶ˆæ¯æ•°è¾¾åˆ°ä¸Šé™ | ç¾¤ç»„={self.group_id} | "
                f"æ¶ˆæ¯æ•°={self.current_round_message_count} | è¿›å…¥å†·å´æœŸ{cooldown_seconds}ç§’"
            )
            return False, f"æœ¬è½®å¯¹è¯æ¶ˆæ¯æ•°è¾¾åˆ°ä¸Šé™ï¼ˆ{max_round_messages}ï¼‰ï¼Œè¿›å…¥å†·å´æœŸ"
        
        # 5. æ£€æŸ¥æˆæœ¬é™åˆ¶
        max_tokens_per_round = config.get("max_tokens_per_round", 50000)
        if self.estimated_tokens_used >= max_tokens_per_round:
            self.in_cooldown = True
            self.cooldown_until = now + timedelta(seconds=300)  # 5åˆ†é’Ÿå†·å´
            
            logger.warning(
                f"ğŸš« æœ¬è½®å¯¹è¯tokenä½¿ç”¨è¾¾åˆ°ä¸Šé™ | ç¾¤ç»„={self.group_id} | "
                f"å·²ç”¨tokens={self.estimated_tokens_used}"
            )
            return False, f"æœ¬è½®å¯¹è¯tokenä½¿ç”¨è¾¾åˆ°ä¸Šé™ï¼ˆ{max_tokens_per_round}ï¼‰ï¼Œè¿›å…¥å†·å´æœŸ"
        
        return True, "å…è®¸å›å¤"
    
    def schedule_cooldown_recovery(self, callback, cooldown_seconds: int):
        """
        è°ƒåº¦å†·å´æœŸç»“æŸåçš„æ¢å¤ä»»åŠ¡
        
        Args:
            callback: å†·å´æœŸç»“æŸåè¦è°ƒç”¨çš„å¼‚æ­¥å‡½æ•°
            cooldown_seconds: å†·å´æœŸæ—¶é•¿ï¼ˆç§’ï¼‰
        """
        async def recovery_task():
            await asyncio.sleep(cooldown_seconds + 1)  # å¤šç­‰1ç§’ç¡®ä¿å†·å´æœŸç»“æŸ
            
            now = datetime.now()
            logger.debug(
                f"â° å†·å´æœŸæ¢å¤ä»»åŠ¡æ‰§è¡Œ | ç¾¤ç»„={self.group_id} | "
                f"in_cooldown={self.in_cooldown} | cooldown_until={self.cooldown_until}"
            )
            
            # å…ˆæ£€æŸ¥å¹¶æ›´æ–°å†·å´æœŸçŠ¶æ€
            if self.in_cooldown and self.cooldown_until:
                if now >= self.cooldown_until:
                    # å†·å´æœŸç¡®å®ç»“æŸäº†ï¼Œé‡ç½®çŠ¶æ€
                    self.in_cooldown = False
                    self.cooldown_until = None
                    self.ai_consecutive_count = 0  # é‡ç½®AIè¿ç»­è®¡æ•°
                    logger.info(f"âœ… å†·å´æœŸå·²ç»“æŸï¼ŒçŠ¶æ€å·²é‡ç½® | ç¾¤ç»„={self.group_id}")
                else:
                    # æ—¶é—´è¿˜æ²¡åˆ°ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
                    remaining = (self.cooldown_until - now).total_seconds()
                    logger.warning(f"âš ï¸ å†·å´æœŸå°šæœªç»“æŸ | ç¾¤ç»„={self.group_id} | å‰©ä½™{remaining:.0f}ç§’")
                    return
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ¢å¤å¯¹è¯
            if not self.in_cooldown:
                logger.info(f"ğŸ”„ å†·å´æœŸå·²ç»“æŸï¼Œå°è¯•æ¢å¤AIå¯¹è¯ | ç¾¤ç»„={self.group_id}")
                try:
                    await callback(self.group_id)
                except Exception as e:
                    logger.error(f"âŒ å†·å´æœŸæ¢å¤å›è°ƒæ‰§è¡Œå¤±è´¥ | ç¾¤ç»„={self.group_id} | é”™è¯¯: {e}", exc_info=True)
            else:
                logger.debug(f"â¸ï¸ å†·å´æœŸè¿›å…¥æ–°çŠ¶æ€ï¼Œè·³è¿‡æ¢å¤ | ç¾¤ç»„={self.group_id}")
        
        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
        asyncio.create_task(recovery_task())
        logger.info(f"â° å·²è°ƒåº¦å†·å´æœŸæ¢å¤ä»»åŠ¡ | ç¾¤ç»„={self.group_id} | {cooldown_seconds}ç§’åæ‰§è¡Œ")
    
    def get_status_summary(self) -> Dict:
        """è·å–çŠ¶æ€æ‘˜è¦"""
        return {
            "group_id": self.group_id,
            "ai_consecutive_count": self.ai_consecutive_count,
            "cooldown_recovery_count": self.cooldown_recovery_count,
            "max_cooldown_recoveries": self.max_cooldown_recoveries,
            "current_round_messages": self.current_round_message_count,
            "estimated_tokens": self.estimated_tokens_used,
            "in_cooldown": self.in_cooldown,
            "manually_stopped": self.manually_stopped,
            "last_human_message_time": self.last_human_message_time.isoformat() if self.last_human_message_time else None,
            "last_ai_message_time": self.last_ai_message_time.isoformat() if self.last_ai_message_time else None,
        }


class ConversationController:
    """å¯¹è¯æ§åˆ¶å™¨"""
    
    # é»˜è®¤é…ç½®
    DEFAULT_CONFIG = {
        "max_ai_consecutive_replies": 3,      # AIæœ€å¤šè¿ç»­å›å¤3æ¬¡
        "max_messages_per_round": 20,         # æ¯è½®å¯¹è¯æœ€å¤š20æ¡æ¶ˆæ¯
        "max_tokens_per_round": 50000,        # æ¯è½®å¯¹è¯æœ€å¤š5ä¸‡tokens
        "cooldown_seconds": 30,               # é»˜è®¤å†·å´æœŸ30ç§’
        "enable_ai_to_ai": True,              # æ˜¯å¦å¯ç”¨AIäº’ç›¸å¯¹è¯
        "ai_reply_probability": 0.6,          # AIå¯¹AIæ¶ˆæ¯çš„å›å¤æ¦‚ç‡ï¼ˆé™ä½ï¼‰
    }
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = {**self.DEFAULT_CONFIG, **(config or {})}
        
        # ç¾¤ç»„çŠ¶æ€ï¼šgroup_id -> ConversationState
        self.group_states: Dict[str, ConversationState] = {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_messages": 0,
            "ai_messages": 0,
            "human_messages": 0,
            "blocked_by_consecutive_limit": 0,
            "blocked_by_round_limit": 0,
            "blocked_by_cooldown": 0,
            "blocked_by_manual_stop": 0,
        }
        
        # å†·å´æœŸæ¢å¤å›è°ƒ
        self.on_cooldown_end_callback = None
        
        logger.info(f"âœ… å¯¹è¯æ§åˆ¶å™¨å·²åˆå§‹åŒ– | é…ç½®: {self.config}")
    
    def get_group_state(self, group_id: str) -> ConversationState:
        """è·å–ç¾¤ç»„çŠ¶æ€ï¼ˆä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰"""
        if group_id not in self.group_states:
            self.group_states[group_id] = ConversationState(group_id, self.config)
        return self.group_states[group_id]
    
    def track_message(self, message: GroupMessage, estimated_tokens: int = 0):
        """
        è¿½è¸ªæ¶ˆæ¯
        
        Args:
            message: ç¾¤æ¶ˆæ¯
            estimated_tokens: ä¼°ç®—çš„tokenæ•°ï¼ˆå¯é€‰ï¼‰
        """
        state = self.get_group_state(message.group_id)
        state.add_message(message.sender_type, estimated_tokens)
        
        self.stats["total_messages"] += 1
        if message.sender_type == MemberType.AI:
            self.stats["ai_messages"] += 1
        else:
            self.stats["human_messages"] += 1
        
        logger.debug(
            f"ğŸ“Š æ¶ˆæ¯è¿½è¸ª | ç¾¤ç»„={message.group_id} | å‘é€è€…={message.sender_name}({message.sender_type}) | "
            f"AIè¿ç»­={state.ai_consecutive_count} | æœ¬è½®æ¶ˆæ¯æ•°={state.current_round_message_count}"
        )
    
    def should_trigger_ai_decision(self, message: GroupMessage, config: Optional[Dict] = None) -> tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘AIå†³ç­–æµç¨‹
        
        Args:
            message: è§¦å‘çš„æ¶ˆæ¯
            config: å¯é€‰çš„é…ç½®å­—å…¸ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        
        Returns:
            (æ˜¯å¦è§¦å‘, åŸå› è¯´æ˜)
        """
        # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
        config = config or self.config
        
        # äººç±»æ¶ˆæ¯ï¼šæ€»æ˜¯è§¦å‘
        if message.sender_type != MemberType.AI:
            return True, "äººç±»æ¶ˆæ¯ï¼Œè§¦å‘AIå†³ç­–"
        
        # AIæ¶ˆæ¯ï¼šæ£€æŸ¥æ˜¯å¦å¯ç”¨AI-to-AI
        if not config.get("enable_ai_to_ai", self.config["enable_ai_to_ai"]):
            return False, "AI-to-AIå¯¹è¯æœªå¯ç”¨"
        
        # AIæ¶ˆæ¯ï¼šæ£€æŸ¥å¯¹è¯æ§åˆ¶é™åˆ¶
        state = self.get_group_state(message.group_id)
        allowed, reason = state.should_allow_ai_response(config)
        
        if not allowed:
            # æ›´æ–°ç»Ÿè®¡
            if "è¿ç»­å›å¤" in reason:
                self.stats["blocked_by_consecutive_limit"] += 1
            elif "æ¶ˆæ¯æ•°è¾¾åˆ°ä¸Šé™" in reason:
                self.stats["blocked_by_round_limit"] += 1
            elif "å†·å´æœŸ" in reason:
                self.stats["blocked_by_cooldown"] += 1
            elif "æ‰‹åŠ¨ä¸­æ–­" in reason:
                self.stats["blocked_by_manual_stop"] += 1
        
        return allowed, reason
    
    def get_ai_reply_probability(self, message: GroupMessage, config: Optional[Dict] = None) -> float:
        """
        è·å–AIå›å¤æ¦‚ç‡ï¼ˆæ ¹æ®æ¶ˆæ¯ç±»å‹åŠ¨æ€è°ƒæ•´ï¼‰
        
        Args:
            message: è§¦å‘çš„æ¶ˆæ¯
            config: å¯é€‰çš„é…ç½®å­—å…¸ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        
        Returns:
            å›å¤æ¦‚ç‡ (0.0 ~ 1.0)
        """
        # ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
        config = config or self.config
        
        base_probability = 1.0 if message.sender_type != MemberType.AI else config.get("ai_reply_probability", self.config["ai_reply_probability"])
        
        state = self.get_group_state(message.group_id)
        
        # æ ¹æ®AIè¿ç»­å›å¤æ¬¡æ•°é™ä½æ¦‚ç‡
        if state.ai_consecutive_count > 0:
            # æ¯æ¬¡AIè¿ç»­å›å¤ï¼Œæ¦‚ç‡é™ä½20%
            reduction = 0.2 * state.ai_consecutive_count
            base_probability = max(0.1, base_probability - reduction)
        
        return base_probability
    
    def manual_stop(self, group_id: str) -> bool:
        """
        æ‰‹åŠ¨ä¸­æ–­ç¾¤ç»„å¯¹è¯
        
        Args:
            group_id: ç¾¤ç»„ID
        
        Returns:
            æ˜¯å¦æˆåŠŸä¸­æ–­
        """
        state = self.get_group_state(group_id)
        state.manually_stopped = True
        
        logger.warning(f"ğŸ›‘ ç¾¤ç»„å¯¹è¯è¢«æ‰‹åŠ¨ä¸­æ–­ | ç¾¤ç»„={group_id}")
        return True
    
    def resume(self, group_id: str) -> bool:
        """
        æ¢å¤ç¾¤ç»„å¯¹è¯
        
        Args:
            group_id: ç¾¤ç»„ID
        
        Returns:
            æ˜¯å¦æˆåŠŸæ¢å¤
        """
        state = self.get_group_state(group_id)
        state.manually_stopped = False
        state.in_cooldown = False
        
        logger.info(f"â–¶ï¸ ç¾¤ç»„å¯¹è¯å·²æ¢å¤ | ç¾¤ç»„={group_id}")
        return True
    
    def get_group_status(self, group_id: str) -> Dict:
        """è·å–ç¾¤ç»„çŠ¶æ€"""
        state = self.get_group_state(group_id)
        return state.get_status_summary()
    
    def get_all_stats(self) -> Dict:
        """è·å–å…¨å±€ç»Ÿè®¡"""
        return {
            "global_stats": self.stats,
            "group_count": len(self.group_states),
            "groups": {
                group_id: state.get_status_summary()
                for group_id, state in self.group_states.items()
            }
        }

