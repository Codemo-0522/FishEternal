"""
ç¾¤èŠç­–ç•¥é…ç½®é€‚é…å™¨

è´Ÿè´£å°†æ•°æ®åº“ä¸­çš„GroupStrategyConfigè½¬æ¢ä¸ºå„ä¸ªé™æµæ¨¡å—éœ€è¦çš„é…ç½®æ ¼å¼

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ç»Ÿä¸€å¤„ç† unrestricted_modeï¼ˆæ— é™åˆ¶æ¨¡å¼ï¼‰
2. å½“å¼€å¯æ— é™åˆ¶æ¨¡å¼æ—¶ï¼Œæ‰€æœ‰é™æµå‚æ•°è‡ªåŠ¨è®¾ç½®ä¸ºæœ€å¤§å€¼
3. é¿å…åœ¨æ¯ä¸ªåˆ¤æ–­å¤„éƒ½æ·»åŠ æ¡ä»¶æ£€æŸ¥
"""
import logging
from typing import Dict, Any
from ...models.group_chat import GroupStrategyConfig

logger = logging.getLogger(__name__)


class StrategyConfigAdapter:
    """ç­–ç•¥é…ç½®é€‚é…å™¨"""
    
    # æ— é™åˆ¶æ¨¡å¼çš„æœ€å¤§å€¼å¸¸é‡ï¼ˆåˆç†çš„ä¸Šé™ï¼Œé˜²æ­¢ç³»ç»Ÿå´©æºƒï¼‰
    UNRESTRICTED_LIMITS = {
        "max_ai_consecutive_replies": 9999,    # AIè¿ç»­å›å¤æ¬¡æ•°
        "max_messages_per_round": 9999,        # æ¯è½®æœ€å¤§æ¶ˆæ¯æ•°
        "max_tokens_per_round": 999999,        # æ¯è½®æœ€å¤§tokenæ•°
        "cooldown_seconds": 0,                  # å†·å´æ—¶é—´
        "max_cooldown_recoveries": 9999,       # å†·å´æ¢å¤æ¬¡æ•°
        "ai_reply_probability": 1.0,           # AIå›å¤æ¦‚ç‡100%
        "max_concurrent": 999,                  # æœ€å¤§å¹¶å‘æ•°
        "min_delay_gap": 0.1,                  # æœ€å°å»¶è¿Ÿï¼ˆä¿ç•™å¾®å°å»¶è¿Ÿé¿å…ç¬é—´çˆ†å‘ï¼‰
        "delay_min": 0.1,                      # æœ€å°å»¶è¿Ÿ
        "delay_max": 0.5,                      # æœ€å¤§å»¶è¿Ÿ
        "ai_to_ai_delay_seconds": 0.5,         # AI-to-AIè§¦å‘å»¶è¿Ÿï¼ˆä¿ç•™çŸ­å»¶è¿Ÿé¿å…ç¬é—´çˆ†å‘ï¼‰
        "keep_rate": 1.0,                      # ä¿ç•™ç‡100%
        "min_sample_count": 999,               # æœ€å°é‡‡æ ·æ•°
        "multiplier": 1.0,                     # æ¦‚ç‡å€æ•°100%
        "similarity_threshold": 0.0,           # ç›¸ä¼¼åº¦é˜ˆå€¼0ï¼ˆä¸æ£€æµ‹ï¼‰
    }
    
    @staticmethod
    def to_conversation_controller_config(config: GroupStrategyConfig) -> Dict[str, Any]:
        """
        è½¬æ¢ä¸ºConversationControlleréœ€è¦çš„é…ç½®æ ¼å¼
        
        Args:
            config: ç¾¤èŠç­–ç•¥é…ç½®
            
        Returns:
            ConversationControlleré…ç½®å­—å…¸
        """
        # å¦‚æœå¼€å¯æ— é™åˆ¶æ¨¡å¼ï¼Œç›´æ¥è¿”å›æœ€å¤§å€¼é…ç½®
        if config.unrestricted_mode:
            logger.info(f"ğŸ”“ æ— é™åˆ¶æ¨¡å¼å·²å¼€å¯ - ConversationControllerä½¿ç”¨æœ€å¤§å€¼é…ç½®")
            return {
                "max_ai_consecutive_replies": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_ai_consecutive_replies"],
                "max_messages_per_round": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_messages_per_round"],
                "max_tokens_per_round": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_tokens_per_round"],
                "cooldown_seconds": StrategyConfigAdapter.UNRESTRICTED_LIMITS["cooldown_seconds"],
                "enable_ai_to_ai": True,  # å¼ºåˆ¶å¼€å¯AIäº’ç›¸å¯¹è¯
                "ai_reply_probability": StrategyConfigAdapter.UNRESTRICTED_LIMITS["ai_reply_probability"],
                "max_cooldown_recoveries": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_cooldown_recoveries"],
            }
        
        # æ­£å¸¸æ¨¡å¼ï¼šä½¿ç”¨æ•°æ®åº“é…ç½®
        return {
            "max_ai_consecutive_replies": config.max_ai_consecutive_replies,
            "max_messages_per_round": config.max_messages_per_round,
            "max_tokens_per_round": config.max_tokens_per_round,
            "cooldown_seconds": config.cooldown_seconds,
            "enable_ai_to_ai": config.enable_ai_to_ai,
            "ai_reply_probability": config.ai_reply_probability,
            "max_cooldown_recoveries": config.max_cooldown_recoveries,
        }
    
    @staticmethod
    def to_ai_scheduler_config(config: GroupStrategyConfig) -> Dict[str, Any]:
        """
        è½¬æ¢ä¸ºAIScheduleréœ€è¦çš„é…ç½®æ ¼å¼
        
        Args:
            config: ç¾¤èŠç­–ç•¥é…ç½®
            
        Returns:
            AIScheduleré…ç½®å­—å…¸
        """
        # å¦‚æœå¼€å¯æ— é™åˆ¶æ¨¡å¼ï¼Œç›´æ¥è¿”å›æœ€å¤§å€¼é…ç½®
        if config.unrestricted_mode:
            logger.info(f"ğŸ”“ æ— é™åˆ¶æ¨¡å¼å·²å¼€å¯ - AISchedulerä½¿ç”¨æœ€å¤§å€¼é…ç½®")
            return {
                "high_probability_threshold": 0.0,  # é˜ˆå€¼é™åˆ°0ï¼Œæ‰€æœ‰AIéƒ½ç®—é«˜æ¦‚ç‡
                "high_probability_keep_rate": StrategyConfigAdapter.UNRESTRICTED_LIMITS["keep_rate"],
                "mid_probability_threshold": 0.0,
                "low_probability_keep_rate": StrategyConfigAdapter.UNRESTRICTED_LIMITS["keep_rate"],
                "min_ai_sample_count": StrategyConfigAdapter.UNRESTRICTED_LIMITS["min_sample_count"],
                "mention_delay_min": StrategyConfigAdapter.UNRESTRICTED_LIMITS["delay_min"],
                "mention_delay_max": StrategyConfigAdapter.UNRESTRICTED_LIMITS["delay_max"],
                "high_interest_delay_min": StrategyConfigAdapter.UNRESTRICTED_LIMITS["delay_min"],
                "high_interest_delay_max": StrategyConfigAdapter.UNRESTRICTED_LIMITS["delay_max"],
                "normal_delay_min": StrategyConfigAdapter.UNRESTRICTED_LIMITS["delay_min"],
                "normal_delay_max": StrategyConfigAdapter.UNRESTRICTED_LIMITS["delay_max"],
            }
        
        # æ­£å¸¸æ¨¡å¼ï¼šä½¿ç”¨æ•°æ®åº“é…ç½®
        return {
            "high_probability_threshold": config.high_probability_threshold,
            "high_probability_keep_rate": config.high_probability_keep_rate,
            "mid_probability_threshold": config.mid_probability_threshold,
            "low_probability_keep_rate": config.low_probability_keep_rate,
            "min_ai_sample_count": config.min_ai_sample_count,
            "mention_delay_min": config.mention_delay_min,
            "mention_delay_max": config.mention_delay_max,
            "high_interest_delay_min": config.high_interest_delay_min,
            "high_interest_delay_max": config.high_interest_delay_max,
            "normal_delay_min": config.normal_delay_min,
            "normal_delay_max": config.normal_delay_max,
        }
    
    @staticmethod
    def to_intelligent_scheduler_config(config: GroupStrategyConfig) -> Dict[str, Any]:
        """
        è½¬æ¢ä¸ºIntelligentScheduleréœ€è¦çš„é…ç½®æ ¼å¼
        
        Args:
            config: ç¾¤èŠç­–ç•¥é…ç½®
            
        Returns:
            IntelligentScheduleré…ç½®å­—å…¸
        """
        # å¦‚æœå¼€å¯æ— é™åˆ¶æ¨¡å¼ï¼Œç›´æ¥è¿”å›æœ€å¤§å€¼é…ç½®
        if config.unrestricted_mode:
            logger.info(f"ğŸ”“ æ— é™åˆ¶æ¨¡å¼å·²å¼€å¯ - IntelligentSchedulerä½¿ç”¨æœ€å¤§å€¼é…ç½®")
            return {
                # æ´»è·ƒåº¦é…ç½® - æ‰€æœ‰æƒ…å†µä¸‹éƒ½å…è®¸æœ€å¤§å¹¶å‘
                "activity": {
                    "cold": {
                        "max_concurrent": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_concurrent"],
                        "min_delay_gap": StrategyConfigAdapter.UNRESTRICTED_LIMITS["min_delay_gap"],
                        "description": "å†·æ¸…ç¾¤ï¼ˆæ— é™åˆ¶ï¼‰"
                    },
                    "warm": {
                        "max_concurrent": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_concurrent"],
                        "min_delay_gap": StrategyConfigAdapter.UNRESTRICTED_LIMITS["min_delay_gap"],
                        "description": "æ¸©å’Œç¾¤ï¼ˆæ— é™åˆ¶ï¼‰"
                    },
                    "hot": {
                        "max_concurrent": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_concurrent"],
                        "min_delay_gap": StrategyConfigAdapter.UNRESTRICTED_LIMITS["min_delay_gap"],
                        "description": "çƒ­é—¹ç¾¤ï¼ˆæ— é™åˆ¶ï¼‰"
                    }
                },
                # è§¦å‘ç±»å‹é…ç½® - æ‰€æœ‰ç±»å‹éƒ½å…è®¸æœ€å¤§å¹¶å‘
                "trigger_type": {
                    "human_message": {
                        "max_concurrent": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_concurrent"],
                        "prefer_multiple": True,
                        "description": "äººç±»æ¶ˆæ¯ï¼ˆæ— é™åˆ¶ï¼‰"
                    },
                    "ai_message": {
                        "max_concurrent": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_concurrent"],
                        "prefer_multiple": True,  # æ— é™åˆ¶æ¨¡å¼ä¸‹ä¹Ÿé¼“åŠ±å¤šAIå›å¤
                        "description": "AIæ¶ˆæ¯ï¼ˆæ— é™åˆ¶ï¼‰"
                    },
                    "at_mention": {
                        "max_concurrent": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_concurrent"],
                        "prefer_multiple": True,
                        "description": "@æ¶ˆæ¯ï¼ˆæ— é™åˆ¶ï¼‰"
                    }
                },
                # AIè¿ç»­å›å¤æ¦‚ç‡è¡°å‡ - å…¨éƒ¨è®¾ä¸º1.0ï¼Œä¸è¡°å‡
                "ai_consecutive": {
                    0: {"multiplier": StrategyConfigAdapter.UNRESTRICTED_LIMITS["multiplier"], "description": "æ— AIè¿ç»­ï¼ˆæ— é™åˆ¶ï¼‰"},
                    1: {"multiplier": StrategyConfigAdapter.UNRESTRICTED_LIMITS["multiplier"], "description": "1æ¬¡AIè¿ç»­ï¼ˆæ— é™åˆ¶ï¼‰"},
                    2: {"multiplier": StrategyConfigAdapter.UNRESTRICTED_LIMITS["multiplier"], "description": "2æ¬¡AIè¿ç»­ï¼ˆæ— é™åˆ¶ï¼‰"},
                    3: {"multiplier": StrategyConfigAdapter.UNRESTRICTED_LIMITS["multiplier"], "description": "3æ¬¡åŠä»¥ä¸ŠAIè¿ç»­ï¼ˆæ— é™åˆ¶ï¼‰"}
                },
                # AIå¯†åº¦ - ä¸é™åˆ¶å¯†åº¦
                "recent_ai_density": {
                    "sparse": {"encourage": True, "description": "AIå›å¤ç¨€ç–ï¼ˆæ— é™åˆ¶ï¼‰"},
                    "balanced": {"encourage": True, "description": "AIå›å¤é€‚ä¸­ï¼ˆæ— é™åˆ¶ï¼‰"},
                    "dense": {
                        "encourage": True,  # æ— é™åˆ¶æ¨¡å¼ä¸‹ä¹Ÿé¼“åŠ±
                        "multiplier": StrategyConfigAdapter.UNRESTRICTED_LIMITS["multiplier"],
                        "description": "AIå›å¤è¿‡å¯†ï¼ˆæ— é™åˆ¶ï¼‰"
                    }
                },
                # ç›¸ä¼¼åº¦æ£€æµ‹ - ç¦ç”¨
                "enable_similarity_detection": False,
                "similarity_threshold": StrategyConfigAdapter.UNRESTRICTED_LIMITS["similarity_threshold"],
                "similarity_lookback": 0,
            }
        
        # æ­£å¸¸æ¨¡å¼ï¼šä½¿ç”¨æ•°æ®åº“é…ç½®
        return {
            # æ´»è·ƒåº¦é…ç½®
            "activity": {
                "cold": {
                    "max_concurrent": config.cold_group_max_concurrent,
                    "min_delay_gap": config.cold_group_min_delay_gap,
                    "description": "å†·æ¸…ç¾¤"
                },
                "warm": {
                    "max_concurrent": config.warm_group_max_concurrent,
                    "min_delay_gap": config.warm_group_min_delay_gap,
                    "description": "æ¸©å’Œç¾¤"
                },
                "hot": {
                    "max_concurrent": config.hot_group_max_concurrent,
                    "min_delay_gap": config.hot_group_min_delay_gap,
                    "description": "çƒ­é—¹ç¾¤"
                }
            },
            # è§¦å‘ç±»å‹é…ç½®
            "trigger_type": {
                "human_message": {
                    "max_concurrent": config.human_message_max_concurrent,
                    "prefer_multiple": True,
                    "description": "äººç±»æ¶ˆæ¯"
                },
                "ai_message": {
                    "max_concurrent": config.ai_message_max_concurrent,
                    "prefer_multiple": False,
                    "description": "AIæ¶ˆæ¯"
                },
                "at_mention": {
                    "max_concurrent": config.at_mention_max_concurrent,
                    "prefer_multiple": False,
                    "description": "@æ¶ˆæ¯"
                }
            },
            # AIè¿ç»­å›å¤æ¦‚ç‡è¡°å‡
            "ai_consecutive": {
                0: {"multiplier": config.ai_consecutive_0_multiplier, "description": "æ— AIè¿ç»­"},
                1: {"multiplier": config.ai_consecutive_1_multiplier, "description": "1æ¬¡AIè¿ç»­"},
                2: {"multiplier": config.ai_consecutive_2_multiplier, "description": "2æ¬¡AIè¿ç»­"},
                3: {"multiplier": config.ai_consecutive_3_multiplier, "description": "3æ¬¡åŠä»¥ä¸ŠAIè¿ç»­"}
            },
            # AIå¯†åº¦
            "recent_ai_density": {
                "sparse": {"encourage": True, "description": "AIå›å¤ç¨€ç–"},
                "balanced": {"encourage": False, "description": "AIå›å¤é€‚ä¸­"},
                "dense": {
                    "encourage": False,
                    "multiplier": config.dense_ai_multiplier,
                    "description": "AIå›å¤è¿‡å¯†"
                }
            },
            # ç›¸ä¼¼åº¦æ£€æµ‹
            "enable_similarity_detection": config.enable_similarity_detection,
            "similarity_threshold": config.similarity_threshold,
            "similarity_lookback": config.similarity_lookback,
        }
    
    @staticmethod
    def to_reply_controller_config(config: GroupStrategyConfig) -> Dict[str, Any]:
        """
        è½¬æ¢ä¸ºReplyControlleréœ€è¦çš„é…ç½®æ ¼å¼
        
        Args:
            config: ç¾¤èŠç­–ç•¥é…ç½®
            
        Returns:
            ReplyControlleré…ç½®å­—å…¸
        """
        # å¦‚æœå¼€å¯æ— é™åˆ¶æ¨¡å¼ï¼Œç›´æ¥è¿”å›æœ€å¤§å€¼é…ç½®
        if config.unrestricted_mode:
            logger.info(f"ğŸ”“ æ— é™åˆ¶æ¨¡å¼å·²å¼€å¯ - ReplyControllerä½¿ç”¨æœ€å¤§å€¼é…ç½®")
            return {
                "max_concurrent_replies": StrategyConfigAdapter.UNRESTRICTED_LIMITS["max_concurrent"],
            }
        
        # æ­£å¸¸æ¨¡å¼ï¼šä½¿ç”¨æ•°æ®åº“é…ç½®
        return {
            "max_concurrent_replies": config.max_concurrent_replies_per_message,
        }
    
    @staticmethod
    def get_ai_to_ai_delay(config: GroupStrategyConfig) -> float:
        """
        è·å–AI-to-AIè§¦å‘å»¶è¿Ÿæ—¶é—´
        
        Args:
            config: ç¾¤èŠç­–ç•¥é…ç½®
            
        Returns:
            å»¶è¿Ÿç§’æ•°
        """
        if config.unrestricted_mode:
            return StrategyConfigAdapter.UNRESTRICTED_LIMITS["ai_to_ai_delay_seconds"]
        return config.ai_to_ai_delay_seconds
    
    @staticmethod
    def get_default_config() -> GroupStrategyConfig:
        """è·å–é»˜è®¤é…ç½®"""
        return GroupStrategyConfig()

