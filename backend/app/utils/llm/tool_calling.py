"""
å·¥å…·è°ƒç”¨æ”¯æŒæ¨¡å—

ä¸º LLM æœåŠ¡æä¾›å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰èƒ½åŠ›
é›†æˆ MCP å·¥å…·ç³»ç»Ÿ
"""
import json
import logging
from typing import List, Dict, Any, AsyncGenerator, Optional
from ...mcp.manager import mcp_manager
from .tool_config import tool_config

logger = logging.getLogger(__name__)


class ToolCallingMixin:
    """
    å·¥å…·è°ƒç”¨æ··å…¥ç±»
    
    ä¸º LLM æœåŠ¡æä¾›å·¥å…·è°ƒç”¨èƒ½åŠ›
    ä»»ä½•éœ€è¦æ”¯æŒå·¥å…·è°ƒç”¨çš„æœåŠ¡éƒ½å¯ä»¥ç»§æ‰¿æ­¤ç±»
    """
    
    async def generate_with_tools(
        self,
        prompt: str,
        system_prompt: str,
        history: List[Dict[str, str]] = None,
        session_id: Optional[str] = None,
        user_id: Optional[str] = None,
        max_tool_iterations: Optional[int] = None,  # ğŸ‘ˆ æ”¹ä¸ºå¯é€‰ï¼Œè‡ªåŠ¨è¯»å–å…¨å±€é…ç½®
        **kwargs
    ) -> AsyncGenerator[str, None]:
        """
        å¸¦å·¥å…·è°ƒç”¨çš„æµå¼ç”Ÿæˆ
        
        å·¥ä½œæµç¨‹ï¼š
        1. è°ƒç”¨ LLMï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
        2. å¦‚æœéœ€è¦ï¼Œæ‰§è¡Œå·¥å…·è°ƒç”¨
        3. å°†å·¥å…·ç»“æœæ·»åŠ åˆ°ä¸Šä¸‹æ–‡
        4. ç»§ç»­è°ƒç”¨ LLM ç›´åˆ°å¾—åˆ°æœ€ç»ˆç­”æ¡ˆ
        
        Args:
            prompt: ç”¨æˆ·è¾“å…¥
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            history: å†å²æ¶ˆæ¯
            session_id: ä¼šè¯ IDï¼ˆå·¥å…·è°ƒç”¨æ—¶éœ€è¦ï¼‰
            user_id: ç”¨æˆ· ID
            max_tool_iterations: æœ€å¤§å·¥å…·è°ƒç”¨è¿­ä»£æ¬¡æ•°ï¼ŒNoneæ—¶ä½¿ç”¨å…¨å±€é…ç½® (tool_config.max_iterations)
            **kwargs: å…¶ä»–å‚æ•°
        
        Yields:
            str: æµå¼å“åº”ç‰‡æ®µ
        """
        history = history or []
        iteration = 0
        
        # ğŸ‘‡ ä½¿ç”¨å…¨å±€é…ç½®æˆ–ä¼ å…¥å‚æ•°
        max_iter = max_tool_iterations if max_tool_iterations is not None else tool_config.max_iterations
        logger.info(f"ğŸ”§ [tool_calling] æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iter} (å…¨å±€é…ç½®: {tool_config.max_iterations})")
        
        # è·å– MCP å·¥å…·åˆ—è¡¨
        mcp_client = mcp_manager.get_client()
        if not mcp_client:
            logger.warning("âš ï¸ MCP Client æœªåˆå§‹åŒ–ï¼Œå›é€€åˆ°æ— å·¥å…·æ¨¡å¼")
            async for chunk in self.generate_stream(prompt, system_prompt, history=history, **kwargs):
                yield chunk
            return
        
        try:
            tools = await mcp_client.list_tools()
            if not tools:
                logger.info("â„¹ï¸ æ— å¯ç”¨å·¥å…·ï¼Œä½¿ç”¨æ™®é€šå¯¹è¯æ¨¡å¼")
                async for chunk in self.generate_stream(prompt, system_prompt, history=history, **kwargs):
                    yield chunk
                return
            
            logger.info(f"ğŸ”§ å·²åŠ è½½ {len(tools)} ä¸ªå·¥å…·")
        except Exception as e:
            logger.error(f"âŒ è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
            async for chunk in self.generate_stream(prompt, system_prompt, history=history, **kwargs):
                yield chunk
            return
        
        # æ„å»ºæ¶ˆæ¯å†å²
        messages = self._build_messages_with_history(system_prompt, history, prompt)
        
        # å¼€å§‹å·¥å…·è°ƒç”¨å¾ªç¯
        while iteration < max_iter:  # ğŸ‘ˆ ä½¿ç”¨å…¨å±€é…ç½®
            iteration += 1
            logger.info(f"ğŸ”„ å·¥å…·è°ƒç”¨è¿­ä»£ {iteration}/{max_iter}")
            
            # è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·åˆ—è¡¨ï¼‰
            response = await self._call_llm_with_tools(messages, tools, **kwargs)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if not response.get("tool_calls"):
                # æ— å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆå›å¤
                logger.info("âœ… LLM è¿”å›æœ€ç»ˆå›å¤ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰")
                final_content = response.get("content", "")
                
                # æµå¼è¾“å‡ºï¼ˆæ¨¡æ‹Ÿï¼‰
                if final_content:
                    for char in final_content:
                        yield char
                
                break
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            tool_calls = response["tool_calls"]
            logger.info(f"ğŸ”§ LLM è¯·æ±‚è°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·")
            
            # å°† assistant æ¶ˆæ¯ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨è¯·æ±‚ï¼‰æ·»åŠ åˆ°å†å²
            messages.append({
                "role": "assistant",
                "content": response.get("content", ""),
                "tool_calls": tool_calls
            })
            
            # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
            tool_results = []
            for tool_call in tool_calls:
                tool_name = tool_call.get("function", {}).get("name")
                tool_args_str = tool_call.get("function", {}).get("arguments", "{}")
                tool_call_id = tool_call.get("id", "")
                
                try:
                    tool_args = json.loads(tool_args_str) if isinstance(tool_args_str, str) else tool_args_str
                except json.JSONDecodeError:
                    tool_args = {}
                
                logger.info(f"  ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}, å‚æ•°: {tool_args}")
                
                # æ‰§è¡Œå·¥å…·
                try:
                    result = await mcp_client.call_tool(
                        tool_name=tool_name,
                        arguments=tool_args,
                        session_id=session_id,
                        user_id=user_id
                    )
                    
                    logger.info(f"  âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ: {tool_name}")
                    tool_results.append({
                        "role": "tool",
                        "tool_call_id": tool_call_id,
                        "name": tool_name,
                        "content": result
                    })
                
                except Exception as e:
                    logger.error(f"  âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {tool_name}, é”™è¯¯: {e}")
                    tool_results.append({
                        "role": "tool",
                        "tool_call_id": tool_call_id,
                        "name": tool_name,
                        "content": json.dumps({"error": str(e)}, ensure_ascii=False)
                    })
            
            # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
            messages.extend(tool_results)
            
            # æç¤ºç”¨æˆ·å·¥å…·è°ƒç”¨è¿›åº¦ï¼ˆå¯é€‰ï¼‰
            yield f"\n[å·¥å…·è°ƒç”¨] å·²æ‰§è¡Œ {len(tool_calls)} ä¸ªå·¥å…·ï¼Œæ­£åœ¨ç”Ÿæˆå›å¤...\n\n"
        
        if iteration >= max_iter:  # ğŸ‘ˆ ä½¿ç”¨å…¨å±€é…ç½®
            logger.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•° ({max_iter})ï¼Œå¼ºåˆ¶ç»“æŸ")
            yield "\n[ç³»ç»Ÿæç¤º] å·²è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œåœæ­¢è¿­ä»£ã€‚\n"
    
    def _build_messages_with_history(
        self,
        system_prompt: str,
        history: List[Dict[str, str]],
        user_message: str
    ) -> List[Dict[str, Any]]:
        """æ„å»ºåŒ…å«å†å²çš„æ¶ˆæ¯åˆ—è¡¨"""
        messages = []
        
        # ç³»ç»Ÿæç¤ºè¯
        if system_prompt and system_prompt.strip():
            messages.append({"role": "system", "content": system_prompt.strip()})
        
        # å†å²æ¶ˆæ¯
        if history:
            for msg in history:
                messages.append({
                    "role": msg.get("role", "user"),
                    "content": msg.get("content", "")
                })
        
        # å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        return messages
    
    async def _call_llm_with_tools(
        self,
        messages: List[Dict[str, Any]],
        tools: List[Dict[str, Any]],
        **kwargs
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·åˆ—è¡¨ï¼‰
        
        å­ç±»åº”è¯¥å®ç°æ­¤æ–¹æ³•æ¥è°ƒç”¨å…·ä½“çš„ LLM API
        
        Returns:
            dict: {
                "content": "å›å¤å†…å®¹",
                "tool_calls": [...]  # å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·
            }
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç° _call_llm_with_tools æ–¹æ³•")


class ToolCallingHelper:
    """å·¥å…·è°ƒç”¨è¾…åŠ©å‡½æ•°"""
    
    @staticmethod
    def convert_mcp_tools_to_openai_format(tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°† MCP å·¥å…·æ ¼å¼è½¬æ¢ä¸º OpenAI Function Calling æ ¼å¼
        
        MCP æ ¼å¼å·²ç»æ˜¯ OpenAI æ ¼å¼ï¼Œç›´æ¥è¿”å›
        """
        return tools
    
    @staticmethod
    def parse_tool_calls_from_response(response) -> Optional[List[Dict[str, Any]]]:
        """
        ä» LLM å“åº”ä¸­è§£æå·¥å…·è°ƒç”¨
        
        Args:
            response: OpenAI API å“åº”å¯¹è±¡
        
        Returns:
            List[Dict] | None: å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        if not hasattr(response, "choices") or not response.choices:
            return None
        
        message = response.choices[0].message
        
        if not hasattr(message, "tool_calls") or not message.tool_calls:
            return None
        
        tool_calls = []
        for tc in message.tool_calls:
            tool_calls.append({
                "id": tc.id,
                "type": "function",
                "function": {
                    "name": tc.function.name,
                    "arguments": tc.function.arguments
                }
            })
        
        return tool_calls


__all__ = ["ToolCallingMixin", "ToolCallingHelper"]

