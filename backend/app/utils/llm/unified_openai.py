from openai import OpenAI, AsyncOpenAI
from openai import APIConnectionError, APITimeoutError, RateLimitError
from .base import ModelService
from .common import BaseModelService
import json
import logging
from typing import Dict, List, AsyncGenerator, Optional, Any
import httpx
import asyncio
from functools import wraps

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


def async_retry_on_connection_error(max_retries: int = None, delay: float = None, backoff: float = 2.0):
    """
    è£…é¥°å™¨ï¼šåœ¨é‡åˆ°ç½‘ç»œè¿æ¥é”™è¯¯æ—¶è‡ªåŠ¨é‡è¯•
    
    Args:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆNoneæ—¶ä½¿ç”¨å…¨å±€é…ç½®ï¼‰
        delay: åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼ŒNoneæ—¶ä½¿ç”¨å…¨å±€é…ç½®ï¼‰
        backoff: å»¶è¿Ÿå€å¢å› å­
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            from .tool_config import tool_config
            
            # ä½¿ç”¨å…¨å±€é…ç½®æˆ–ä¼ å…¥å‚æ•°
            actual_max_retries = max_retries if max_retries is not None else tool_config.max_retries
            actual_delay = delay if delay is not None else tool_config.retry_delay
            
            last_exception = None
            current_delay = actual_delay
            
            for attempt in range(actual_max_retries + 1):  # +1 å› ä¸ºç¬¬ä¸€æ¬¡ä¸ç®—é‡è¯•
                try:
                    # å°è¯•æ‰§è¡Œå‡½æ•°
                    async for item in func(*args, **kwargs):
                        yield item
                    return  # æˆåŠŸå®Œæˆï¼Œé€€å‡º
                    
                except (APIConnectionError, APITimeoutError, httpx.ConnectError, httpx.TimeoutException) as e:
                    last_exception = e
                    
                    if attempt < actual_max_retries:
                        logger.warning(
                            f"âš ï¸ ç½‘ç»œè¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{actual_max_retries + 1}): {e}"
                        )
                        logger.info(f"â³ {current_delay:.1f}ç§’åé‡è¯•...")
                        await asyncio.sleep(current_delay)
                        current_delay *= backoff  # æŒ‡æ•°é€€é¿
                    else:
                        logger.error(
                            f"âŒ é‡è¯• {actual_max_retries} æ¬¡åä»ç„¶å¤±è´¥: {e}"
                        )
                        raise
                        
                except Exception as e:
                    # å…¶ä»–å¼‚å¸¸ä¸é‡è¯•ï¼Œç›´æ¥æŠ›å‡º
                    raise
        
        return wrapper
    return decorator


class UnifiedOpenAIService(ModelService, BaseModelService):
    """
    ç»Ÿä¸€çš„ OpenAI å…¼å®¹æœåŠ¡
    
    æ”¯æŒæ‰€æœ‰å…¼å®¹ OpenAI API æ ¼å¼çš„æ¨¡å‹å‚å•†ï¼Œé€šè¿‡é…ç½®åŒºåˆ†ä¸åŒå‚å•†çš„ç‰¹æ€§ã€‚
    åªéœ€æä¾› provider é…ç½®å³å¯è‡ªåŠ¨é€‚é…ä¸åŒå‚å•†ã€‚
    
    âœ¨ ä¸ªæ€§åŒ–å‚æ•°æ”¯æŒï¼š
    - ä½¿ç”¨ OpenAI SDK çš„ extra_body æœºåˆ¶ä¼ é€’æ¨¡å‹ç‰¹å®šå‚æ•°
    - æ ‡å‡†å‚æ•°ï¼ˆtemperature, top_p ç­‰ï¼‰ç›´æ¥ä¼ é€’
    - éæ ‡å‡†å‚æ•°ï¼ˆtop_k, repetition_penalty ç­‰ï¼‰é€šè¿‡ extra_body ä¼ é€’
    - å®Œç¾æ”¯æŒå„å‚å•†çš„ä¸ªæ€§åŒ–é…ç½®ï¼Œæ— éœ€ä¿®æ”¹ SDK
    """
    
    # ğŸ”’ OpenAI SDK æ”¯æŒçš„æ ‡å‡†å‚æ•°åˆ—è¡¨
    # æ³¨æ„ï¼šOpenAI Python SDK åœ¨å®¢æˆ·ç«¯ä¼šä¸¥æ ¼éªŒè¯å‚æ•°ï¼Œåªæ¥å—æ ‡å‡†å‚æ•°ã€‚
    # ä½† SDK æä¾›äº† extra_body å‚æ•°ï¼Œå¯ä»¥ä¼ é€’æ¨¡å‹ç‰¹å®šçš„ä¸ªæ€§åŒ–å‚æ•°åˆ°æœåŠ¡ç«¯ã€‚
    # 
    # å·¥ä½œåŸç†ï¼š
    # - æ ‡å‡†å‚æ•°ï¼ˆå¦‚ temperature, top_pï¼‰ç›´æ¥ä¼ é€’ç»™ SDK
    # - éæ ‡å‡†å‚æ•°ï¼ˆå¦‚ top_k, repetition_penaltyï¼‰é€šè¿‡ extra_body ä¼ é€’åˆ°æœåŠ¡ç«¯
    # - è¿™æ ·æ—¢æ»¡è¶³ SDK éªŒè¯ï¼Œåˆä¿ç•™äº†æ¨¡å‹çš„ä¸ªæ€§åŒ–é…ç½®èƒ½åŠ›
    # 
    # å‚è€ƒ: https://platform.openai.com/docs/api-reference/chat/create
    OPENAI_SDK_SUPPORTED_PARAMS = {
        'model', 'messages', 'stream', 'temperature', 'top_p', 'max_tokens',
        'presence_penalty', 'frequency_penalty', 'logit_bias', 'logprobs',
        'top_logprobs', 'n', 'stop', 'seed', 'user', 'response_format',
        'tools', 'tool_choice', 'parallel_tool_calls'
    }
    
    # ğŸ¯ é¢„å®šä¹‰å„å‚å•†çš„ç‰¹æ®Šé…ç½®
    PROVIDER_CONFIGS = {
        "deepseek": {
            "url_suffix": "",  # API URL åç¼€
            "api_key_override": None,  # æ˜¯å¦è¦†ç›– API Keyï¼ˆNoneè¡¨ç¤ºä½¿ç”¨ä¼ å…¥çš„ï¼‰
            "default_headers": {},  # è‡ªå®šä¹‰è¯·æ±‚å¤´
            "supports_vision": False,  # æ˜¯å¦æ”¯æŒå›¾ç‰‡ç†è§£
            "save_images_to_minio": False,  # æ˜¯å¦ä¿å­˜å›¾ç‰‡åˆ° MinIO
            "fallback_to_non_stream": False,  # æµå¼å¤±è´¥æ—¶æ˜¯å¦å›é€€åˆ°éæµå¼
            "default_params": {  # æ¨¡å‹ç‰¹å®šçš„é»˜è®¤å‚æ•°
                # âœ¨ OpenAI SDK æ”¯æŒé€šè¿‡ extra_body ä¼ é€’é¢å¤–å‚æ•°
                # æ ‡å‡†å‚æ•°ç›´æ¥ä¼ é€’ï¼Œéæ ‡å‡†å‚æ•°é€šè¿‡ extra_body ä¼ é€’åˆ°æœåŠ¡ç«¯
                "top_k": 30,  # ğŸ¯ é€šè¿‡ extra_body ä¼ é€’ï¼ˆDeepSeek ç‰¹æœ‰ï¼‰
                "presence_penalty": 0.3,  # âœ… æ ‡å‡†å‚æ•°ï¼Œç›´æ¥ä¼ é€’
                "frequency_penalty": 0.2,  # âœ… æ ‡å‡†å‚æ•°ï¼Œç›´æ¥ä¼ é€’
                "repetition_penalty": 1.2,  # ğŸ¯ é€šè¿‡ extra_body ä¼ é€’ï¼ˆDeepSeek ç‰¹æœ‰ï¼‰
            }
        },
        "ollama": {
            "url_suffix": "/v1",  # Ollama éœ€è¦ /v1 åç¼€
            "api_key_override": "ollama",  # Ollama ä¸éªŒè¯ API Keyï¼Œéšæ„å¡«
            "default_headers": {},
            "supports_vision": True,  # Ollama æ”¯æŒ LLaVA ç­‰å¤šæ¨¡æ€æ¨¡å‹
            "save_images_to_minio": False,
            "fallback_to_non_stream": False,
            "default_params": {
                "temperature": 0.7,
                "max_tokens": 1024,
            }
        },
        "doubao": {
            "url_suffix": "",
            "api_key_override": None,
            "default_headers": {
                "User-Agent": "fish-chat/1.0"
            },
            "supports_vision": True,  # è±†åŒ…æ”¯æŒå¤šæ¨¡æ€
            "save_images_to_minio": True,  # è±†åŒ…éœ€è¦ä¿å­˜å›¾ç‰‡åˆ° MinIO
            "fallback_to_non_stream": True,  # è±†åŒ…æµå¼å¤±è´¥æ—¶é‡è¯•éæµå¼
            "default_params": {
                # è±†åŒ…ä¸æ”¯æŒæŸäº›å‚æ•°ï¼Œä½¿ç”¨ç©ºå­—å…¸
            }
        },
        "bailian": {
            "url_suffix": "",  # å·²åŒ…å«åœ¨ base_url ä¸­
            "api_key_override": None,
            "default_headers": {},
            "supports_vision": True,  # é€šä¹‰åƒé—®æ”¯æŒå¤šæ¨¡æ€
            "save_images_to_minio": False,  # ç›´æ¥æ”¯æŒ base64 å›¾ç‰‡
            "fallback_to_non_stream": False,
            "default_params": {
                "temperature": 0.8,  # é€šä¹‰åƒé—®æ¨èçš„æ¸©åº¦å€¼
                "top_p": 0.8,
            }
        },
        "siliconflow": {
            "url_suffix": "",  # å·²åŒ…å«åœ¨ base_url ä¸­
            "api_key_override": None,
            "default_headers": {},
            "supports_vision": True,  # ç¡…åŸºæµåŠ¨æ”¯æŒå¤šæ¨¡æ€
            "save_images_to_minio": False,  # ç›´æ¥æ”¯æŒ base64 å›¾ç‰‡
            "fallback_to_non_stream": False,
            "default_params": {
                "temperature": 0.8,  # ç¡…åŸºæµåŠ¨æ¨èçš„æ¸©åº¦å€¼
                "top_p": 0.8,
            }
        },
        "zhipu": {
            "url_suffix": "",  # å·²åŒ…å«åœ¨ base_url ä¸­
            "api_key_override": None,
            "default_headers": {},
            "supports_vision": True,  # æ™ºè°±AIæ”¯æŒå¤šæ¨¡æ€
            "save_images_to_minio": False,  # ç›´æ¥æ”¯æŒ base64 å›¾ç‰‡
            "fallback_to_non_stream": False,
            "default_params": {
                "temperature": 0.7,
                "top_p": 0.7,
            }
        },
        "hunyuan": {
            "url_suffix": "",  # å·²åŒ…å«åœ¨ base_url ä¸­
            "api_key_override": None,
            "default_headers": {},
            "supports_vision": True,  # è…¾è®¯æ··å…ƒæ”¯æŒå¤šæ¨¡æ€
            "save_images_to_minio": False,  # ç›´æ¥æ”¯æŒ base64 å›¾ç‰‡
            "fallback_to_non_stream": False,
            "default_params": {
                "temperature": 0.7,
                "top_p": 0.7,
            }
        },
        "moonshot": {
            "url_suffix": "",  # å·²åŒ…å«åœ¨ base_url ä¸­
            "api_key_override": None,
            "default_headers": {},
            "supports_vision": True,  # Moonshot Kimiæ”¯æŒå¤šæ¨¡æ€
            "save_images_to_minio": False,  # ç›´æ¥æ”¯æŒ base64 å›¾ç‰‡
            "fallback_to_non_stream": False,
            "default_params": {
                "temperature": 0.3,
                "top_p": 0.7,
            }
        },
        "modelscope": {
            "url_suffix": "",
            "api_key_override": None,
            "default_headers": {},
            "supports_vision": True,  # Qwen-VLæ¨¡å‹æ”¯æŒå›¾ç‰‡
            "save_images_to_minio": True,
            "fallback_to_non_stream": False,
            "default_params": {
                "temperature": 0.7,
                "top_p": 0.8
            }
        },
        "stepfun": {
            "url_suffix": "",  # å·²åŒ…å«åœ¨ base_url ä¸­
            "api_key_override": None,
            "default_headers": {},
            "supports_vision": True,  # é˜¶è·ƒæ˜Ÿè¾°æ”¯æŒå¤šæ¨¡æ€
            "save_images_to_minio": False,  # ç›´æ¥æ”¯æŒ base64 å›¾ç‰‡
            "fallback_to_non_stream": False,
            "default_params": {
                "temperature": 0.7,
                "top_p": 0.7,
            }
        },
    }
    
    def __init__(self, base_url: str, api_key: str, model_name: str, provider: str = "openai"):
        """
        åˆå§‹åŒ–ç»Ÿä¸€çš„ OpenAI å…¼å®¹æœåŠ¡
        
        Args:
            base_url: API åŸºç¡€ URL
            api_key: API å¯†é’¥
            model_name: æ¨¡å‹åç§°
            provider: å‚å•†æ ‡è¯† (deepseek/ollama/doubao ç­‰)
        """
        BaseModelService.__init__(self, base_url, api_key, model_name)
        
        self.provider = provider
        self.config = self.PROVIDER_CONFIGS.get(provider, {})
        self.last_saved_images = []  # ä¿å­˜çš„å›¾ç‰‡ URL åˆ—è¡¨
        
        # æ ¹æ®é…ç½®å¤„ç† URL
        url_suffix = self.config.get('url_suffix', '')
        final_url = f"{self.base_url}{url_suffix}"
        
        # æ ¹æ®é…ç½®å¤„ç† API Key
        api_key_override = self.config.get('api_key_override')
        final_key = api_key_override if api_key_override is not None else api_key
        
        # æ ¹æ®é…ç½®å¤„ç† Headers
        headers = self.config.get('default_headers', {})
        
        # é…ç½®è¶…æ—¶ï¼šconnect=10ç§’ï¼Œread=120ç§’ï¼Œwrite=120ç§’ï¼Œpool=10ç§’
        # è¿™æ ·å¯ä»¥é˜²æ­¢ç½‘ç»œé—®é¢˜å¯¼è‡´çš„æ— é™ç­‰å¾…ï¼ŒåŒæ—¶ç»™æµå¼å“åº”è¶³å¤Ÿæ—¶é—´
        timeout = httpx.Timeout(
            connect=10.0,  # è¿æ¥è¶…æ—¶
            read=120.0,    # è¯»å–è¶…æ—¶ï¼ˆæµå¼å“åº”éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰
            write=120.0,   # å†™å…¥è¶…æ—¶
            pool=10.0      # è¿æ¥æ± è¶…æ—¶
        )
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆåŒæ­¥ï¼‰
        self.client = OpenAI(
            base_url=final_url,
            api_key=final_key,
            default_headers=headers if headers else None,
            timeout=timeout,  # æ·»åŠ è¶…æ—¶é…ç½®
            max_retries=0  # ç¦ç”¨è‡ªåŠ¨é‡è¯•ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
        )
        
        # åˆå§‹åŒ– OpenAI å¼‚æ­¥å®¢æˆ·ç«¯ï¼ˆç”¨äºçœŸæµå¼ï¼‰
        self.async_client = AsyncOpenAI(
            base_url=final_url,
            api_key=final_key,
            default_headers=headers if headers else None,
            timeout=timeout,
            max_retries=0
        )
        
        logger.info(f"ğŸ¯ åˆå§‹åŒ– {provider} æœåŠ¡")
        logger.info(f"ğŸ“¡ API URL: {final_url}")
        logger.info(f"ğŸ·ï¸ æ¨¡å‹: {model_name}")
    
    def get_model_specific_params(self) -> Dict[str, Any]:
        """è·å–å‚å•†ç‰¹å®šçš„é»˜è®¤å‚æ•°"""
        return self.config.get('default_params', {})
    
    def _process_request_data(self, data: Dict[str, Any], images_base64: Optional[List[str]] = None, **kwargs) -> Dict[str, Any]:
        """
        å¤„ç†è¯·æ±‚æ•°æ®ï¼Œç»Ÿä¸€å¤„ç†å›¾ç‰‡æ ¼å¼
        
        å°†å›¾ç‰‡è½¬æ¢ä¸º OpenAI Vision API æ ‡å‡†æ ¼å¼
        
        é€»è¾‘ç®€åŒ–ï¼šåªè¦æœ‰å›¾ç‰‡å°±å¤„ç†ï¼Œä¸ç®¡é…ç½®å¦‚ä½•
        è¿™æ ·å¯ä»¥è®© API è‡ªå·±å†³å®šæ˜¯å¦æ”¯æŒå›¾ç‰‡ï¼Œè€Œä¸æ˜¯åœ¨å®¢æˆ·ç«¯åˆ¤æ–­
        """
        # ğŸ› è°ƒè¯•ï¼šè®°å½•æ¥æ”¶åˆ°çš„images_base64
        logger.info(f"ğŸ–¼ï¸ [UnifiedOpenAIService._process_request_data] æ¥æ”¶åˆ°images_base64å‚æ•°: {len(images_base64) if images_base64 else 0}å¼ å›¾ç‰‡")
        logger.info(f"ğŸ–¼ï¸ [UnifiedOpenAIService._process_request_data] images_base64ç±»å‹: {type(images_base64)}")
        if images_base64:
            logger.info(f"ğŸ–¼ï¸ [UnifiedOpenAIService._process_request_data] ç¬¬ä¸€å¼ å›¾ç‰‡Base64å‰ç¼€: {images_base64[0][:50] if images_base64[0] else 'None'}")
        
        messages = data.get("messages", [])
        
        # ğŸ–¼ï¸ ç¬¬ä¸€æ­¥ï¼šå¤„ç†å†å²æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ï¼ˆMinIO URL -> Base64ï¼‰
        from ...utils.minio_client import minio_client
        
        for i, msg in enumerate(messages):
            if msg.get("role") == "user" and msg.get("images"):
                user_content = msg.get("content", "")
                image_urls = msg.get("images", [])
                
                # æ„å»ºåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯å†…å®¹ï¼ˆOpenAI æ ‡å‡†æ ¼å¼ï¼‰
                message_content = []
                
                # å°† MinIO URL è½¬æ¢ä¸º base64
                for image_url in image_urls:
                    if image_url.startswith("minio://"):
                        try:
                            # get_image_base64 è¿”å›çš„å·²ç»æ˜¯å®Œæ•´çš„ data URL (data:image/png;base64,...)
                            data_url = minio_client.get_image_base64(image_url)
                            if data_url:
                                message_content.append({
                                    "type": "image_url",
                                    "image_url": {
                                        "url": data_url
                                    }
                                })
                                logger.info(f"ğŸ“¸ å†å²æ¶ˆæ¯å›¾ç‰‡å·²è½¬æ¢: {image_url[:60]}... -> base64")
                            else:
                                logger.warning(f"âš ï¸ æ— æ³•ä»MinIOè·å–å›¾ç‰‡: {image_url}")
                        except Exception as e:
                            logger.error(f"âŒ è½¬æ¢å†å²æ¶ˆæ¯å›¾ç‰‡å¤±è´¥: {str(e)}")
                
                # æ·»åŠ æ–‡æœ¬å†…å®¹
                if user_content.strip():
                    message_content.append({
                        "type": "text",
                        "text": user_content
                    })
                
                # æ›´æ–°æ¶ˆæ¯æ ¼å¼ï¼ˆåªæœ‰æœ‰å›¾ç‰‡æ—¶æ‰æ”¹ä¸ºå¤šæ¨¡æ€æ ¼å¼ï¼‰
                if message_content and any(item.get("type") == "image_url" for item in message_content):
                    messages[i]["content"] = message_content
                    logger.info(f"ğŸ“¸ å†å²æ¶ˆæ¯å·²è½¬æ¢ä¸ºå¤šæ¨¡æ€æ ¼å¼: {len(image_urls)}å¼ å›¾ç‰‡")
                
                # ç§»é™¤ images å­—æ®µï¼Œå› ä¸ºå·²ç»è½¬æ¢åˆ° content ä¸­
                if "images" in messages[i]:
                    del messages[i]["images"]
        
        # ğŸ–¼ï¸ ç¬¬äºŒæ­¥ï¼šå¤„ç†å½“å‰æ¶ˆæ¯çš„å›¾ç‰‡ï¼ˆBase64ï¼‰
        if images_base64 and len(images_base64) > 0:
            # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å¹¶æ·»åŠ å›¾ç‰‡
            for i in range(len(messages) - 1, -1, -1):
                if messages[i].get("role") == "user":
                    user_content = messages[i].get("content", "")
                    
                    # å¦‚æœå·²ç»æ˜¯å¤šæ¨¡æ€æ ¼å¼ï¼ˆä»å†å²æ¶ˆæ¯å¤„ç†æ¥çš„ï¼‰ï¼Œè¿½åŠ å›¾ç‰‡
                    if isinstance(user_content, list):
                        message_content = user_content
                    else:
                        # æ„å»ºæ–°çš„å¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹
                        message_content = []
                        # å…ˆæ·»åŠ æ–‡æœ¬
                        if user_content.strip():
                            message_content.append({
                                "type": "text",
                                "text": user_content
                            })
                    
                    # æ·»åŠ æ‰€æœ‰å½“å‰æ¶ˆæ¯çš„å›¾ç‰‡
                    for image_base64 in images_base64:
                        image_format = self._detect_image_format(image_base64)
                        image_url = f"data:image/{image_format};base64,{image_base64}"
                        
                        message_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": image_url
                            }
                        })
                        
                        logger.info(f"æ£€æµ‹åˆ°å›¾ç‰‡æ ¼å¼: {image_format}")
                    
                    # æ›´æ–°æ¶ˆæ¯æ ¼å¼
                    messages[i]["content"] = message_content
                    logger.info(f"ä¸º {self.provider} API è½¬æ¢å›¾ç‰‡æ¶ˆæ¯æ ¼å¼: {len(images_base64)}å¼ å›¾ç‰‡")
                    break
        
        data["messages"] = messages
        return data
    
    def _OLD_COMPLEX_process_request_data(self, data: Dict[str, Any], images_base64: Optional[List[str]] = None, **kwargs) -> Dict[str, Any]:
        """
        ã€åºŸå¼ƒã€‘æ—§çš„å¤æ‚é€»è¾‘ï¼ŒåŒ…å« supports_vision æ£€æŸ¥
        ä¿ç•™ä»¥å¤‡å‚è€ƒ
        """
        messages = data.get("messages", [])
        supports_vision = self.config.get('supports_vision', False)
        
        # ğŸš« å¦‚æœå½“å‰æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡ï¼Œç§»é™¤æ‰€æœ‰å›¾ç‰‡ç›¸å…³å­—æ®µ
        if not supports_vision:
            logger.warning(f"âš ï¸ å½“å‰æ¨¡å‹ {self.model_name} ä¸æ”¯æŒå›¾ç‰‡ï¼Œå°†å¿½ç•¥å†å²æ¶ˆæ¯å’Œå½“å‰æ¶ˆæ¯ä¸­çš„æ‰€æœ‰å›¾ç‰‡")
            
            # æ¸…ç†å†å²æ¶ˆæ¯ä¸­çš„å›¾ç‰‡å­—æ®µ
            for i, msg in enumerate(messages):
                if msg.get("role") == "user" and msg.get("images"):
                    logger.info(f"ğŸ“¸ ç§»é™¤å†å²æ¶ˆæ¯ä¸­çš„å›¾ç‰‡å­—æ®µ: {len(msg.get('images', []))}å¼ å›¾ç‰‡")
                    # ç§»é™¤ images å­—æ®µ
                    if "images" in messages[i]:
                        del messages[i]["images"]
                    # ç¡®ä¿ content æ˜¯çº¯æ–‡æœ¬æ ¼å¼
                    if isinstance(messages[i].get("content"), list):
                        # å¦‚æœæ˜¯å¤šæ¨¡æ€æ ¼å¼ï¼Œæå–æ–‡æœ¬éƒ¨åˆ†
                        text_parts = [item.get("text", "") for item in messages[i]["content"] if item.get("type") == "text"]
                        messages[i]["content"] = " ".join(text_parts).strip()
            
            # å¿½ç•¥å½“å‰æ¶ˆæ¯ä¸­çš„å›¾ç‰‡(ä¸å¤„ç† images_base64)
            if images_base64 and len(images_base64) > 0:
                logger.warning(f"âš ï¸ å¿½ç•¥å½“å‰æ¶ˆæ¯ä¸­çš„ {len(images_base64)} å¼ å›¾ç‰‡ï¼Œå› ä¸ºå½“å‰æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡")
            
            data["messages"] = messages
            return data
        
        # âœ… å¦‚æœå½“å‰æ¨¡å‹æ”¯æŒå›¾ç‰‡ï¼Œå¤„ç†å›¾ç‰‡æ•°æ®
        logger.info(f"âœ… å½“å‰æ¨¡å‹ {self.model_name} æ”¯æŒå›¾ç‰‡ï¼Œå°†å¤„ç†å†å²æ¶ˆæ¯å’Œå½“å‰æ¶ˆæ¯ä¸­çš„å›¾ç‰‡")
        
        # ğŸ–¼ï¸ ç¬¬ä¸€æ­¥ï¼šå¤„ç†å†å²æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ï¼ˆMinIO URL -> Base64ï¼‰
        from ...utils.minio_client import minio_client
        
        for i, msg in enumerate(messages):
            if msg.get("role") == "user" and msg.get("images"):
                user_content = msg.get("content", "")
                image_urls = msg.get("images", [])
                
                # æ„å»ºåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯å†…å®¹ï¼ˆOpenAI æ ‡å‡†æ ¼å¼ï¼‰
                message_content = []
                
                # å°† MinIO URL è½¬æ¢ä¸º base64
                for image_url in image_urls:
                    if image_url.startswith("minio://"):
                        try:
                            # get_image_base64 è¿”å›çš„å·²ç»æ˜¯å®Œæ•´çš„ data URL (data:image/png;base64,...)
                            data_url = minio_client.get_image_base64(image_url)
                            if data_url:
                                message_content.append({
                                    "type": "image_url",
                                    "image_url": {
                                        "url": data_url
                                    }
                                })
                                logger.info(f"ğŸ“¸ å†å²æ¶ˆæ¯å›¾ç‰‡å·²è½¬æ¢: {image_url[:60]}... -> base64")
                            else:
                                logger.warning(f"âš ï¸ æ— æ³•ä»MinIOè·å–å›¾ç‰‡: {image_url}")
                        except Exception as e:
                            logger.error(f"âŒ è½¬æ¢å†å²æ¶ˆæ¯å›¾ç‰‡å¤±è´¥: {str(e)}")
                
                # æ·»åŠ æ–‡æœ¬å†…å®¹
                if user_content.strip():
                    message_content.append({
                        "type": "text",
                        "text": user_content
                    })
                
                # æ›´æ–°æ¶ˆæ¯æ ¼å¼ï¼ˆåªæœ‰æœ‰å›¾ç‰‡æ—¶æ‰æ”¹ä¸ºå¤šæ¨¡æ€æ ¼å¼ï¼‰
                if any(item.get("type") == "image_url" for item in message_content):
                    messages[i]["content"] = message_content
                    # ç§»é™¤ images å­—æ®µï¼Œé¿å…ä¼ é€’ç»™ API
                    if "images" in messages[i]:
                        del messages[i]["images"]
        
        # ğŸ–¼ï¸ ç¬¬äºŒæ­¥ï¼šå¤„ç†å½“å‰æ¶ˆæ¯çš„å›¾ç‰‡ï¼ˆBase64ï¼‰
        if images_base64:
            # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å¹¶æ·»åŠ å›¾ç‰‡
            for i in range(len(messages) - 1, -1, -1):
                if messages[i].get("role") == "user":
                    user_content = messages[i].get("content", "")
                    
                    # å¦‚æœå·²ç»æ˜¯å¤šæ¨¡æ€æ ¼å¼ï¼Œè¿½åŠ å›¾ç‰‡
                    if isinstance(user_content, list):
                        message_content = user_content
                    else:
                        message_content = []
                    
                    # æ·»åŠ æ‰€æœ‰å›¾ç‰‡
                    for image_base64 in images_base64:
                        image_format = self._detect_image_format(image_base64)
                        image_url = f"data:image/{image_format};base64,{image_base64}"
                        
                        message_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": image_url
                            }
                        })
                        
                        logger.info(f"æ£€æµ‹åˆ°å›¾ç‰‡æ ¼å¼: {image_format}")
                    
                    # æ·»åŠ æ–‡æœ¬å†…å®¹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                    if not isinstance(user_content, list) and user_content.strip():
                        message_content.append({
                            "type": "text",
                            "text": user_content
                        })
                    
                    # æ›´æ–°æ¶ˆæ¯æ ¼å¼
                    messages[i]["content"] = message_content
                    logger.info(f"ä¸º {self.provider} API è½¬æ¢å½“å‰æ¶ˆæ¯å›¾ç‰‡æ ¼å¼: {len(images_base64)}å¼ å›¾ç‰‡")
                    break
        
        data["messages"] = messages
        return data
    
    def _detect_image_format(self, image_base64: str) -> str:
        """
        è‡ªåŠ¨æ£€æµ‹å›¾ç‰‡æ ¼å¼
        
        æ ¹æ® Base64 ç¼–ç çš„å¼€å¤´å­—ç¬¦åˆ¤æ–­å›¾ç‰‡æ ¼å¼
        """
        if image_base64.startswith('/9j/') or image_base64.startswith('/9j'):
            return "jpeg"
        elif image_base64.startswith('iVBORw0KGgo'):
            return "png"
        elif image_base64.startswith('R0lGODlh') or image_base64.startswith('R0lGODdh'):
            return "gif"
        elif image_base64.startswith('UklGR'):  # WEBP
            return "webp"
        else:
            return "jpeg"  # é»˜è®¤
    
    async def generate_stream(self, prompt: str, system_prompt: str, **kwargs) -> AsyncGenerator[str, None]:
        """å®ç°æŠ½è±¡æ–¹æ³• - ä½¿ç”¨æ¨¡æ¿æ–¹æ³•"""
        async for chunk in self.generate_stream_template(prompt, system_prompt, **kwargs):
            yield chunk
    
    def _filter_params(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†ç¦»æ ‡å‡†å‚æ•°å’Œé¢å¤–å‚æ•°
        
        OpenAI SDK ä¼šåœ¨å®¢æˆ·ç«¯ä¾§ä¸¥æ ¼éªŒè¯å‚æ•°ï¼Œåªæ¥å—æ ‡å‡†å‚æ•°
        ä½†å¯ä»¥é€šè¿‡ extra_body å‚æ•°ä¼ é€’æ¨¡å‹ç‰¹å®šçš„ä¸ªæ€§åŒ–å‚æ•°
        
        Args:
            data: è¯·æ±‚æ•°æ®å­—å…¸
        
        Returns:
            dict: è¿‡æ»¤åçš„æ•°æ®ï¼ˆæ ‡å‡†å‚æ•° + extra_bodyï¼‰
        """
        filtered_data = {}
        extra_params = {}
        
        for key, value in data.items():
            if key in self.OPENAI_SDK_SUPPORTED_PARAMS:
                filtered_data[key] = value
            else:
                extra_params[key] = value
        
        # è®°å½•å‚æ•°åˆ†ç¦»æƒ…å†µ
        if extra_params:
            logger.info(f"âœ¨ é€šè¿‡ extra_body ä¼ é€’æ¨¡å‹ä¸ªæ€§åŒ–å‚æ•°: {list(extra_params.keys())}")
            logger.info(f"   ä¸ªæ€§åŒ–å‚æ•°è¯¦æƒ…: {json.dumps(extra_params, ensure_ascii=False)}")
            # å°†é¢å¤–å‚æ•°æ·»åŠ åˆ° extra_body
            filtered_data['extra_body'] = extra_params
        
        return filtered_data
    
    async def _call_api(self, data: Dict[str, Any], **kwargs) -> AsyncGenerator[str, None]:
        """
        ç»Ÿä¸€çš„ API è°ƒç”¨å®ç°
        
        æ‰€æœ‰å…¼å®¹ OpenAI æ ¼å¼çš„å‚å•†éƒ½ä½¿ç”¨ç›¸åŒçš„è°ƒç”¨é€»è¾‘
        """
        try:
            logger.info(f"ğŸ“¡ è°ƒç”¨ {self.provider} API")
            logger.info(f"ğŸ·ï¸ æ¨¡å‹: {data.get('model')}")
            
            # æå–å‚æ•°ç”¨äºåç»­å¤„ç†
            images_base64 = kwargs.get("images_base64")
            session_id = kwargs.get("session_id")
            message_id = kwargs.get("message_id")
            user_id = kwargs.get("user_id")
            
            try:
                # ğŸ”’ åˆ†ç¦»æ ‡å‡†å‚æ•°å’Œé¢å¤–å‚æ•°
                filtered_data = self._filter_params(data)
                
                logger.info(f"ğŸ” ä¼ é€’ç»™ OpenAI SDK çš„æ ‡å‡†å‚æ•°:")
                for key, value in filtered_data.items():
                    if key == 'extra_body':
                        logger.info(f"  {key}: {json.dumps(value, ensure_ascii=False)}")
                    elif key != 'messages':
                        logger.info(f"  {key}: {type(value).__name__} = {value}")
                    else:
                        logger.info(f"  {key}: [{len(value)} messages]")
                
                # âœ… ä½¿ç”¨ extra_body ä¼ é€’é¢å¤–å‚æ•°çš„ OpenAI SDK æµå¼è¯·æ±‚
                stream = self.client.chat.completions.create(**filtered_data)
                
                # å¤„ç†æµå¼å“åº”
                from ...config import settings
                full_response = ""
                MAX_RESPONSE_LENGTH = settings.max_response_length  # ä»é…ç½®è¯»å–æœ€å¤§å“åº”é•¿åº¦
                MAX_CHUNK_LENGTH = settings.max_chunk_length  # ä»é…ç½®è¯»å–å•ä¸ªchunkæœ€å¤§é•¿åº¦
                chunk_count = 0
                
                for chunk in stream:
                    # å¢åŠ å®‰å…¨æ£€æŸ¥ï¼Œç¡®ä¿ choices åˆ—è¡¨ä¸ä¸ºç©º
                    if chunk.choices and chunk.choices[0].delta.content is not None:
                        content = chunk.choices[0].delta.content
                        chunk_count += 1
                        
                        # ğŸ›¡ï¸ é˜²æŠ¤1ï¼šæ£€æŸ¥å•ä¸ªchunké•¿åº¦ï¼ˆå¼‚å¸¸æ•°æ®æ³¨å…¥ï¼‰
                        if len(content) > MAX_CHUNK_LENGTH:
                            error_msg = f"ğŸš¨ æ£€æµ‹åˆ°å¼‚å¸¸æ•°æ®æ³¨å…¥ï¼å•ä¸ªchunké•¿åº¦={len(content)}ï¼Œè¶…è¿‡é™åˆ¶{MAX_CHUNK_LENGTH}ã€‚chunkåºå·={chunk_count}"
                            logger.error(error_msg)
                            logger.error(f"å¼‚å¸¸chunkå‰1000å­—ç¬¦é¢„è§ˆ: {content[:1000]}")
                            # æŠ›å‡ºå¼‚å¸¸ï¼Œæ‹’ç»æ­¤æ¬¡è¯·æ±‚
                            raise ValueError(f"æ£€æµ‹åˆ°å¼‚å¸¸æ•°æ®ï¼šå•ä¸ªå“åº”ç‰‡æ®µè¿‡é•¿ï¼ˆ{len(content)}å­—ç¬¦ï¼‰ï¼Œå¯èƒ½æ˜¯å¼‚å¸¸æ³¨å…¥ï¼Œå·²æ‹’ç»è¯·æ±‚")
                        
                        # ğŸ›¡ï¸ é˜²æŠ¤2ï¼šæ£€æŸ¥ç´¯ç§¯å“åº”é•¿åº¦ï¼ˆå¼‚å¸¸æ•°æ®æ³¨å…¥ï¼‰
                        if len(full_response) + len(content) > MAX_RESPONSE_LENGTH:
                            error_msg = f"ğŸš¨ æ£€æµ‹åˆ°å¼‚å¸¸æ•°æ®æ³¨å…¥ï¼å“åº”æ€»é•¿åº¦={len(full_response) + len(content)}ï¼Œè¶…è¿‡é™åˆ¶{MAX_RESPONSE_LENGTH}"
                            logger.error(error_msg)
                            logger.error(f"å®Œæ•´å“åº”å‰2000å­—ç¬¦: {full_response[:2000]}")
                            logger.error(f"å®Œæ•´å“åº”å2000å­—ç¬¦: {full_response[-2000:]}")
                            # æŠ›å‡ºå¼‚å¸¸ï¼Œæ‹’ç»æ­¤æ¬¡è¯·æ±‚
                            raise ValueError(f"æ£€æµ‹åˆ°å¼‚å¸¸æ•°æ®ï¼šå“åº”æ€»é•¿åº¦è¿‡é•¿ï¼ˆ{len(full_response) + len(content)}å­—ç¬¦ï¼‰ï¼Œå¯èƒ½æ˜¯å¼‚å¸¸æ³¨å…¥ï¼Œå·²æ‹’ç»è¯·æ±‚")
                        
                        full_response += content
                        yield content
                        
                logger.info(f"âœ… æµå¼å“åº”å®Œæˆã€‚æ€»chunkæ•°={chunk_count}ï¼Œæ€»é•¿åº¦={len(full_response)}")
                
                # ğŸ–¼ï¸ å¦‚æœé…ç½®äº†ä¿å­˜å›¾ç‰‡åˆ° MinIOï¼Œåœ¨å“åº”å®Œæˆåä¿å­˜
                if self.config.get('save_images_to_minio'):
                    await self._save_images_after_response(images_base64, session_id, message_id, user_id)
                
            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶å¼‚å¸¸
                is_timeout = isinstance(e, (httpx.TimeoutException, httpx.ReadTimeout, httpx.ConnectTimeout))
                
                if is_timeout:
                    logger.error(f"â±ï¸ {self.provider} è¯·æ±‚è¶…æ—¶: {str(e)}")
                else:
                    logger.error(f"{self.provider} æµå¼è¯·æ±‚å¤±è´¥: {str(e)}")
                
                # å¦‚æœé…ç½®äº† fallbackï¼Œå°è¯•éæµå¼è¯·æ±‚ï¼ˆä½†è¶…æ—¶å¼‚å¸¸ä¸é‡è¯•ï¼‰
                if self.config.get('fallback_to_non_stream') and not is_timeout:
                    logger.info(f"å°è¯• {self.provider} éæµå¼è¯·æ±‚...")
                    request_data = filtered_data.copy()  # ä½¿ç”¨å·²è¿‡æ»¤çš„æ•°æ®
                    request_data["stream"] = False
                    
                    response = self.client.chat.completions.create(**request_data)
                    
                    if response.choices[0].message.content:
                        full_response = response.choices[0].message.content
                        yield full_response
                        
                        # ğŸ–¼ï¸ éæµå¼å“åº”å®Œæˆåä¹Ÿä¿å­˜å›¾ç‰‡
                        if self.config.get('save_images_to_minio'):
                            await self._save_images_after_response(images_base64, session_id, message_id, user_id)
                else:
                    # ä¸æ”¯æŒ fallback æˆ–è¶…æ—¶å¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡º
                    if is_timeout:
                        raise Exception(f"APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
                    raise e
        
        except Exception as e:
            logger.error(f"{self.provider} API Error: {str(e)}")
            raise self.error_handler.handle_api_error(e)
    
    async def _save_images_after_response(self, 
                                         images_base64: Optional[List[str]], 
                                         session_id: Optional[str], 
                                         message_id: Optional[str], 
                                         user_id: Optional[str] = None):
        """
        å“åº”å®Œæˆåä¿å­˜å›¾ç‰‡åˆ° MinIO
        
        åªæœ‰é…ç½®äº† save_images_to_minio çš„å‚å•†æ‰ä¼šæ‰§è¡Œæ­¤æ“ä½œ
        """
        logger.info(f"=== æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜å›¾ç‰‡åˆ° MinIO ({self.provider}) ===")
        logger.info(f"images_base64å­˜åœ¨: {images_base64 is not None}")
        logger.info(f"user_id: {user_id}")
        logger.info(f"session_idå­˜åœ¨: {session_id is not None}")
        logger.info(f"message_idå­˜åœ¨: {message_id is not None}")
        
        if images_base64 and session_id and message_id:
            logger.info(f"âœ… å¼€å§‹ä¿å­˜ {len(images_base64)} å¼ å›¾ç‰‡åˆ° MinIO...")
            saved_images = await self._save_images_to_minio(images_base64, session_id, message_id, user_id)
            logger.info(f"âœ… å›¾ç‰‡ä¿å­˜ç»“æœ: {saved_images}")
            
            # å°†ä¿å­˜çš„å›¾ç‰‡ URL å­˜å‚¨åˆ°å®ä¾‹å˜é‡ä¸­ï¼Œä¾›å¤–éƒ¨è®¿é—®
            self.last_saved_images = saved_images
        else:
            logger.warning(f"âŒ ç¼ºå°‘å¿…è¦å‚æ•°ï¼Œè·³è¿‡å›¾ç‰‡ä¿å­˜ ({self.provider})")
            if not images_base64:
                logger.warning("  - images_base64ä¸ºç©º")
            if not session_id:
                logger.warning("  - session_idä¸ºç©º")
            if not message_id:
                logger.warning("  - message_idä¸ºç©º")
    
    async def _save_images_to_minio(self, 
                                   images_base64: List[str], 
                                   session_id: str, 
                                   message_id: str, 
                                   user_id: Optional[str] = None):
        """
        ä¿å­˜å›¾ç‰‡åˆ° MinIO
        
        Args:
            images_base64: Base64 ç¼–ç çš„å›¾ç‰‡åˆ—è¡¨
            session_id: ä¼šè¯ ID
            message_id: æ¶ˆæ¯ ID
            user_id: ç”¨æˆ· IDï¼ˆç”¨äºè·¯å¾„éš”ç¦»ï¼‰
            
        Returns:
            ä¿å­˜æˆåŠŸçš„å›¾ç‰‡ URL åˆ—è¡¨
        """
        logger.info(f"=== å¼€å§‹ä¿å­˜å›¾ç‰‡åˆ° MinIO ({self.provider}) ===")
        logger.info(f"user_id: {user_id}")
        logger.info(f"session_id: {session_id}")
        logger.info(f"message_id: {message_id}")
        logger.info(f"å›¾ç‰‡æ•°é‡: {len(images_base64)}")
        
        try:
            from ..minio_client import minio_client
            
            saved_images = []
            for i, image_base64 in enumerate(images_base64):
                logger.info(f"æ­£åœ¨ä¿å­˜ç¬¬ {i+1} å¼ å›¾ç‰‡...")
                minio_url = minio_client.upload_image(image_base64, session_id, message_id, user_id)
                if minio_url:
                    saved_images.append(minio_url)
                    logger.info(f"âœ… å›¾ç‰‡å·²ä¿å­˜åˆ° MinIO: {minio_url}")
                else:
                    logger.error(f"âŒ ç¬¬ {i+1} å¼ å›¾ç‰‡ä¿å­˜å¤±è´¥")
            
            if saved_images:
                logger.info(f"âœ… å…±ä¿å­˜äº† {len(saved_images)} å¼ å›¾ç‰‡åˆ° MinIO")
                return saved_images
            else:
                logger.error("âŒ æ²¡æœ‰å›¾ç‰‡ä¿å­˜æˆåŠŸ")
                return []
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å›¾ç‰‡åˆ° MinIO å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return []
    
    def _call_llm_with_tools_sync(self, messages: List[Dict[str, Any]], tools: List[Dict[str, Any]], model_params: Optional[Dict[str, Any]] = None, images_base64: Optional[List[str]] = None, use_streaming: bool = False, **kwargs) -> Dict[str, Any]:
        """
        åŒæ­¥è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·æ”¯æŒï¼‰
        
        æ”¯æŒæµå¼å’Œéæµå¼ä¸¤ç§æ¨¡å¼ï¼š
        - éæµå¼ï¼ˆé»˜è®¤ï¼‰ï¼šç›´æ¥è¿”å›å®Œæ•´å“åº”
        - æµå¼ï¼šç´¯ç§¯æµå¼å“åº”ç‰‡æ®µåè¿”å›å®Œæ•´å“åº”
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            tools: å·¥å…·åˆ—è¡¨ï¼ˆOpenAI æ ¼å¼ï¼‰
            model_params: ç”¨æˆ·è‡ªå®šä¹‰æ¨¡å‹å‚æ•°ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            images_base64: å›¾ç‰‡base64åˆ—è¡¨ï¼ˆç”¨äºvisionæ¨¡å‹ï¼‰
            use_streaming: æ˜¯å¦ä½¿ç”¨æµå¼æ¨¡å¼ï¼ˆé»˜è®¤Falseï¼‰
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆåŒ…æ‹¬ session_id, message_id, user_idï¼‰
        
        Returns:
            dict: {
                "content": "å›å¤å†…å®¹",
                "tool_calls": [...]  # å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·
            }
        
        Raises:
            NotImplementedError: å½“æ¨¡å‹ä¸æ”¯æŒå·¥å…·è°ƒç”¨æ—¶
        """
        try:
            # ğŸ–¼ï¸ ä¿å­˜å›¾ç‰‡ç›¸å…³å‚æ•°åˆ°å®ä¾‹å˜é‡ï¼ˆç”¨äºåç»­ä¿å­˜åˆ°MinIOï¼‰
            if images_base64:
                session_id = kwargs.get('session_id')
                message_id = kwargs.get('message_id')
                user_id = kwargs.get('user_id')
                
                self._pending_images = {
                    'images_base64': images_base64,
                    'session_id': session_id,
                    'message_id': message_id,
                    'user_id': user_id
                }
                logger.info(f"ğŸ–¼ï¸ å·¥å…·è°ƒç”¨æ¨¡å¼ï¼šå·²ç¼“å­˜ {len(images_base64)} å¼ å›¾ç‰‡æ•°æ®ï¼ˆsession_id={session_id}, message_id={message_id}, user_id={user_id}ï¼‰")
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "model": self.model_name,
                "messages": messages,
                "tools": tools,
                "stream": use_streaming,  # ğŸ¯ æ”¯æŒæµå¼/éæµå¼åˆ‡æ¢
                **self.get_default_request_params(),
                **self.get_model_specific_params()
            }
            
            # ğŸ¯ åˆå¹¶ç”¨æˆ·è‡ªå®šä¹‰æ¨¡å‹å‚æ•°ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            if isinstance(model_params, dict) and model_params:
                request_data.update(model_params)
                logger.info(f"âœ… å·¥å…·è°ƒç”¨åº”ç”¨è‡ªå®šä¹‰æ¨¡å‹å‚æ•°: {json.dumps(model_params, ensure_ascii=False)}")
            
            # ğŸ–¼ï¸ ã€å…³é”®ä¿®å¤ã€‘å§‹ç»ˆè°ƒç”¨ _process_request_data æ¥å¤„ç†å›¾ç‰‡
            # å³ä½¿å½“å‰æ¶ˆæ¯æ²¡æœ‰å›¾ç‰‡ï¼Œå†å²æ¶ˆæ¯ä¸­ä¹Ÿå¯èƒ½åŒ…å«å›¾ç‰‡éœ€è¦è½¬æ¢
            if images_base64:
                logger.info(f"ğŸ–¼ï¸ å·¥å…·è°ƒç”¨ä¸­åŒ…å« {len(images_base64)} å¼ å½“å‰æ¶ˆæ¯å›¾ç‰‡ï¼Œè°ƒç”¨_process_request_dataå¤„ç†")
            else:
                logger.info(f"ğŸ–¼ï¸ å½“å‰æ¶ˆæ¯æ— å›¾ç‰‡ï¼Œä½†æ£€æŸ¥å†å²æ¶ˆæ¯æ˜¯å¦åŒ…å«å›¾ç‰‡...")
            
            request_data = self._process_request_data(request_data, images_base64, **kwargs)
            
            # åˆ†ç¦»æ ‡å‡†å‚æ•°å’Œé¢å¤–å‚æ•°
            filtered_data = self._filter_params(request_data)
            
            logger.info(f"ğŸ”§ è°ƒç”¨ {self.provider} LLMï¼ˆå¸¦å·¥å…·æ”¯æŒï¼Œ{'âœ… æµå¼' if use_streaming else 'âš ï¸ éæµå¼'}æ¨¡å¼ï¼‰")
            logger.info(f"ğŸ› ï¸ å·¥å…·æ•°é‡: {len(tools)}")
            
            # æ‰“å°å®é™…å‘é€çš„è¯·æ±‚ä½“ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            self.log_request_data(filtered_data, f"{self.provider} (å·¥å…·è°ƒç”¨)")
            
            # è°ƒç”¨ API
            response = self.client.chat.completions.create(**filtered_data)
            
            # ğŸ¯ è‡ªåŠ¨æ£€æµ‹è¿”å›ç±»å‹ï¼ˆå…¼å®¹å¼ºåˆ¶æµå¼æ¨¡å‹ï¼‰
            # æ£€æŸ¥ response æ˜¯å¦ä¸º Stream å¯¹è±¡
            is_stream_response = hasattr(response, '__iter__') and not hasattr(response, 'choices')
            
            if is_stream_response:
                # ğŸ”„ æµå¼æ¨¡å¼ï¼šç´¯ç§¯chunks
                logger.info("ğŸ”„ ä½¿ç”¨æµå¼æ¨¡å¼å¤„ç†å·¥å…·è°ƒç”¨å“åº”")
                result = {
                    "content": "",
                    "tool_calls": []
                }
                
                # ç”¨äºç´¯ç§¯å·¥å…·è°ƒç”¨ä¿¡æ¯
                tool_calls_accumulator = {}  # {index: {id, name, arguments}}
                finish_reason = None
                
                for chunk in response:
                    # æ£€æŸ¥ finish_reasonï¼ˆæµå¼ç»“æŸæ ‡å¿—ï¼‰
                    if chunk.choices and chunk.choices[0].finish_reason:
                        finish_reason = chunk.choices[0].finish_reason
                        logger.info(f"ğŸ æµå¼è¾“å‡ºç»“æŸæ ‡å¿—: {finish_reason}")
                    
                    delta = chunk.choices[0].delta if chunk.choices else None
                    if not delta:
                        continue
                    
                    # ç´¯ç§¯å†…å®¹
                    if hasattr(delta, 'content') and delta.content:
                        result["content"] += delta.content
                    
                    # ç´¯ç§¯å·¥å…·è°ƒç”¨
                    if hasattr(delta, 'tool_calls') and delta.tool_calls:
                        for tc_delta in delta.tool_calls:
                            idx = tc_delta.index
                            
                            if idx not in tool_calls_accumulator:
                                tool_calls_accumulator[idx] = {
                                    "id": "",
                                    "name": "",
                                    "arguments": ""
                                }
                            
                            if hasattr(tc_delta, 'id') and tc_delta.id:
                                tool_calls_accumulator[idx]["id"] = tc_delta.id
                            
                            if hasattr(tc_delta, 'function'):
                                if hasattr(tc_delta.function, 'name') and tc_delta.function.name:
                                    tool_calls_accumulator[idx]["name"] = tc_delta.function.name
                                if hasattr(tc_delta.function, 'arguments') and tc_delta.function.arguments:
                                    tool_calls_accumulator[idx]["arguments"] += tc_delta.function.arguments
                
                # ğŸ¯ æµå¼è¾“å‡ºå®Œæˆåçš„æ—¥å¿—
                logger.info(f"âœ… æµå¼è¾“å‡ºå®Œæˆï¼Œfinish_reason={finish_reason}ï¼Œç´¯ç§¯äº† {len(tool_calls_accumulator)} ä¸ªå·¥å…·è°ƒç”¨")
                
                # è½¬æ¢ç´¯ç§¯çš„å·¥å…·è°ƒç”¨ä¸ºæ ‡å‡†æ ¼å¼
                for idx in sorted(tool_calls_accumulator.keys()):
                    tc = tool_calls_accumulator[idx]
                    result["tool_calls"].append({
                        "id": tc["id"],
                        "type": "function",
                        "function": {
                            "name": tc["name"],
                            "arguments": tc["arguments"]
                        }
                    })
                
                if result["tool_calls"]:
                    logger.info(f"ğŸ”§ LLM è¯·æ±‚è°ƒç”¨ {len(result['tool_calls'])} ä¸ªå·¥å…·ï¼ˆæµå¼ç´¯ç§¯ï¼‰")
                else:
                    logger.info("âœ… LLM è¿”å›æœ€ç»ˆå›å¤ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼Œæµå¼ï¼‰")
            else:
                # ğŸ“¦ éæµå¼æ¨¡å¼ï¼šç›´æ¥è§£æ
                message = response.choices[0].message
                result = {
                    "content": message.content or "",
                    "tool_calls": []
                }
                
                # ğŸ” è°ƒè¯•ï¼šæ‰“å°åŸå§‹å“åº”ç»“æ„
                logger.debug(f"ğŸ” API è¿”å›çš„ message å¯¹è±¡: {message}")
                logger.debug(f"ğŸ” message æ˜¯å¦æœ‰ tool_calls å±æ€§: {hasattr(message, 'tool_calls')}")
                logger.debug(f"ğŸ” message.tool_calls çš„å€¼: {getattr(message, 'tool_calls', None)}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if hasattr(message, "tool_calls") and message.tool_calls:
                    for tc in message.tool_calls:
                        result["tool_calls"].append({
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        })
                    
                    logger.info(f"ğŸ”§ LLM è¯·æ±‚è°ƒç”¨ {len(result['tool_calls'])} ä¸ªå·¥å…·")
                else:
                    logger.info("âœ… LLM è¿”å›æœ€ç»ˆå›å¤ï¼ˆæ— å·¥å…·è°ƒç”¨ï¼‰")
            
            return result
        
        except Exception as e:
            # ğŸ¯ æ£€æŸ¥æ˜¯å¦ä¸º"æ¨¡å‹ä¸æ”¯æŒå·¥å…·è°ƒç”¨"çš„é”™è¯¯
            # ç­–ç•¥ï¼šé€šè¿‡é”™è¯¯å¯¹è±¡çš„ code/type å±æ€§åˆ¤æ–­ï¼ˆæ¯”å­—ç¬¦ä¸²åŒ¹é…æ›´å¯é ï¼‰
            
            error_msg = str(e).lower()
            
            # 1ï¸âƒ£ ä¼˜å…ˆæ£€æŸ¥å¼‚å¸¸å¯¹è±¡çš„ code å±æ€§ï¼ˆOpenAI SDK æ ‡å‡†ï¼‰
            error_code = getattr(e, 'code', None)
            error_type_attr = getattr(e, 'type', None)
            
            # 2ï¸âƒ£ æ˜ç¡®çš„"ä¸æ”¯æŒå·¥å…·"é”™è¯¯ç ï¼ˆå„APIæä¾›å•†å¯èƒ½ä½¿ç”¨çš„æ ‡å‡†ç ï¼‰
            # - feature_not_supported: åŠŸèƒ½ä¸æ”¯æŒ
            # - invalid_request_error + tools/functions å…³é”®è¯: å·¥å…·è¯·æ±‚æ— æ•ˆ
            if error_code in ['feature_not_supported', 'unsupported_feature']:
                logger.warning(f"âš ï¸ æ¨¡å‹ {self.model_name} ä¸æ”¯æŒæ­¤åŠŸèƒ½ï¼ˆé”™è¯¯ç : {error_code}ï¼‰")
                raise NotImplementedError(f"Model {self.model_name} does not support function calling") from e
            
            # 3ï¸âƒ£ invalid_request_error ä¸”é”™è¯¯ä¿¡æ¯æ˜ç¡®æåˆ°å·¥å…·/å‡½æ•°ä¸æ”¯æŒ
            if error_code == 'invalid_request_error' or error_type_attr == 'invalid_request_error':
                # åªæœ‰åŒæ—¶åŒ…å«"ä¸æ”¯æŒ"+"å·¥å…·/å‡½æ•°"æ‰è®¤å®šä¸ºMCPä¸æ”¯æŒ
                has_unsupported = any(kw in error_msg for kw in [
                    "not supported", "unsupported", "does not support", "ä¸æ”¯æŒ"
                ])
                has_tool_ref = any(kw in error_msg for kw in [
                    "tool", "function", "function_call", "function calling"
                ])
                
                if has_unsupported and has_tool_ref:
                    logger.warning(f"âš ï¸ æ¨¡å‹ {self.model_name} ä¸æ”¯æŒå·¥å…·è°ƒç”¨")
                    logger.debug(f"ğŸ” é”™è¯¯è¯¦æƒ…: code={error_code}, type={error_type_attr}, msg={error_msg[:150]}")
                    raise NotImplementedError(f"Model {self.model_name} does not support function calling") from e
            
            # âš ï¸ å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡ºï¼Œä¸æ ‡è®°ä¸º"ä¸æ”¯æŒå·¥å…·"
            # åŒ…æ‹¬ï¼šè®¤è¯é”™è¯¯ã€ç½‘ç»œé”™è¯¯ã€å‚æ•°é”™è¯¯ã€æœåŠ¡ä¸å¯ç”¨ç­‰
            logger.error(f"âŒ è°ƒç”¨ LLM å¤±è´¥ ({type(e).__name__}): {e}", exc_info=True)
            raise
    
    @async_retry_on_connection_error()  # ä½¿ç”¨å…¨å±€é…ç½®
    async def _call_llm_with_tools_streaming(
        self,
        messages: List[Dict[str, Any]],
        tools: List[Dict[str, Any]],
        model_params: Optional[Dict[str, Any]] = None,
        images_base64: Optional[List[str]] = None,
        **kwargs
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¼‚æ­¥æµå¼è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·æ”¯æŒï¼‰
        
        ä¸ _call_llm_with_tools_sync çš„åŒºåˆ«ï¼š
        - è¿”å›å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œé€å—yieldäº‹ä»¶
        - å·¥å…·è°ƒç”¨ï¼šç´¯ç§¯åyieldå®Œæ•´çš„tool_calls
        - å†…å®¹è¾“å‡ºï¼šç›´æ¥é€ä¼ æ¯ä¸ªchunkï¼Œä¸ç´¯ç§¯
        
        Yields:
            dict: äº‹ä»¶å¯¹è±¡
                - {"type": "content_delta", "content": "..."}  # å†…å®¹ç‰‡æ®µ
                - {"type": "tool_calls", "tool_calls": [...]}  # å·¥å…·è°ƒç”¨ï¼ˆç´¯ç§¯å®Œæˆï¼‰
                - {"type": "done", "finish_reason": "stop"}    # å®Œæˆæ ‡å¿—
        """
        try:
            # ğŸ–¼ï¸ ä¿å­˜å›¾ç‰‡ç›¸å…³å‚æ•°
            if images_base64:
                session_id = kwargs.get('session_id')
                message_id = kwargs.get('message_id')
                user_id = kwargs.get('user_id')
                
                self._pending_images = {
                    'images_base64': images_base64,
                    'session_id': session_id,
                    'message_id': message_id,
                    'user_id': user_id
                }
                logger.info(f"ğŸ–¼ï¸ æµå¼å·¥å…·è°ƒç”¨ï¼šå·²ç¼“å­˜ {len(images_base64)} å¼ å›¾ç‰‡æ•°æ®")
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "model": self.model_name,
                "messages": messages,
                "tools": tools,
                "stream": True,  # ğŸ¯ å¼ºåˆ¶æµå¼
                **self.get_default_request_params(),
                **self.get_model_specific_params()
            }
            
            # åˆå¹¶ç”¨æˆ·è‡ªå®šä¹‰å‚æ•°
            if isinstance(model_params, dict) and model_params:
                request_data.update(model_params)
                logger.info(f"âœ… åº”ç”¨è‡ªå®šä¹‰æ¨¡å‹å‚æ•°: {json.dumps(model_params, ensure_ascii=False)}")
            
            # å¤„ç†å›¾ç‰‡
            request_data = self._process_request_data(request_data, images_base64, **kwargs)
            filtered_data = self._filter_params(request_data)
            
            logger.info(f"ğŸ”§ è°ƒç”¨ {self.provider} LLMï¼ˆçœŸæµå¼å·¥å…·è°ƒç”¨æ¨¡å¼ï¼‰")
            logger.info(f"ğŸ› ï¸ å·¥å…·æ•°é‡: {len(tools)}")
            self.log_request_data(filtered_data, f"{self.provider} (çœŸæµå¼)")
            
            # ğŸš€ è°ƒç”¨ APIï¼ˆå¼‚æ­¥ï¼‰
            response = await self.async_client.chat.completions.create(**filtered_data)
            
            # ğŸ¯ æµå¼å¤„ç†
            tool_calls_accumulator = {}  # å·¥å…·è°ƒç”¨éœ€è¦ç´¯ç§¯
            finish_reason = None
            
            async for chunk in response:
                # æ£€æŸ¥å®Œæˆæ ‡å¿—
                if chunk.choices and chunk.choices[0].finish_reason:
                    finish_reason = chunk.choices[0].finish_reason
                
                delta = chunk.choices[0].delta if chunk.choices else None
                if not delta:
                    continue
                
                # ğŸ¯ å†…å®¹ç›´æ¥é€ä¼ ï¼ˆä¸ç´¯ç§¯ï¼‰
                if hasattr(delta, 'content') and delta.content:
                    yield {
                        "type": "content_delta",
                        "content": delta.content
                    }
                
                # ğŸ¯ å·¥å…·è°ƒç”¨ç´¯ç§¯ï¼ˆå¿…é¡»ç­‰å¾…å®Œæ•´ï¼‰
                if hasattr(delta, 'tool_calls') and delta.tool_calls:
                    for tc_delta in delta.tool_calls:
                        idx = tc_delta.index
                        
                        if idx not in tool_calls_accumulator:
                            tool_calls_accumulator[idx] = {
                                "id": "",
                                "name": "",
                                "arguments": ""
                            }
                        
                        if hasattr(tc_delta, 'id') and tc_delta.id:
                            tool_calls_accumulator[idx]["id"] = tc_delta.id
                        
                        if hasattr(tc_delta, 'function'):
                            if hasattr(tc_delta.function, 'name') and tc_delta.function.name:
                                tool_calls_accumulator[idx]["name"] = tc_delta.function.name
                            if hasattr(tc_delta.function, 'arguments') and tc_delta.function.arguments:
                                tool_calls_accumulator[idx]["arguments"] += tc_delta.function.arguments
            
            # ğŸ æµå¼ç»“æŸ
            logger.info(f"âœ… çœŸæµå¼å®Œæˆï¼Œfinish_reason={finish_reason}ï¼Œç´¯ç§¯äº† {len(tool_calls_accumulator)} ä¸ªå·¥å…·è°ƒç”¨")
            
            # ğŸ¯ å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œyieldå·¥å…·è°ƒç”¨äº‹ä»¶
            if tool_calls_accumulator:
                tool_calls = []
                for idx in sorted(tool_calls_accumulator.keys()):
                    tc = tool_calls_accumulator[idx]
                    tool_calls.append({
                        "id": tc["id"],
                        "type": "function",
                        "function": {
                            "name": tc["name"],
                            "arguments": tc["arguments"]
                        }
                    })
                
                logger.info(f"ğŸ”§ LLM è¯·æ±‚è°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·ï¼ˆçœŸæµå¼ç´¯ç§¯ï¼‰")
                yield {
                    "type": "tool_calls",
                    "tool_calls": tool_calls
                }
            
            # ğŸ¯ æœ€åyieldå®Œæˆäº‹ä»¶
            yield {
                "type": "done",
                "finish_reason": finish_reason
            }
        
        except Exception as e:
            # é”™è¯¯å¤„ç†ï¼ˆä¸åŒæ­¥ç‰ˆæœ¬ç›¸åŒï¼‰
            error_msg = str(e).lower()
            error_code = getattr(e, 'code', None)
            error_type_attr = getattr(e, 'type', None)
            
            if error_code in ['feature_not_supported', 'unsupported_feature']:
                logger.warning(f"âš ï¸ æ¨¡å‹ {self.model_name} ä¸æ”¯æŒæ­¤åŠŸèƒ½ï¼ˆé”™è¯¯ç : {error_code}ï¼‰")
                raise NotImplementedError(f"Model {self.model_name} does not support function calling") from e
            
            if error_code == 'invalid_request_error' or error_type_attr == 'invalid_request_error':
                has_unsupported = any(kw in error_msg for kw in [
                    "not supported", "unsupported", "does not support", "ä¸æ”¯æŒ"
                ])
                has_tool_ref = any(kw in error_msg for kw in [
                    "tool", "function", "function_call", "function calling"
                ])
                
                if has_unsupported and has_tool_ref:
                    logger.warning(f"âš ï¸ æ¨¡å‹ {self.model_name} ä¸æ”¯æŒå·¥å…·è°ƒç”¨")
                    raise NotImplementedError(f"Model {self.model_name} does not support function calling") from e
            
            logger.error(f"âŒ çœŸæµå¼è°ƒç”¨å¤±è´¥ ({type(e).__name__}): {e}", exc_info=True)
            raise

