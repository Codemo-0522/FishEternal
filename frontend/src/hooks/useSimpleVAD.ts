import { useState, useRef, useCallback } from 'react';

/**
 * ç®€å•çš„ VAD å®ç° - åŸºäº Web Audio API éŸ³é‡æ£€æµ‹
 * ä¸ä¾èµ–ä»»ä½•å¤–éƒ¨åº“ï¼Œçº¯æµè§ˆå™¨ API å®ç°
 */

interface SimpleVADOptions {
  /** éŸ³é‡é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºæ˜¯è¯­éŸ³ */
  volumeThreshold?: number;
  /** é™éŸ³æŒç»­æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œè¶…è¿‡æ­¤æ—¶é•¿è‡ªåŠ¨åœæ­¢ */
  silenceDuration?: number;
  /** è¯­éŸ³å¼€å§‹å›è°ƒ */
  onSpeechStart?: () => void;
  /** è¯­éŸ³ç»“æŸå›è°ƒ */
  onSpeechEnd?: () => void;
}

interface UseSimpleVADReturn {
  /** æ˜¯å¦æ­£åœ¨è¯´è¯ */
  isSpeaking: boolean;
  /** å¯åŠ¨ VAD */
  startVAD: (stream: MediaStream) => void;
  /** åœæ­¢ VAD */
  stopVAD: () => void;
  /** å½“å‰éŸ³é‡ï¼ˆ0-1ï¼‰ */
  currentVolume: number;
}

export const useSimpleVAD = (options: SimpleVADOptions = {}): UseSimpleVADReturn => {
  const {
    volumeThreshold = 0.02, // éŸ³é‡é˜ˆå€¼ï¼ˆè°ƒä½ä¸€ç‚¹æ›´æ•æ„Ÿï¼‰
    silenceDuration = 1500, // 1.5ç§’é™éŸ³åç»“æŸ
    onSpeechStart,
    onSpeechEnd,
  } = options;

  const [isSpeaking, setIsSpeaking] = useState(false);
  const [currentVolume, setCurrentVolume] = useState(0);

  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  const startVAD = useCallback((stream: MediaStream) => {
    console.log('[SimpleVAD] ğŸš€ å¯åŠ¨éŸ³é‡æ£€æµ‹ VAD');
    
    // ä¿å­˜ stream å¼•ç”¨
    streamRef.current = stream;

    // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
    audioContextRef.current = audioContext;

    // åˆ›å»ºåˆ†æå™¨èŠ‚ç‚¹
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    analyser.smoothingTimeConstant = 0.8;
    analyserRef.current = analyser;

    // è¿æ¥éŸ³é¢‘æº
    const source = audioContext.createMediaStreamSource(stream);
    source.connect(analyser);

    // å¼€å§‹æ£€æµ‹éŸ³é‡
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    
    const detectVolume = () => {
      if (!analyserRef.current) return;

      analyser.getByteFrequencyData(dataArray);
      
      // è®¡ç®—å¹³å‡éŸ³é‡
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
      const volume = average / 255; // å½’ä¸€åŒ–åˆ° 0-1
      
      setCurrentVolume(volume);

      // åˆ¤æ–­æ˜¯å¦åœ¨è¯´è¯
      if (volume > volumeThreshold) {
        // æ£€æµ‹åˆ°è¯­éŸ³
        if (!isSpeaking) {
          console.log('[SimpleVAD] ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹, éŸ³é‡:', volume.toFixed(3));
          setIsSpeaking(true);
          onSpeechStart?.();
        }

        // æ¸…é™¤é™éŸ³è®¡æ—¶å™¨
        if (silenceTimerRef.current) {
          clearTimeout(silenceTimerRef.current);
          silenceTimerRef.current = null;
        }
      } else {
        // æ£€æµ‹åˆ°é™éŸ³
        if (isSpeaking && !silenceTimerRef.current) {
          console.log('[SimpleVAD] ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ï¼Œå¼€å§‹è®¡æ—¶...');
          
          // å¯åŠ¨é™éŸ³è®¡æ—¶å™¨
          silenceTimerRef.current = setTimeout(() => {
            console.log('[SimpleVAD] â±ï¸ é™éŸ³è¶…è¿‡', silenceDuration, 'msï¼Œè§¦å‘è¯­éŸ³ç»“æŸ');
            setIsSpeaking(false);
            onSpeechEnd?.();
            silenceTimerRef.current = null;
          }, silenceDuration);
        }
      }

      // ç»§ç»­æ£€æµ‹
      animationFrameRef.current = requestAnimationFrame(detectVolume);
    };

    detectVolume();
  }, [volumeThreshold, silenceDuration, onSpeechStart, onSpeechEnd, isSpeaking]);

  const stopVAD = useCallback(() => {
    console.log('[SimpleVAD] ğŸ›‘ åœæ­¢ VAD');

    // åœæ­¢éŸ³é‡æ£€æµ‹
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    // æ¸…é™¤é™éŸ³è®¡æ—¶å™¨
    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }

    // å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    analyserRef.current = null;
    streamRef.current = null;
    setIsSpeaking(false);
    setCurrentVolume(0);
  }, []);

  return {
    isSpeaking,
    startVAD,
    stopVAD,
    currentVolume,
  };
};

